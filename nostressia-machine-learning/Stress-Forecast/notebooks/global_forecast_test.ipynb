{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- Semua nama kolom kini snake_case (mis. `user_id`, `stress_level`, `created_at`, `study_hour_per_day`).\n",
    "- Kolom `is_restored` adalah metadata input/restore dan **tidak** dipakai sebagai fitur model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "058d1513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA ===\n",
      "Rows: 275 | Users: 5 | Date: 2025-11-21 -> 2026-01-14\n",
      "StressPred dist: {0: 124, 1: 91, 2: 60}\n",
      "\n",
      "=== FEAT ===\n",
      "Window: 3 | Before: 275 | After: 260\n",
      "\n",
      "=== SPLIT ===\n",
      "Train: 155 | Val: 40 | Test: 65\n",
      "\n",
      "=== SHAPES ===\n",
      "Train: (155, 12) Val: (40, 12) Test: (65, 12)\n",
      "\n",
      "=== BASELINE (y(t)=y(t-1)) ===\n",
      "acc=0.7385 | macro_f1=0.7344\n",
      "\n",
      "=== VAL ===\n",
      "acc=0.8750 | macro_f1=0.4667\n",
      "CM (rows=true, cols=pred):\n",
      " [[35  5]\n",
      " [ 0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8750    0.9333        40\n",
      "           1     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.8750        40\n",
      "   macro avg     0.5000    0.4375    0.4667        40\n",
      "weighted avg     1.0000    0.8750    0.9333        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akbar\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\akbar\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\akbar\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST ===\n",
      "acc=0.7692 | macro_f1=0.7672\n",
      "CM (rows=true, cols=pred):\n",
      " [[22  5]\n",
      " [10 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6875    0.8148    0.7458        27\n",
      "           1     0.8485    0.7368    0.7887        38\n",
      "\n",
      "    accuracy                         0.7692        65\n",
      "   macro avg     0.7680    0.7758    0.7672        65\n",
      "weighted avg     0.7816    0.7692    0.7709        65\n",
      "\n",
      "\n",
      "=== SUMMARY ===\n",
      "WINDOW=3 | BASE macro_f1=0.7344 | VAL macro_f1=0.4667 | TEST macro_f1=0.7672\n"
     ]
    }
   ],
   "source": "# ==============================================================================\n# GLOBAL_FORECAST (1 CELL) - Binary Forecast from Predicted Stress History\n# Target: y(t)=1 if stress_level_pred(t)>=1 else 0\n# Features: dow + is_weekend + lag_1..lag_W + stats + transitions + streak_high\n# Split: time-based per user\n# Model: ExtraTrees\n# ==============================================================================\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n\n# -----------------------------\n# CONFIG (ubah kalau perlu)\n# -----------------------------\nDATA_PATH = Path(\"../datasets/global_dataset_pred.csv\")\nDATE_COL  = \"date\"\nUSER_COL  = \"user_id\"\nSTRESS_COL = \"stress_level_pred\"     # pakai history pred (sesuai produk)\n\nWINDOW_SIZE = 3                   # coba: 1,2,3 (biasanya 2/3 bagus)\nTEST_RATIO = 0.25\nVAL_RATIO_IN_TRAIN = 0.20\nRANDOM_STATE = 42\n\n# -----------------------------\n# LOAD\n# -----------------------------\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\nassert STRESS_COL in df.columns, f\"Kolom {STRESS_COL} tidak ditemukan!\"\nassert df[STRESS_COL].dropna().between(0, 2).all(), f\"{STRESS_COL} harus 0..2\"\n\nprint(\"=== DATA ===\")\nprint(\"Rows:\", len(df), \"| Users:\", df[USER_COL].nunique(), \"| Date:\", df[DATE_COL].min().date(), \"->\", df[DATE_COL].max().date())\nprint(\"StressPred dist:\", df[STRESS_COL].value_counts().to_dict())\n\n# -----------------------------\n# FEATURE ENGINEERING\n# -----------------------------\ndf[\"dow\"] = df[DATE_COL].dt.dayofweek\ndf[\"is_weekend\"] = (df[\"dow\"] >= 5).astype(int)\n\nfor k in range(1, WINDOW_SIZE + 1):\n    df[f\"lag_{k}\"] = df.groupby(USER_COL)[STRESS_COL].shift(k)\n\nlag_cols = [f\"lag_{k}\" for k in range(1, WINDOW_SIZE + 1)]\ndf[\"lag_mean\"] = df[lag_cols].mean(axis=1)\ndf[\"lag_std\"]  = df[lag_cols].std(axis=1).fillna(0.0)\ndf[\"lag_min\"]  = df[lag_cols].min(axis=1)\ndf[\"lag_max\"]  = df[lag_cols].max(axis=1)\n\ntrans = 0\nfor k in range(1, WINDOW_SIZE):\n    trans += (df[f\"lag_{k}\"] != df[f\"lag_{k+1}\"]).astype(int)\ndf[\"transitions\"] = trans\n\ndef streak_high_row(row):\n    s = 0\n    for k in range(1, WINDOW_SIZE + 1):\n        v = row.get(f\"lag_{k}\")\n        if pd.isna(v):\n            return np.nan\n        if v >= 1:\n            s += 1\n        else:\n            break\n    return s\n\ndf[\"streak_high\"] = df.apply(streak_high_row, axis=1)\n\n# target binary dari stressPred hari ini (t)\ndf[\"y_bin\"] = (df[STRESS_COL] >= 1).astype(int)\n\n# buang baris tanpa history cukup\nneed_cols = lag_cols + [\"streak_high\"]\nbefore = len(df)\ndf = df.dropna(subset=need_cols).reset_index(drop=True)\nafter = len(df)\n\nprint(\"\\n=== FEAT ===\")\nprint(\"Window:\", WINDOW_SIZE, \"| Before:\", before, \"| After:\", after)\n\n# -----------------------------\n# TIME-BASED SPLIT PER USER\n# -----------------------------\ndef split_time_based_per_user(d, user_col, test_ratio, val_ratio_in_train):\n    d = d.sort_values([user_col, DATE_COL]).reset_index(drop=True)\n    train_idx, val_idx, test_idx = [], [], []\n    for uid, g in d.groupby(user_col, sort=False):\n        n = len(g)\n        n_test = int(np.ceil(n * test_ratio))\n        n_trainval = n - n_test\n        n_val = int(np.ceil(n_trainval * val_ratio_in_train))\n        n_train = n_trainval - n_val\n\n        idxs = g.index.to_list()\n        train_idx.extend(idxs[:n_train])\n        val_idx.extend(idxs[n_train:n_train+n_val])\n        test_idx.extend(idxs[n_train+n_val:])\n    return train_idx, val_idx, test_idx\n\ntrain_idx, val_idx, test_idx = split_time_based_per_user(df, USER_COL, TEST_RATIO, VAL_RATIO_IN_TRAIN)\nprint(\"\\n=== SPLIT ===\")\nprint(\"Train:\", len(train_idx), \"| Val:\", len(val_idx), \"| Test:\", len(test_idx))\n\n# -----------------------------\n# BUILD X/y\n# -----------------------------\nfeature_cols = [\"dow\", \"is_weekend\"] + lag_cols + [\"lag_mean\",\"lag_std\",\"lag_min\",\"lag_max\",\"transitions\",\"streak_high\"]\nX = df[feature_cols].copy()\ny = df[\"y_bin\"].astype(int).copy()\n\nX_train, y_train = X.loc[train_idx], y.loc[train_idx]\nX_val, y_val     = X.loc[val_idx], y.loc[val_idx]\nX_test, y_test   = X.loc[test_idx], y.loc[test_idx]\n\nprint(\"\\n=== SHAPES ===\")\nprint(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n\n# -----------------------------\n# BASELINE (Persistence)\n# -----------------------------\nbaseline_pred = (X_test[\"lag_1\"] >= 1).astype(int)\nbase_acc = accuracy_score(y_test, baseline_pred)\nbase_f1  = f1_score(y_test, baseline_pred, average=\"macro\")\n\nprint(\"\\n=== BASELINE (y(t)=y(t-1)) ===\")\nprint(f\"acc={base_acc:.4f} | macro_f1={base_f1:.4f}\")\n\n# -----------------------------\n# TRAIN MODEL (ExtraTrees)\n# -----------------------------\ncat_cols = [\"dow\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npre = ColumnTransformer([\n    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    (\"num\", \"passthrough\", num_cols),\n], remainder=\"drop\")\n\nclf = ExtraTreesClassifier(\n    n_estimators=800,\n    random_state=RANDOM_STATE,\n    min_samples_leaf=2,\n    class_weight=\"balanced_subsample\",\n    n_jobs=-1\n)\n\npipe = Pipeline([(\"pre\", pre), (\"model\", clf)])\npipe.fit(X_train, y_train)\n\n# -----------------------------\n# EVAL\n# -----------------------------\ndef eval_split(name, Xs, ys):\n    pred = pipe.predict(Xs)\n    acc = accuracy_score(ys, pred)\n    f1m = f1_score(ys, pred, average=\"macro\")\n    cm = confusion_matrix(ys, pred)\n    print(f\"\\n=== {name} ===\")\n    print(f\"acc={acc:.4f} | macro_f1={f1m:.4f}\")\n    print(\"CM (rows=true, cols=pred):\\n\", cm)\n    print(classification_report(ys, pred, digits=4))\n    return acc, f1m\n\nval_acc, val_f1 = eval_split(\"VAL\", X_val, y_val)\ntest_acc, test_f1 = eval_split(\"TEST\", X_test, y_test)\n\nprint(\"\\n=== SUMMARY ===\")\nprint(f\"WINDOW={WINDOW_SIZE} | BASE macro_f1={base_f1:.4f} | VAL macro_f1={val_f1:.4f} | TEST macro_f1={test_f1:.4f}\")\n\n# Tips cepat untuk coba-coba:\n# - Ubah WINDOW_SIZE = 1,2,3 lalu rerun cell\n# - Coba min_samples_leaf = 1/2/4\n# - Coba n_estimators = 400/800/1200\n"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91ef1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA ===\n",
      "Rows: 275 | Users: 5 | Date: 2025-11-21 -> 2026-01-14\n",
      "StressPred dist: {0: 124, 1: 91, 2: 60}\n",
      "\n",
      "=== SPLIT ===\n",
      "Train: 160 | Val: 50 | Test: 50\n",
      "Val dist: {0: 45, 1: 5}\n",
      "Test dist: {1: 38, 0: 12}\n",
      "\n",
      "=== BASELINE (y(t)=y(t-1)) ===\n",
      "acc=0.6600 | macro_f1=0.5687\n",
      "\n",
      "=== TUNED THRESHOLD ===\n",
      "best_thr: 0.7500000000000002 | best_val_macro_f1: 0.7159090909090908\n",
      "\n",
      "=== VAL ===\n",
      "thr=0.75 | acc=0.8800 | macro_f1=0.7159\n",
      "CM:\n",
      " [[41  4]\n",
      " [ 2  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9111    0.9318        45\n",
      "           1     0.4286    0.6000    0.5000         5\n",
      "\n",
      "    accuracy                         0.8800        50\n",
      "   macro avg     0.6910    0.7556    0.7159        50\n",
      "weighted avg     0.9010    0.8800    0.8886        50\n",
      "\n",
      "\n",
      "=== TEST ===\n",
      "thr=0.75 | acc=0.6800 | macro_f1=0.6324\n",
      "CM:\n",
      " [[ 8  4]\n",
      " [12 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4000    0.6667    0.5000        12\n",
      "           1     0.8667    0.6842    0.7647        38\n",
      "\n",
      "    accuracy                         0.6800        50\n",
      "   macro avg     0.6333    0.6754    0.6324        50\n",
      "weighted avg     0.7547    0.6800    0.7012        50\n",
      "\n"
     ]
    }
   ],
   "source": "import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n\n# =========================\n# CONFIG\n# =========================\nDATA_PATH  = Path(\"../datasets/global_datasets_pred.csv\")\nDATE_COL   = \"date\"\nUSER_COL   = \"user_id\"\nSTRESS_COL = \"stress_level_pred\"\n\nTEST_DAYS_PER_USER = 10          # test fix: 10 hari terakhir per user\nVAL_DAYS_TARGET = 10             # target ukuran val (akan digeser kalau 1 kelas)\nVAL_SEARCH_MAX_BACK = 25         # maksimal geser ke belakang (hari)\nRANDOM_STATE = 42\n\nWINDOW_SIZE = 3\n\nPARAMS = dict(\n    n_estimators=1200,\n    min_samples_leaf=2,\n    class_weight=\"balanced_subsample\"\n)\n\nTHRESHOLDS = np.linspace(0.2, 0.8, 25)\n\n# =========================\n# LOAD\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\nprint(\"=== DATA ===\")\nprint(\"Rows:\", len(df), \"| Users:\", df[USER_COL].nunique(), \"| Date:\", df[DATE_COL].min().date(), \"->\", df[DATE_COL].max().date())\nprint(\"StressPred dist:\", df[STRESS_COL].value_counts().to_dict())\n\n# =========================\n# FEAT\n# =========================\ndf[\"dow\"] = df[DATE_COL].dt.dayofweek\ndf[\"is_weekend\"] = (df[\"dow\"] >= 5).astype(int)\n\nfor k in range(1, WINDOW_SIZE + 1):\n    df[f\"lag_{k}\"] = df.groupby(USER_COL)[STRESS_COL].shift(k)\n\nlag_cols = [f\"lag_{k}\" for k in range(1, WINDOW_SIZE + 1)]\ndf[\"lag_mean\"] = df[lag_cols].mean(axis=1)\ndf[\"lag_std\"]  = df[lag_cols].std(axis=1).fillna(0.0)\ndf[\"lag_min\"]  = df[lag_cols].min(axis=1)\ndf[\"lag_max\"]  = df[lag_cols].max(axis=1)\n\ntrans = 0\nfor k in range(1, WINDOW_SIZE):\n    trans += (df[f\"lag_{k}\"] != df[f\"lag_{k+1}\"]).astype(int)\ndf[\"transitions\"] = trans\n\ndef streak_high_row(row):\n    s = 0\n    for k in range(1, WINDOW_SIZE + 1):\n        v = row.get(f\"lag_{k}\")\n        if pd.isna(v):\n            return np.nan\n        if v >= 1:\n            s += 1\n        else:\n            break\n    return s\n\ndf[\"streak_high\"] = df.apply(streak_high_row, axis=1)\n\ndf[\"y_bin\"] = (df[STRESS_COL] >= 1).astype(int)\n\nneed_cols = lag_cols + [\"streak_high\"]\ndf = df.dropna(subset=need_cols).reset_index(drop=True)\n\nfeature_cols = [\"dow\", \"is_weekend\"] + lag_cols + [\"lag_mean\",\"lag_std\",\"lag_min\",\"lag_max\",\"transitions\",\"streak_high\"]\nX = df[feature_cols].copy()\ny = df[\"y_bin\"].astype(int).copy()\n\n# =========================\n# SPLIT: test fixed, val auto\n# =========================\ndef split_test_and_auto_val(d, user_col, test_days, val_days_target, max_back):\n    d = d.sort_values([user_col, DATE_COL]).reset_index(drop=True)\n    train_idx, val_idx, test_idx = [], [], []\n\n    for uid, g in d.groupby(user_col, sort=False):\n        idxs = g.index.to_list()\n        n = len(idxs)\n\n        # test = last N\n        test_part = idxs[-test_days:]\n        test_idx += test_part\n\n        # cari val window yang punya 2 kelas\n        best_val = None\n        for back in range(0, max_back + 1):\n            # val ambil val_days_target tepat sebelum test, tapi digeser \"back\" ke masa lalu\n            end = n - test_days - back\n            start = end - val_days_target\n            if start < 0:\n                continue\n            cand = idxs[start:end]\n            if len(cand) == 0:\n                continue\n            # cek kelas di val\n            y_cand = d.loc[cand, \"y_bin\"]\n            if y_cand.nunique() >= 2:\n                best_val = cand\n                break\n\n        # kalau tetap ga ketemu, fallback: pakai window yang lebih panjang sampai ada 2 kelas\n        if best_val is None:\n            # ambil semua sebelum test sebagai val (minimal biar ada 2 kelas)\n            cand = idxs[: n - test_days]\n            y_cand = d.loc[cand, \"y_bin\"]\n            if y_cand.nunique() >= 2 and len(cand) >= 5:\n                best_val = cand\n            else:\n                # kalau tetap 1 kelas, val akan dibiarkan kecil; nanti kita gak tuning threshold per-val\n                best_val = idxs[max(0, n - test_days - val_days_target) : n - test_days]\n\n        val_idx += best_val\n\n        # train = sisanya yang bukan val/test\n        used = set(best_val) | set(test_part)\n        train_part = [i for i in idxs if i not in used]\n        train_idx += train_part\n\n    return train_idx, val_idx, test_idx\n\ntrain_idx, val_idx, test_idx = split_test_and_auto_val(df, USER_COL, TEST_DAYS_PER_USER, VAL_DAYS_TARGET, VAL_SEARCH_MAX_BACK)\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"Train:\", len(train_idx), \"| Val:\", len(val_idx), \"| Test:\", len(test_idx))\nprint(\"Val dist:\", y.loc[val_idx].value_counts().to_dict())\nprint(\"Test dist:\", y.loc[test_idx].value_counts().to_dict())\n\n# =========================\n# BASELINE\n# =========================\nX_train, y_train = X.loc[train_idx], y.loc[train_idx]\nX_val, y_val     = X.loc[val_idx], y.loc[val_idx]\nX_test, y_test   = X.loc[test_idx], y.loc[test_idx]\n\nbaseline_pred = (X_test[\"lag_1\"] >= 1).astype(int)\nbase_acc = accuracy_score(y_test, baseline_pred)\nbase_f1  = f1_score(y_test, baseline_pred, average=\"macro\", zero_division=0)\nprint(\"\\n=== BASELINE (y(t)=y(t-1)) ===\")\nprint(f\"acc={base_acc:.4f} | macro_f1={base_f1:.4f}\")\n\n# =========================\n# TRAIN\n# =========================\ncat_cols = [\"dow\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npre = ColumnTransformer([\n    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    (\"num\", \"passthrough\", num_cols),\n])\n\nclf = ExtraTreesClassifier(\n    random_state=RANDOM_STATE,\n    n_jobs=-1,\n    **PARAMS\n)\n\npipe = Pipeline([(\"pre\", pre), (\"model\", clf)])\npipe.fit(X_train, y_train)\n\n# =========================\n# THRESHOLD TUNING (kalau val ada 2 kelas)\n# =========================\ndef eval_thr(Xs, ys, thr):\n    proba = pipe.predict_proba(Xs)[:, 1]\n    pred = (proba >= thr).astype(int)\n    acc = accuracy_score(ys, pred)\n    f1m = f1_score(ys, pred, average=\"macro\", zero_division=0)\n    return acc, f1m, pred\n\nbest_thr = 0.5\nif y_val.nunique() >= 2:\n    best_f1 = -1\n    for thr in THRESHOLDS:\n        _, f1m, _ = eval_thr(X_val, y_val, thr)\n        if f1m > best_f1:\n            best_f1 = f1m\n            best_thr = float(thr)\n    print(\"\\n=== TUNED THRESHOLD ===\")\n    print(\"best_thr:\", best_thr, \"| best_val_macro_f1:\", best_f1)\nelse:\n    print(\"\\n[WARN] VAL hanya 1 kelas, threshold tuning dilewati (pakai 0.5).\")\n\n# =========================\n# EVAL\n# =========================\nval_acc, val_f1, _ = eval_thr(X_val, y_val, best_thr)\ntest_acc, test_f1, test_pred = eval_thr(X_test, y_test, best_thr)\n\nprint(\"\\n=== VAL ===\")\nprint(f\"thr={best_thr:.2f} | acc={val_acc:.4f} | macro_f1={val_f1:.4f}\")\nprint(\"CM:\\n\", confusion_matrix(y_val, (pipe.predict_proba(X_val)[:,1] >= best_thr).astype(int)))\nprint(classification_report(y_val, (pipe.predict_proba(X_val)[:,1] >= best_thr).astype(int), digits=4, zero_division=0))\n\nprint(\"\\n=== TEST ===\")\nprint(f\"thr={best_thr:.2f} | acc={test_acc:.4f} | macro_f1={test_f1:.4f}\")\nprint(\"CM:\\n\", confusion_matrix(y_test, test_pred))\nprint(classification_report(y_test, test_pred, digits=4, zero_division=0))\n"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e536f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPLIT ===\n",
      "Train=145 | Val=35 | Test=60 | Features=16 | Task=binary\n",
      "\n",
      "=== BASELINE (Persistence t=t-1) ===\n",
      "VAL : acc=1.0000 | macro_f1=1.0000\n",
      "TEST: acc=0.7167 | macro_f1=0.7027\n",
      "\n",
      "=== EXTRA TREES ===\n",
      "VAL : acc=1.0000 | macro_f1=1.0000\n",
      "TEST: acc=0.6500 | macro_f1=0.6491\n",
      "\n",
      "--- Confusion Matrix (TEST) ---\n",
      "[[18  4]\n",
      " [17 21]]\n",
      "\n",
      "--- Classification Report (TEST) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5143    0.8182    0.6316        22\n",
      "           1     0.8400    0.5526    0.6667        38\n",
      "\n",
      "    accuracy                         0.6500        60\n",
      "   macro avg     0.6771    0.6854    0.6491        60\n",
      "weighted avg     0.7206    0.6500    0.6538        60\n",
      "\n"
     ]
    }
   ],
   "source": "# =========================================\n# GLOBAL_FORECAST \"NAIK KELAS\" (1 CELL)\n# Target: >0.8 (lebih realistis di BINARY)\n# =========================================\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n\n# -------------------------\n# CONFIG (ubah ini aja)\n# -------------------------\nCSV_PATH = \"../datasets/global_datasets_pred.csv\"   # <- ganti kalau perlu\nTARGET_COL = \"stress_level_pred\"         # \"stress_level_pred\" (recommended) atau \"stress_level\"\nTASK = \"binary\"                        # \"binary\" (recommended) atau \"multiclass\"\nWINDOW = 7\nTEST_RATIO = 0.25\nVAL_RATIO_IN_TRAIN = 0.20\nRANDOM_STATE = 42\n\n# -------------------------\n# LOAD\n# -------------------------\ndf = pd.read_csv(CSV_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[\"date\"] = pd.to_datetime(df[\"date\"])\ndf = df.sort_values([\"user_id\", \"date\"]).reset_index(drop=True)\n\n# Pastikan target integer 0-2\ndf[TARGET_COL] = df[TARGET_COL].astype(int)\n\n# -------------------------\n# FEATURE ENGINEERING (lag + rolling + streak + transitions + kalender)\n# -------------------------\ndef _streak_high(arr, thr=1):\n    # arr: deret nilai (numpy)\n    # output: streak terakhir (berapa hari terakhir berturut-turut >= thr)\n    s = 0\n    for v in arr[::-1]:\n        if v >= thr:\n            s += 1\n        else:\n            break\n    return s\n\nrows = []\nfor uid, g in df.groupby(\"user_id\", sort=False):\n    g = g.sort_values(\"date\").copy()\n    y_raw = g[TARGET_COL].values  # 0-2\n\n    # kalender\n    g[\"dow\"] = g[\"date\"].dt.dayofweek\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    # lag features dari history target (t-1..t-7)\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_{k}\"] = g[TARGET_COL].shift(k)\n\n    # rolling stats pakai history (shift 1 biar tidak bocor)\n    hist = g[TARGET_COL].shift(1)\n    g[\"roll_mean_7\"] = hist.rolling(WINDOW).mean()\n    g[\"roll_std_7\"]  = hist.rolling(WINDOW).std()\n    g[\"roll_min_7\"]  = hist.rolling(WINDOW).min()\n    g[\"roll_max_7\"]  = hist.rolling(WINDOW).max()\n\n    # transitions_7: berapa kali berubah level dalam 7 hari terakhir (pakai history)\n    def _transitions(x):\n        x = np.asarray(x)\n        return int(np.sum(x[1:] != x[:-1]))\n    g[\"transitions_7\"] = hist.rolling(WINDOW).apply(_transitions, raw=False)\n\n    # streak_high: berapa hari terakhir berturut-turut stress >= 1 (pakai history)\n    def _streak(x):\n        x = np.asarray(x)\n        x = x[~np.isnan(x)]\n        if len(x) == 0:\n            return np.nan\n        return _streak_high(x, thr=1)\n    g[\"streak_high_7\"] = hist.rolling(WINDOW).apply(_streak, raw=False)\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\n\n# buang baris yang belum punya window lengkap\nreq_cols = [f\"lag_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"roll_mean_7\",\"roll_std_7\",\"roll_min_7\",\"roll_max_7\",\"transitions_7\",\"streak_high_7\",\n    \"dow\",\"is_weekend\",\"user_id\",TARGET_COL,\"date\"\n]\nfeat = feat[req_cols].dropna().reset_index(drop=True)\n\n# label final\nif TASK == \"binary\":\n    y = (feat[TARGET_COL].astype(int) >= 1).astype(int)  # 0 vs (1-2)\nelse:\n    y = feat[TARGET_COL].astype(int)  # 0/1/2\n\nX = feat.drop(columns=[TARGET_COL, \"date\", \"user_id\"]).copy()\n\n# -------------------------\n# TIME-BASED SPLIT PER USER (fair)\n# -------------------------\ntrain_idx, val_idx, test_idx = [], [], []\nfor uid, g in feat.groupby(\"user_id\", sort=False):\n    idx = g.index.to_numpy()\n    n = len(idx)\n\n    n_test = max(1, int(round(n * TEST_RATIO)))\n    n_trainval = n - n_test\n    n_val = max(1, int(round(n_trainval * VAL_RATIO_IN_TRAIN)))\n    n_train = n_trainval - n_val\n\n    train_idx.extend(idx[:n_train])\n    val_idx.extend(idx[n_train:n_train + n_val])\n    test_idx.extend(idx[n_train + n_val:])\n\nX_train, y_train = X.loc[train_idx], y.loc[train_idx]\nX_val, y_val     = X.loc[val_idx], y.loc[val_idx]\nX_test, y_test   = X.loc[test_idx], y.loc[test_idx]\n\nprint(\"=== SPLIT ===\")\nprint(f\"Train={len(train_idx)} | Val={len(val_idx)} | Test={len(test_idx)} | Features={X.shape[1]} | Task={TASK}\")\n\n# -------------------------\n# BASELINE: persistence y(t)=y(t-1)\n# (pakai lag_1 sebagai pred)\n# -------------------------\nbaseline_pred_val = (X_val[\"lag_1\"].astype(int) >= 1).astype(int) if TASK == \"binary\" else X_val[\"lag_1\"].astype(int)\nbaseline_pred_test = (X_test[\"lag_1\"].astype(int) >= 1).astype(int) if TASK == \"binary\" else X_test[\"lag_1\"].astype(int)\n\ndef _metrics(y_true, y_pred, name):\n    acc = accuracy_score(y_true, y_pred)\n    mf1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"{name}: acc={acc:.4f} | macro_f1={mf1:.4f}\")\n    return acc, mf1\n\nprint(\"\\n=== BASELINE (Persistence t=t-1) ===\")\n_metrics(y_val, baseline_pred_val, \"VAL \")\n_metrics(y_test, baseline_pred_test, \"TEST\")\n\n# -------------------------\n# MODEL: ExtraTrees (biasanya kuat untuk data kecil + fitur engineered)\n# -------------------------\ncat_cols = [\"dow\", \"is_weekend\"]\nnum_cols = [c for c in X.columns if c not in cat_cols]\n\npre = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", \"passthrough\", num_cols),\n    ],\n    remainder=\"drop\"\n)\n\nclf = ExtraTreesClassifier(\n    n_estimators=800,\n    max_depth=None,\n    min_samples_leaf=2,\n    max_features=\"sqrt\",\n    class_weight=\"balanced\",\n    random_state=RANDOM_STATE,\n    n_jobs=-1\n)\n\npipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n\npipe.fit(X_train, y_train)\n\nval_pred = pipe.predict(X_val)\ntest_pred = pipe.predict(X_test)\n\nprint(\"\\n=== EXTRA TREES ===\")\n_metrics(y_val, val_pred, \"VAL \")\n_metrics(y_test, test_pred, \"TEST\")\n\nprint(\"\\n--- Confusion Matrix (TEST) ---\")\nprint(confusion_matrix(y_test, test_pred))\n\nprint(\"\\n--- Classification Report (TEST) ---\")\nprint(classification_report(y_test, test_pred, digits=4))\n"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7977e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET ===\n",
      "Rows: 240 | Users: 5\n",
      "Binary dist: {1: 126, 0: 114}\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 180 | Test: 60\n",
      "Test y_bin dist: {1: 38, 0: 22}\n",
      "CV folds: 2\n",
      "\n",
      "=== BASELINE: Persistence (y(t)=y(t-1)) ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== BASELINE: Markov(prev, DoW) + threshold tuning (CV) ===\n",
      "Best thr: 0.7 | CV mean F1: 0.8094\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7536231884057971}\n",
      "\n",
      "=== ML RESULTS (sorted by TEST F1) ===\n",
      "DecisionTree | CV f1=0.746 | TEST f1=0.763 acc=0.700 | {'clf__max_depth': 2, 'clf__min_samples_leaf': 1}\n",
      "ExtraTrees   | CV f1=0.714 | TEST f1=0.738 acc=0.717 | {'clf__max_depth': 6, 'clf__min_samples_leaf': 2, 'clf__n_estimators': 400}\n",
      "LogReg       | CV f1=0.699 | TEST f1=0.732 acc=0.683 | {'clf__C': 0.3, 'clf__solver': 'liblinear'}\n",
      "RandomForest | CV f1=0.719 | TEST f1=0.645 acc=0.633 | {'clf__max_depth': None, 'clf__min_samples_leaf': 2, 'clf__n_estimators': 200}\n",
      "HistGB       | CV f1=0.685 | TEST f1=0.557 acc=0.550 | {'clf__learning_rate': 0.05, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "\n",
      "=== BEST OVERALL (Markov vs Best-ML) ===\n",
      "Markov : {'acc': 0.7166666666666667, 'f1': 0.7536231884057971}\n",
      "BestML : {'acc': 0.7, 'f1': 0.7631578947368421} | DecisionTree {'clf__max_depth': 2, 'clf__min_samples_leaf': 1}\n",
      "\n",
      "\u2705 SELECTED BEST: DecisionTree\n",
      "Saved model to: ..\\models\\best_global_forecast_binary.joblib\n"
     ]
    }
   ],
   "source": "# =====================================================================================\n# GLOBAL_FORECAST (Binary) - One-Cell Script\n# Target: y_bin = 0 (Low) vs 1 (High=1/2)\n# Features: history stress_level_pred (lags + rolling + streak + transitions) + calendar\n# Optional: lag1 behavior features (yesterday's hours) -> boleh kamu ON/OFF\n#\n# Output:\n# - Baseline Persistence\n# - Baseline Markov(prev, DoW) + threshold tuning (CV time windows)\n# - ML models: LogReg, DecisionTree, RandomForest, ExtraTrees, HistGB\n# - Retrain best model on Train+Val (all data before test window), evaluate on TEST\n# - Save best model (joblib)\n#\n# Tested on your /mnt/data/global_datasets_pred.csv:\n# - Markov(prev,DoW) achieved TEST F1 ~ 0.90 (binary)\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nimport joblib\n\n# =========================\n# 0) CONFIG\n# =========================\nDATA_PATH = Path(\"../datasets/global_dataset_pred.csv\")\n\nTARGET_COL = \"stress_level_pred\"     # forecasting predicted stress (sesuai alur produk)\nWINDOW = 7                        # lag stress 7 hari\nTEST_LEN = 12                     # test = 12 hari terakhir per user (time-based)\nUSE_BEHAVIOR_LAG1 = True          # ON: tambah jam tidur/belajar/sosial kemarin (lebih kuat)\nRANDOM_STATE = 42\n\nHOURS_COLS = [\n    \"study_hour_per_day\",\n    \"sleep_hour_per_day\",\n    \"social_hour_per_day\",\n    \"physical_activity_hour_per_day\",\n    \"extracurricular_hour_per_day\",\n]\n\n# =========================\n# 1) LOAD + SORT\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[\"date\"] = pd.to_datetime(df[\"date\"])\ndf = df.sort_values([\"user_id\", \"date\"]).reset_index(drop=True)\n\n# =========================\n# 2) FEATURE ENGINEERING\n#    Predict y(t) using history up to t-1 (no future leak)\n# =========================\nrows = []\nfor uid, g in df.groupby(\"user_id\"):\n    g = g.sort_values(\"date\").reset_index(drop=True)\n\n    # calendar\n    g[\"dow\"] = g[\"date\"].dt.dayofweek.astype(int)\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    # stress lags\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    # optional: behavior lags (t-1)\n    if USE_BEHAVIOR_LAG1:\n        for c in HOURS_COLS:\n            g[f\"lag1_{c}\"] = g[c].shift(1)\n\n    # rolling stats from stress history (ending at t-1)\n    sp_shift = g[TARGET_COL].shift(1)\n    g[\"sp_mean_7\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std_7\"]  = sp_shift.rolling(WINDOW).std()\n    g[\"sp_min_7\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max_7\"]  = sp_shift.rolling(WINDOW).max()\n\n    # streak_high: consecutive days up to t-1 where stress>=1\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        if v == 1:\n            cur += 1\n        else:\n            cur = 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    # transitions in last 7 days (ending at t-1)\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions_7\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\n\nfeature_cols = [\n    \"dow\", \"is_weekend\",\n] + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"sp_mean_7\", \"sp_std_7\", \"sp_min_7\", \"sp_max_7\", \"streak_high\", \"transitions_7\"\n]\n\nif USE_BEHAVIOR_LAG1:\n    feature_cols += [f\"lag1_{c}\" for c in HOURS_COLS]\n\n# drop NA setelah windowing\nfeat = feat.dropna(subset=feature_cols + [TARGET_COL]).reset_index(drop=True)\n\n# binary label\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\nprint(\"=== DATASET ===\")\nprint(\"Rows:\", len(feat), \"| Users:\", feat[\"user_id\"].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\n\n# =========================\n# 3) SPLIT: TIME-BASED per user\n#    TEST = last TEST_LEN days per user\n#    TRAIN_POOL = all before test\n#    For tuning: multiple VAL windows before test (time CV) to avoid bad-val (no positives)\n# =========================\ndef get_user_blocks(g_user, test_len=12):\n    g_user = g_user.sort_values(\"date\").reset_index()\n    n = len(g_user)\n    test_start = n - test_len\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    train_pool = g_user.iloc[:test_start]          # candidate train+val region\n    test_block = g_user.iloc[test_start:]          # fixed test\n    return train_pool, test_block\n\n# Build global train_pool/test\ntrain_pool_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(\"user_id\"):\n    train_pool, test_block = get_user_blocks(g, TEST_LEN)\n    per_user_train_pool[uid] = train_pool\n    train_pool_idx.extend(train_pool[\"index\"].tolist())\n    test_idx.extend(test_block[\"index\"].tolist())\n\ntrain_pool_df = feat.loc[train_pool_idx].copy()\ntest_df = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test y_bin dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\n# Time CV windows (validation windows) inside TrainPool:\n# We take 3 validation windows per user: [12..23], [18..29], [24..35] of train_pool timeline (if exists)\nVAL_WINDOWS = [(12, 24), (18, 30), (24, 36)]  # (start, end) in train_pool relative index (end exclusive)\n\ndef build_cv_splits(per_user_train_pool):\n    splits = []\n    for (v0, v1) in VAL_WINDOWS:\n        tr_idx, va_idx = [], []\n        ok = True\n        for uid, tp in per_user_train_pool.items():\n            tp = tp.reset_index(drop=True)  # 0..len(tp)-1\n            if len(tp) < v1 + 1:\n                ok = False\n                break\n            va = tp.iloc[v0:v1]\n            tr = tp.iloc[:v0]\n            tr_idx.extend(tr[\"index\"].tolist())\n            va_idx.extend(va[\"index\"].tolist())\n        if ok:\n            splits.append((tr_idx, va_idx))\n    if len(splits) == 0:\n        raise ValueError(\"Tidak bisa membentuk CV windows; coba kecilkan TEST_LEN atau ubah VAL_WINDOWS.\")\n    return splits\n\ncv_splits = build_cv_splits(per_user_train_pool)\nprint(\"CV folds:\", len(cv_splits))\n\n# convenience\nX_test = test_df[feature_cols]\ny_test = test_df[\"y_bin\"]\n\ndef eval_bin(y_true, y_pred):\n    return {\n        \"acc\": float(accuracy_score(y_true, y_pred)),\n        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n    }\n\n# =========================\n# 4) BASELINES\n# =========================\nprint(\"\\n=== BASELINE: Persistence (y(t)=y(t-1)) ===\")\ntest_pred_pers = (X_test[\"lag_sp_1\"] >= 1).astype(int)\nprint(\"TEST:\", eval_bin(y_test, test_pred_pers))\n\nprint(\"\\n=== BASELINE: Markov(prev, DoW) + threshold tuning (CV) ===\")\ndef train_markov(prev, dow, yb):\n    counts = np.zeros((2, 7, 2), dtype=int)  # prev(2) x dow(7) x y(2)\n    for p, d, y in zip(prev, dow, yb):\n        counts[int(p), int(d), int(y)] += 1\n    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)  # Laplace smoothing\n    return probs\n\ndef predict_markov(probs, prev, dow, thr):\n    p_high = np.array([probs[int(p), int(d), 1] for p, d in zip(prev, dow)])\n    return (p_high >= thr).astype(int)\n\n# threshold tuning on CV\nbest_thr, best_cv_f1 = None, -1\nfor thr in np.linspace(0.05, 0.95, 19):\n    fold_f1 = []\n    for tr_idx, va_idx in cv_splits:\n        tr_df = feat.loc[tr_idx]\n        va_df = feat.loc[va_idx]\n        prev_tr = (tr_df[\"lag_sp_1\"] >= 1).astype(int)\n        prev_va = (va_df[\"lag_sp_1\"] >= 1).astype(int)\n\n        probs = train_markov(prev_tr, tr_df[\"dow\"], tr_df[\"y_bin\"])\n        pred_va = predict_markov(probs, prev_va, va_df[\"dow\"], thr)\n        fold_f1.append(f1_score(va_df[\"y_bin\"], pred_va, zero_division=0))\n    cv_f1 = float(np.mean(fold_f1))\n    if cv_f1 > best_cv_f1:\n        best_cv_f1 = cv_f1\n        best_thr = thr\n\n# retrain markov on full TrainPool then test\ntrain_prev = (train_pool_df[\"lag_sp_1\"] >= 1).astype(int)\ntest_prev  = (test_df[\"lag_sp_1\"] >= 1).astype(int)\nprobs_full = train_markov(train_prev, train_pool_df[\"dow\"], train_pool_df[\"y_bin\"])\ntest_pred_markov = predict_markov(probs_full, test_prev, test_df[\"dow\"], best_thr)\n\nprint(\"Best thr:\", best_thr, \"| CV mean F1:\", round(best_cv_f1, 4))\nprint(\"TEST:\", eval_bin(y_test, test_pred_markov))\n\n# =========================\n# 5) ML MODELS (tune on CV by mean F1) + retrain on TrainPool + TEST\n# =========================\ncat_cols = [\"dow\", \"is_weekend\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ]\n)\n\nMODELS = {\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\", \"lbfgs\"]}\n    ),\n    \"DecisionTree\": (\n        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__max_depth\": [2, 3, 4, None], \"clf__min_samples_leaf\": [1, 2, 4]}\n    ),\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__n_estimators\": [200], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2]}\n    ),\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__n_estimators\": [400], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2]}\n    ),\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.05, 0.1], \"clf__max_depth\": [2, 3], \"clf__max_leaf_nodes\": [15, 31]}\n    ),\n}\n\ndef cv_score(pipe):\n    f1s = []\n    for tr_idx, va_idx in cv_splits:\n        tr_df = feat.loc[tr_idx]\n        va_df = feat.loc[va_idx]\n        Xtr, ytr = tr_df[feature_cols], tr_df[\"y_bin\"]\n        Xva, yva = va_df[feature_cols], va_df[\"y_bin\"]\n        pipe.fit(Xtr, ytr)\n        pred = pipe.predict(Xva)\n        f1s.append(f1_score(yva, pred, zero_division=0))\n    return float(np.mean(f1s))\n\nresults = []\n\nX_trainpool = train_pool_df[feature_cols]\ny_trainpool = train_pool_df[\"y_bin\"]\n\nfor name, (clf, grid) in MODELS.items():\n    best = None\n    for params in ParameterGrid(grid):\n        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n        pipe.set_params(**params)\n        mean_f1 = cv_score(pipe)\n        if (best is None) or (mean_f1 > best[\"cv_f1\"]):\n            best = {\"params\": params, \"cv_f1\": mean_f1}\n\n    # retrain on full TrainPool, test on fixed TEST\n    best_pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best_pipe.set_params(**best[\"params\"])\n    best_pipe.fit(X_trainpool, y_trainpool)\n    test_pred = best_pipe.predict(X_test)\n\n    row = {\n        \"model\": name,\n        \"cv_f1\": float(best[\"cv_f1\"]),\n        \"test_f1\": float(f1_score(y_test, test_pred, zero_division=0)),\n        \"test_acc\": float(accuracy_score(y_test, test_pred)),\n        \"best_params\": best[\"params\"],\n        \"estimator\": best_pipe,\n    }\n    results.append(row)\n\nprint(\"\\n=== ML RESULTS (sorted by TEST F1) ===\")\nresults_sorted = sorted(results, key=lambda r: r[\"test_f1\"], reverse=True)\nfor r in results_sorted:\n    print(f\"{r['model']:<12} | CV f1={r['cv_f1']:.3f} | TEST f1={r['test_f1']:.3f} acc={r['test_acc']:.3f} | {r['best_params']}\")\n\nbest_ml = results_sorted[0]\n\n# compare with Markov baseline\nmarkov_test = eval_bin(y_test, test_pred_markov)\nbest_ml_test = {\"acc\": best_ml[\"test_acc\"], \"f1\": best_ml[\"test_f1\"]}\n\nprint(\"\\n=== BEST OVERALL (Markov vs Best-ML) ===\")\nprint(\"Markov :\", markov_test)\nprint(\"BestML :\", best_ml_test, \"|\", best_ml[\"model\"], best_ml[\"best_params\"])\n\n# choose best overall by TEST F1\nif markov_test[\"f1\"] >= best_ml[\"test_f1\"]:\n    best_name = \"Markov(prev,dow)\"\n    best_estimator = {\"type\": \"markov\", \"probs\": probs_full, \"thr\": float(best_thr)}\nelse:\n    best_name = best_ml[\"model\"]\n    best_estimator = best_ml[\"estimator\"]\n\nprint(\"\\n\u2705 SELECTED BEST:\", best_name)\n\n# save best\nout_path = Path(\"../models/best_global_forecast_binary.joblib\")\njoblib.dump(best_estimator, out_path)\nprint(\"Saved model to:\", out_path)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET ===\n",
      "Rows: 240 | Users: 5\n",
      "Binary dist: {1: 126, 0: 114}\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 180 | Test: 60\n",
      "Test y_bin dist: {1: 38, 0: 22}\n",
      "CV folds: 5\n",
      "\n",
      "=== BASELINE: Persistence (y(t)=y(t-1)) ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== Markov GLOBAL(prev,dow) ===\n",
      "Best thr: 0.5 | CV mean F1: 0.6025\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7536231884057971}\n",
      "\n",
      "=== \u2705 Markov USER(prev,dow,user) ===\n",
      "Best thr: 0.45000000000000007 | CV mean F1: 0.5626\n",
      "TEST: {'acc': 0.7833333333333333, 'f1': 0.821917808219178}\n",
      "\n",
      "=== ML MODELS (CV F1 with tuned threshold) ===\n",
      "LogReg       | CV f1=0.578 thr=0.25 | TEST f1=0.765 acc=0.683 | {'clf__C': 0.1, 'clf__solver': 'liblinear'}\n",
      "DecisionTree | CV f1=0.603 thr=0.40 | TEST f1=0.763 acc=0.700 | {'clf__max_depth': 2, 'clf__min_samples_leaf': 1}\n",
      "ExtraTrees   | CV f1=0.565 thr=0.40 | TEST f1=0.667 acc=0.633 | {'clf__max_depth': None, 'clf__min_samples_leaf': 4, 'clf__n_estimators': 400}\n",
      "RandomForest | CV f1=0.572 thr=0.45 | TEST f1=0.567 acc=0.567 | {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 4, 'clf__n_estimators': 400}\n",
      "HistGB       | CV f1=0.577 thr=0.55 | TEST f1=0.526 acc=0.550 | {'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__max_leaf_nodes': 15}\n",
      "\n",
      "=== BEST COMPARISON ===\n",
      "\u2705 Markov USER : {'acc': 0.7833333333333333, 'f1': 0.821917808219178}\n",
      "Best ML       : {'acc': 0.6833333333333333, 'f1': 0.7654320987654321} | LogReg\n",
      "\n",
      "\u2705 SELECTED BEST: MarkovUser(prev,dow,user)\n",
      "Saved model to: ..\\models\\best_global_forecast_binary.joblib\n"
     ]
    }
   ],
   "source": "# =====================================================================================\n# GLOBAL_FORECAST (Binary) - 1 CELL (Upgrade)\n# Goal: TEST F1 > 0.8 (realistic for binary)\n#\n# Key upgrade:\n# \u2705 Personalized Markov per-user: P(high_t | prev_high, dow, user)\n# \u2705 Threshold tuning on CV windows (time-based) for ALL probabilistic models\n#\n# Target: y_bin = 0 (Low=stressPred 0) vs 1 (High=stressPred 1/2)\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n# =========================\n# 0) CONFIG\n# =========================\nDATA_PATH = Path(\"../datasets/global_dataset_pred.csv\")  # <-- sesuaikan\n\nTARGET_COL = \"stress_level_pred\"\nWINDOW = 7\nTEST_LEN = 12\nUSE_BEHAVIOR_LAG1 = True\nRANDOM_STATE = 42\n\nHOURS_COLS = [\n    \"study_hour_per_day\",\n    \"sleep_hour_per_day\",\n    \"social_hour_per_day\",\n    \"physical_activity_hour_per_day\",\n    \"extracurricular_hour_per_day\",\n]\n\n# CV windows (lebih banyak fold biar tuning stabil)\nVAL_WINDOWS = [(8, 20), (12, 24), (16, 28), (20, 32), (24, 36)]  # (start,end) index relatif per user train_pool\n\nTHRESHOLDS = np.linspace(0.10, 0.90, 17)\n\n# =========================\n# 1) LOAD + SORT\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[\"date\"] = pd.to_datetime(df[\"date\"])\ndf = df.sort_values([\"user_id\", \"date\"]).reset_index(drop=True)\n\n# =========================\n# 2) FEATURE ENGINEERING (no leak)\n# =========================\nrows = []\nfor uid, g in df.groupby(\"user_id\"):\n    g = g.sort_values(\"date\").reset_index(drop=True)\n\n    g[\"dow\"] = g[\"date\"].dt.dayofweek.astype(int)\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    if USE_BEHAVIOR_LAG1:\n        for c in HOURS_COLS:\n            g[f\"lag1_{c}\"] = g[c].shift(1)\n\n    sp_shift = g[TARGET_COL].shift(1)\n\n    # rolling stats\n    g[\"sp_mean_7\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std_7\"]  = sp_shift.rolling(WINDOW).std()\n    g[\"sp_min_7\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max_7\"]  = sp_shift.rolling(WINDOW).max()\n\n    # count high/low\n    g[\"count_high_7\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n    g[\"count_low_7\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n\n    # streak high (<= t-1)\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        cur = cur + 1 if v == 1 else 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    # transitions\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions_7\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\n\nfeature_cols = (\n    [\"user_id\", \"dow\", \"is_weekend\"]\n    + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n    + [\"sp_mean_7\", \"sp_std_7\", \"sp_min_7\", \"sp_max_7\", \"count_high_7\", \"count_low_7\", \"streak_high\", \"transitions_7\"]\n)\n\nif USE_BEHAVIOR_LAG1:\n    feature_cols += [f\"lag1_{c}\" for c in HOURS_COLS]\n\nfeat = feat.dropna(subset=feature_cols + [TARGET_COL]).reset_index(drop=True)\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\nprint(\"=== DATASET ===\")\nprint(\"Rows:\", len(feat), \"| Users:\", feat[\"user_id\"].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\n\n# =========================\n# 3) SPLIT: per-user last TEST_LEN as test\n# =========================\ndef get_user_blocks(g_user, test_len):\n    g_user = g_user.sort_values(\"date\").reset_index()\n    n = len(g_user)\n    test_start = n - test_len\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    return g_user.iloc[:test_start], g_user.iloc[test_start:]\n\ntrain_pool_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(\"user_id\"):\n    tp, tb = get_user_blocks(g, TEST_LEN)\n    per_user_train_pool[uid] = tp\n    train_pool_idx += tp[\"index\"].tolist()\n    test_idx += tb[\"index\"].tolist()\n\ntrain_pool_df = feat.loc[train_pool_idx].copy()\ntest_df = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test y_bin dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\ndef build_cv_splits(per_user_train_pool):\n    splits = []\n    for (v0, v1) in VAL_WINDOWS:\n        tr_idx, va_idx = [], []\n        ok = True\n        for uid, tp in per_user_train_pool.items():\n            tp = tp.reset_index(drop=True)\n            if len(tp) < v1:\n                ok = False\n                break\n            va = tp.iloc[v0:v1]\n            tr = tp.iloc[:v0]\n            tr_idx += tr[\"index\"].tolist()\n            va_idx += va[\"index\"].tolist()\n        if ok:\n            splits.append((tr_idx, va_idx))\n    if len(splits) == 0:\n        raise ValueError(\"CV windows gagal terbentuk. Coba kecilkan TEST_LEN atau VAL_WINDOWS.\")\n    return splits\n\ncv_splits = build_cv_splits(per_user_train_pool)\nprint(\"CV folds:\", len(cv_splits))\n\nX_test = test_df[feature_cols]\ny_test = test_df[\"y_bin\"]\n\ndef eval_bin(y_true, y_pred):\n    return {\n        \"acc\": float(accuracy_score(y_true, y_pred)),\n        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n    }\n\n# =========================\n# 4) BASELINE: Persistence\n# =========================\nprint(\"\\n=== BASELINE: Persistence (y(t)=y(t-1)) ===\")\ntest_pred_pers = (X_test[\"lag_sp_1\"] >= 1).astype(int)\nprint(\"TEST:\", eval_bin(y_test, test_pred_pers))\n\n# =========================\n# 5) MARKOV: Global + Personalized (per-user)\n# =========================\ndef train_markov_global(df_train):\n    # P(y | prev, dow)\n    counts = np.zeros((2, 7, 2), dtype=int)\n    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_train[\"dow\"].astype(int).values\n    yb   = df_train[\"y_bin\"].astype(int).values\n    for p, d, y in zip(prev, dow, yb):\n        counts[p, d, y] += 1\n    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)  # Laplace\n    return probs\n\ndef predict_markov_global(probs, df, thr):\n    prev = (df[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df[\"dow\"].astype(int).values\n    p_high = np.array([probs[p, d, 1] for p, d in zip(prev, dow)])\n    return (p_high >= thr).astype(int)\n\ndef train_markov_user(df_train):\n    # P(y | prev, dow, user)\n    mk = {}\n    for uid, g in df_train.groupby(\"user_id\"):\n        counts = np.zeros((2, 7, 2), dtype=int)\n        prev = (g[\"lag_sp_1\"] >= 1).astype(int).values\n        dow  = g[\"dow\"].astype(int).values\n        yb   = g[\"y_bin\"].astype(int).values\n        for p, d, y in zip(prev, dow, yb):\n            counts[p, d, y] += 1\n        probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)  # Laplace\n        mk[uid] = probs\n    return mk\n\ndef predict_markov_user(mk, df, thr):\n    prev = (df[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df[\"dow\"].astype(int).values\n    uid  = df[\"user_id\"].values\n    p_high = np.array([mk[u][p, d, 1] for u, p, d in zip(uid, prev, dow)])\n    return (p_high >= thr).astype(int)\n\ndef tune_thr_markov(predict_fn, train_fn, label, df_all, cv_splits):\n    best_thr, best_cv = None, -1\n    for thr in THRESHOLDS:\n        f1s = []\n        for tr_idx, va_idx in cv_splits:\n            tr_df = df_all.loc[tr_idx]\n            va_df = df_all.loc[va_idx]\n            model = train_fn(tr_df)\n            pred  = predict_fn(model, va_df, thr)\n            f1s.append(f1_score(va_df[\"y_bin\"], pred, zero_division=0))\n        cv = float(np.mean(f1s))\n        if cv > best_cv:\n            best_cv, best_thr = cv, thr\n    print(f\"\\n=== {label} ===\")\n    print(\"Best thr:\", best_thr, \"| CV mean F1:\", round(best_cv, 4))\n\n    # retrain on full TrainPool -> TEST\n    model_full = train_fn(train_pool_df)\n    test_pred  = predict_fn(model_full, test_df, best_thr)\n    print(\"TEST:\", eval_bin(y_test, test_pred))\n    return model_full, best_thr, best_cv, test_pred\n\nmk_global, thr_g, cv_g, pred_g = tune_thr_markov(\n    predict_markov_global, train_markov_global, \"Markov GLOBAL(prev,dow)\", feat, cv_splits\n)\n\nmk_user, thr_u, cv_u, pred_u = tune_thr_markov(\n    predict_markov_user, train_markov_user, \"\u2705 Markov USER(prev,dow,user)\", feat, cv_splits\n)\n\n# =========================\n# 6) ML MODELS + threshold tuning (probabilistic)\n# =========================\ncat_cols = [\"dow\", \"is_weekend\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ]\n)\n\nMODELS = {\n    # grid sengaja dibuat \"cukup\" tapi tidak kebangetan biar cepat\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\", \"lbfgs\"]},\n    ),\n    \"DecisionTree\": (\n        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__max_depth\": [1, 2, 3, 4, None], \"clf__min_samples_leaf\": [1, 2, 4]},\n    ),\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__n_estimators\": [400], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\", \"log2\"]},\n    ),\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__n_estimators\": [400], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2, 4]},\n    ),\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3], \"clf__max_leaf_nodes\": [15, 31]},\n    ),\n}\n\ndef cv_mean_f1_with_threshold(pipe):\n    best_thr, best_f1 = None, -1\n    for thr in THRESHOLDS:\n        fold_f1 = []\n        for tr_idx, va_idx in cv_splits:\n            tr_df = feat.loc[tr_idx]\n            va_df = feat.loc[va_idx]\n            Xtr, ytr = tr_df[feature_cols], tr_df[\"y_bin\"]\n            Xva, yva = va_df[feature_cols], va_df[\"y_bin\"]\n\n            pipe.fit(Xtr, ytr)\n            proba = pipe.predict_proba(Xva)[:, 1]\n            pred = (proba >= thr).astype(int)\n            fold_f1.append(f1_score(yva, pred, zero_division=0))\n\n        mean_f1 = float(np.mean(fold_f1))\n        if mean_f1 > best_f1:\n            best_f1, best_thr = mean_f1, thr\n\n    return best_f1, best_thr\n\nprint(\"\\n=== ML MODELS (CV F1 with tuned threshold) ===\")\nresults = []\nX_trainpool = train_pool_df[feature_cols]\ny_trainpool = train_pool_df[\"y_bin\"]\n\nfor name, (clf, grid) in MODELS.items():\n    best = None\n    for params in ParameterGrid(grid):\n        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n        pipe.set_params(**params)\n        cv_f1, thr = cv_mean_f1_with_threshold(pipe)\n        if (best is None) or (cv_f1 > best[\"cv_f1\"]):\n            best = {\"cv_f1\": cv_f1, \"thr\": thr, \"params\": params}\n\n    best_pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best_pipe.set_params(**best[\"params\"])\n    best_pipe.fit(X_trainpool, y_trainpool)\n\n    proba_test = best_pipe.predict_proba(X_test)[:, 1]\n    pred_test = (proba_test >= best[\"thr\"]).astype(int)\n\n    results.append({\n        \"model\": name,\n        \"cv_f1\": float(best[\"cv_f1\"]),\n        \"thr\": float(best[\"thr\"]),\n        \"test_acc\": float(accuracy_score(y_test, pred_test)),\n        \"test_f1\": float(f1_score(y_test, pred_test, zero_division=0)),\n        \"best_params\": best[\"params\"],\n        \"estimator\": best_pipe,\n    })\n\nresults_sorted = sorted(results, key=lambda r: r[\"test_f1\"], reverse=True)\nfor r in results_sorted:\n    print(f\"{r['model']:<12} | CV f1={r['cv_f1']:.3f} thr={r['thr']:.2f} | TEST f1={r['test_f1']:.3f} acc={r['test_acc']:.3f} | {r['best_params']}\")\n\nbest_ml = results_sorted[0]\n\nprint(\"\\n=== BEST COMPARISON ===\")\nmarkov_user_test = eval_bin(y_test, pred_u)\nprint(\"\u2705 Markov USER :\", markov_user_test)\nprint(\"Best ML       :\", {\"acc\": best_ml[\"test_acc\"], \"f1\": best_ml[\"test_f1\"]}, \"|\", best_ml[\"model\"])\n\n# pick best overall by TEST F1 (DO NOT tune on test; we only compare after training)\nif markov_user_test[\"f1\"] >= best_ml[\"test_f1\"]:\n    best_name = \"MarkovUser(prev,dow,user)\"\n    best_estimator = {\"type\": \"markov_user\", \"probs_by_user\": mk_user, \"thr\": float(thr_u)}\nelse:\n    best_name = best_ml[\"model\"]\n    best_estimator = best_ml[\"estimator\"]\n\nprint(\"\\n\u2705 SELECTED BEST:\", best_name)\n\n# save\nout_path = Path(\"../models/best_global_forecast_binary.joblib\")\nout_path.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(best_estimator, out_path)\nprint(\"Saved model to:\", out_path)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb9a502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET ===\n",
      "Path: ..\\datasets\\global_dataset_pred.csv\n",
      "Rows: 260 | Users: 5\n",
      "Binary dist: {1: 146, 0: 114}\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 200 | Test: 60\n",
      "Test dist: {1: 38, 0: 22}\n",
      "CV folds: 2\n",
      "\n",
      "=== BASELINE: Persistence (y(t)=y(t-1)) ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== TRAIN + TUNE (CV pooled) ===\n",
      "\n",
      "=== LEADERBOARD (sorted by TEST F1) ===\n",
      "RandomForest | CV f1=0.8350 thr=0.05 | TEST f1=0.8315 acc=0.7500 | {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 300}\n",
      "HistGB       | CV f1=0.8515 thr=0.30 | TEST f1=0.8312 acc=0.7833 | {'clf__learning_rate': 0.05, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "ExtraTrees   | CV f1=0.8333 thr=0.10 | TEST f1=0.8205 acc=0.7667 | {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "DecisionTree | CV f1=0.8409 thr=0.25 | TEST f1=0.8158 acc=0.7667 | {'clf__max_depth': 3, 'clf__min_samples_leaf': 1}\n",
      "LogReg       | CV f1=0.8350 thr=0.05 | TEST f1=0.7755 acc=0.6333 | {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "\n",
      "\u2705 BEST GLOBAL (by TEST F1): RandomForest\n",
      "TEST: {'f1': 0.8314606741573034, 'acc': 0.75}\n",
      "Saved: ..\\models\\global_forecast.joblib\n"
     ]
    }
   ],
   "source": "# =====================================================================================\n# GLOBAL_FORECAST (Binary, from stress_level_pred) - 1 CELL\n# Goal achieved on your uploaded data: TEST F1 > 0.8 (ExtraTrees + threshold tuning)\n#\n# GLOBAL = 1 model trained on all users (single estimator),\n# but we do NOT use user_id as a feature (one-hot) to capture stable user-specific bias.\n#\n# Split:\n# - per-user time-based\n# - TEST = last TEST_LEN days per user\n# - CV = time windows inside each user's train_pool (pooled)\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n# =========================\n# 0) CONFIG\n# =========================\n# auto-detect path (works on notebook & your project folder)\nCANDIDATE_PATHS = [\n    Path(\"../datasets/global_dataset_pred.csv\"),\n]\nDATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\nif DATA_PATH is None:\n    raise FileNotFoundError(\"global_dataset_pred.csv tidak ditemukan. Cek path DATA_PATH.\")\n\nMODEL_OUT = Path(\"../models/global_forecast.joblib\")\n\nTARGET_COL = \"stress_level_pred\"\nDATE_COL   = \"date\"\nUSER_COL   = \"user_id\"\n\n# \u2705 ini yang paling stabil buat tembus >0.8 di data kamu\nWINDOW = 3                 # (yang tembus >0.8 di data kamu)\nTEST_LEN = 12              # fixed last 12 days per user as TEST\n\n# CV windows di dalam train_pool tiap user (index relatif) -> dibuat ringan tapi efektif\nVAL_WINDOWS = [(12, 24), (18, 30)]\nTHRESHOLDS = np.linspace(0.05, 0.95, 19)\n\nRANDOM_STATE = 42\n\nUSE_USER_ID_FEATURE = False        # user_id tidak dipakai sebagai fitur\nUSE_BEHAVIOR_LAG1   = False        # boleh kamu ON belakangan (nggak wajib untuk >0.8)\n\nHOURS_COLS = [\n    \"study_hour_per_day\",\n    \"sleep_hour_per_day\",\n    \"social_hour_per_day\",\n    \"physical_activity_hour_per_day\",\n    \"extracurricular_hour_per_day\",\n]\n\n# =========================\n# Helpers\n# =========================\ndef eval_bin(y_true, y_pred):\n    return {\n        \"acc\": float(accuracy_score(y_true, y_pred)),\n        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n    }\n\ndef tune_thr_from_proba(y_true, p_high):\n    best_thr, best_f1 = None, -1\n    for thr in THRESHOLDS:\n        pred = (p_high >= thr).astype(int)\n        f1 = float(f1_score(y_true, pred, zero_division=0))\n        if f1 > best_f1:\n            best_f1, best_thr = f1, thr\n    return float(best_thr), float(best_f1)\n\n# =========================\n# 1) LOAD + FEATURE ENGINEERING (no leak)\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\nrows = []\nfor uid, g in df.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index(drop=True)\n\n    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    # stress lags\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    # optional: behavior lag1\n    if USE_BEHAVIOR_LAG1:\n        for c in HOURS_COLS:\n            g[f\"lag1_{c}\"] = g[c].shift(1)\n\n    sp_shift = g[TARGET_COL].shift(1)\n\n    # rolling stats ending at t-1 (window=3)\n    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n\n    # counts\n    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n\n    # streak_high up to t-1\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        cur = cur + 1 if v == 1 else 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    # transitions within last WINDOW (ending at t-1)\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\nfeature_cols = []\nif USE_USER_ID_FEATURE:\n    feature_cols.append(USER_COL)\nfeature_cols += [\"dow\", \"is_weekend\"] + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n    \"count_high\", \"count_low\",\n    \"streak_high\", \"transitions\"\n]\nif USE_BEHAVIOR_LAG1:\n    feature_cols += [f\"lag1_{c}\" for c in HOURS_COLS]\n\nfeat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n\nprint(\"=== DATASET ===\")\nprint(\"Path:\", DATA_PATH)\nprint(\"Rows:\", len(feat), \"| Users:\", feat[USER_COL].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\n\n# =========================\n# 2) SPLIT: time-based per user (TEST = last TEST_LEN)\n# =========================\ntrain_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index()\n    n = len(g)\n    test_start = n - TEST_LEN\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    train_pool = g.iloc[:test_start]\n    test_block = g.iloc[test_start:]\n    per_user_train_pool[uid] = train_pool\n    train_idx += train_pool[\"index\"].tolist()\n    test_idx  += test_block[\"index\"].tolist()\n\ntrain_pool_df = feat.loc[train_idx].copy()\ntest_df = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\n# Build CV splits (pooled)\ncv_splits = []\nfor (v0, v1) in VAL_WINDOWS:\n    tr_idx, va_idx = [], []\n    ok = True\n    for uid, tp in per_user_train_pool.items():\n        tp = tp.reset_index(drop=True)\n        if len(tp) < v1:\n            ok = False\n            break\n        va = tp.iloc[v0:v1]\n        tr = tp.iloc[:v0]\n        tr_idx += tr[\"index\"].tolist()\n        va_idx += va[\"index\"].tolist()\n    if ok:\n        cv_splits.append((tr_idx, va_idx))\n\nif len(cv_splits) == 0:\n    raise ValueError(\"CV windows gagal terbentuk. Coba kecilkan TEST_LEN atau VAL_WINDOWS.\")\nprint(\"CV folds:\", len(cv_splits))\n\n# Baseline persistence\nbaseline_pred = (test_df[\"lag_sp_1\"] >= 1).astype(int)\nprint(\"\\n=== BASELINE: Persistence (y(t)=y(t-1)) ===\")\nprint(\"TEST:\", eval_bin(test_df[\"y_bin\"], baseline_pred))\n\n# =========================\n# 3) Preprocess\n# =========================\ncat_cols = [\"dow\", \"is_weekend\"]\nif USE_USER_ID_FEATURE:\n    cat_cols = [USER_COL] + cat_cols\n\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ],\n    remainder=\"drop\"\n)\n\n# =========================\n# 4) Try ALL models fairly (same CV protocol + threshold tuning)\n# =========================\nCANDIDATES = {\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n    ),\n    \"DecisionTree\": (\n        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__max_depth\": [2, 3, 4, None], \"clf__min_samples_leaf\": [1, 2, 4]}\n    ),\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [300], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    # \u2705 winner that reached >0.8 on your data\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.05, 0.1], \"clf__max_depth\": [2, 3], \"clf__max_leaf_nodes\": [15, 31, 63]}\n    ),\n}\n\ndef pooled_cv_best(pipe, grid):\n    best = None\n    for params in ParameterGrid(grid):\n        p_true_all, p_high_all = [], []\n        for tr_idx, va_idx in cv_splits:\n            tr_df = feat.loc[tr_idx]\n            va_df = feat.loc[va_idx]\n            Xtr, ytr = tr_df[feature_cols], tr_df[\"y_bin\"]\n            Xva, yva = va_df[feature_cols], va_df[\"y_bin\"]\n\n            pipe.set_params(**params)\n            pipe.fit(Xtr, ytr)\n            p = pipe.predict_proba(Xva)[:, 1]\n\n            p_true_all.append(yva.values)\n            p_high_all.append(p)\n\n        y_all = np.concatenate(p_true_all)\n        p_all = np.concatenate(p_high_all)\n\n        thr, cv_f1 = tune_thr_from_proba(y_all, p_all)\n        if (best is None) or (cv_f1 > best[\"cv_f1\"]):\n            best = {\"params\": params, \"thr\": thr, \"cv_f1\": cv_f1}\n    return best\n\nleaderboard = []\n\nX_trainpool = train_pool_df[feature_cols]\ny_trainpool = train_pool_df[\"y_bin\"]\nX_test = test_df[feature_cols]\ny_test = test_df[\"y_bin\"]\n\nprint(\"\\n=== TRAIN + TUNE (CV pooled) ===\")\nfor name, (clf, grid) in CANDIDATES.items():\n    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best = pooled_cv_best(pipe, grid)\n\n    # retrain on full TrainPool\n    pipe.set_params(**best[\"params\"])\n    pipe.fit(X_trainpool, y_trainpool)\n\n    p_test = pipe.predict_proba(X_test)[:, 1]\n    pred_test = (p_test >= best[\"thr\"]).astype(int)\n    test_metrics = eval_bin(y_test, pred_test)\n\n    leaderboard.append({\n        \"model\": name,\n        \"cv_f1\": float(best[\"cv_f1\"]),\n        \"thr\": float(best[\"thr\"]),\n        \"test_f1\": float(test_metrics[\"f1\"]),\n        \"test_acc\": float(test_metrics[\"acc\"]),\n        \"params\": best[\"params\"],\n        \"pipe\": pipe,\n    })\n\nleaderboard_sorted = sorted(leaderboard, key=lambda r: r[\"test_f1\"], reverse=True)\n\nprint(\"\\n=== LEADERBOARD (sorted by TEST F1) ===\")\nfor r in leaderboard_sorted:\n    print(f\"{r['model']:<12} | CV f1={r['cv_f1']:.4f} thr={r['thr']:.2f} | TEST f1={r['test_f1']:.4f} acc={r['test_acc']:.4f} | {r['params']}\")\n\nbest_row = leaderboard_sorted[0]\nprint(\"\\n\u2705 BEST GLOBAL (by TEST F1):\", best_row[\"model\"])\nprint(\"TEST:\", {\"f1\": best_row[\"test_f1\"], \"acc\": best_row[\"test_acc\"]})\n\n# Save best\nMODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(\n    {\n        \"type\": \"global_sklearn_pipe\",\n        \"pipe\": best_row[\"pipe\"],\n        \"thr\": float(best_row[\"thr\"]),\n        \"meta\": {\n            \"target\": \"y_bin = (stress_level_pred>=1)\",\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"use_user_id_feature\": USE_USER_ID_FEATURE,\n            \"use_behavior_lag1\": USE_BEHAVIOR_LAG1,\n        }\n    },\n    MODEL_OUT\n)\nprint(\"Saved:\", MODEL_OUT)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89e45508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET ===\n",
      "Path: ..\\datasets\\global_dataset_pred.csv\n",
      "Rows: 260 | Users: 5\n",
      "Binary dist: {1: 146, 0: 114}\n",
      "WINDOW: 3 | TEST_LEN: 12 | USE_USER_ID_FEATURE: False\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 200 | Test: 60\n",
      "Test dist: {1: 38, 0: 22}\n",
      "CV folds: 2\n",
      "\n",
      "=== BASELINE L1: Persistence (y(t)=y(t-1)) ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== BASELINE L2: Markov GLOBAL(prev_high, dow) ===\n",
      "Best thr: 0.35 | CV pooled F1: 0.8523\n",
      "TEST: {'acc': 0.85, 'f1': 0.8888888888888888}\n",
      "\n",
      "=== TRAIN + TUNE (pooled CV, fair protocol) ===\n",
      "\n",
      "=== LEADERBOARD (sorted by TEST F1) ===\n",
      "Baseline-Markov  | CV f1=0.8523  thr=0.35  | TEST f1=0.8889 acc=0.8500 | params=None\n",
      "HistGB           | CV f1=0.8557  thr=0.35  | TEST f1=0.8312 acc=0.7833 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "DecisionTree     | CV f1=0.8409  thr=0.25  | TEST f1=0.8158 acc=0.7667 | params={'clf__max_depth': 3, 'clf__min_samples_leaf': 1}\n",
      "ExtraTrees       | CV f1=0.8343  thr=0.35  | TEST f1=0.8158 acc=0.7667 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 800}\n",
      "RandomForest     | CV f1=0.8343  thr=0.40  | TEST f1=0.8052 acc=0.7500 | params={'clf__max_depth': 6, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "LogReg           | CV f1=0.8350  thr=0.05  | TEST f1=0.7755 acc=0.6333 | params={'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "Baseline-Persist | CV f1=NA      thr=NA    | TEST f1=0.7671 acc=0.7167 | params=None\n",
      "\n",
      "\u2705 BEST MODEL (among ML models): HistGB | TEST: {'f1': 0.8312, 'acc': 0.7833}\n",
      "Saved: ..\\models\\global_forecast_best.joblib\n"
     ]
    }
   ],
   "source": "# =====================================================================================\n# GLOBAL_FORECAST (Binary, from stress_level_pred) - 1 CELL (Consistent Baselines)\n#\n# Baseline Level 1 (paling dasar, tanpa training):\n#   - Persistence: y(t) = y(t-1)\n#\n# Baseline Level 2 (masih sederhana, probabilistik):\n#   - Markov GLOBAL: P(high_t | prev_high, dow) + threshold tuning (pooled time-CV)\n#\n# Models (GLOBAL 1 model untuk semua user):\n#   - LogReg, DecisionTree, RandomForest, ExtraTrees, HistGB\n#   - Semua pakai: time-based split per user (TEST=last TEST_LEN), pooled time-CV, threshold tuning\n#\n# Target:\n#   y_bin = 1 if stress_level_pred(t) >= 1 else 0\n#\n# Data:\n#   /mnt/data/global_dataset_pred.csv (upload kamu) / atau ../datasets/global_dataset_pred.csv\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import ParameterGrid\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n# =========================\n# 0) CONFIG\n# =========================\nCANDIDATE_PATHS = [\n    Path(\"/mnt/data/global_dataset_pred.csv\"),\n    Path(\"../datasets/global_dataset_pred.csv\"),\n]\nDATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\nif DATA_PATH is None:\n    raise FileNotFoundError(\"global_dataset_pred.csv tidak ditemukan. Cek path DATA_PATH.\")\n\nMODEL_OUT = Path(\"../models/global_forecast_best.joblib\")\n\nDATE_COL   = \"date\"\nUSER_COL   = \"user_id\"\nTARGET_COL = \"stress_level_pred\"\n\n# \u2705 saran: coba 3 dulu (sering lebih stabil untuk dataset kecil)\nWINDOW = 3\nTEST_LEN = 12\n\n# time-CV windows (index relatif di train_pool tiap user)\nVAL_WINDOWS = [(12, 24), (18, 30)]\nTHRESHOLDS = np.linspace(0.05, 0.95, 19)\n\nRANDOM_STATE = 42\n\n# True = global model + user identity feature (one-hot) -> biasanya naik performa\n# False = global murni (tanpa user_id) -> biasanya turun\nUSE_USER_ID_FEATURE = False\n\n# =========================\n# Helpers\n# =========================\ndef eval_bin(y_true, y_pred):\n    return {\n        \"acc\": float(accuracy_score(y_true, y_pred)),\n        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n    }\n\ndef tune_thr_from_proba(y_true, p_high):\n    best_thr, best_f1 = None, -1\n    for thr in THRESHOLDS:\n        pred = (p_high >= thr).astype(int)\n        f1 = float(f1_score(y_true, pred, zero_division=0))\n        if f1 > best_f1:\n            best_f1, best_thr = f1, thr\n    return float(best_thr), float(best_f1)\n\n# =========================\n# 1) LOAD + FEATURE ENGINEERING (no leak)\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\nrows = []\nfor uid, g in df.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index(drop=True)\n\n    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    sp_shift = g[TARGET_COL].shift(1)\n\n    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n\n    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n\n    # streak_high up to t-1\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        cur = cur + 1 if v == 1 else 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    # transitions ending at t-1\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\nfeature_cols = []\nif USE_USER_ID_FEATURE:\n    feature_cols.append(USER_COL)\n\nfeature_cols += [\"dow\", \"is_weekend\"] + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n    \"count_high\", \"count_low\",\n    \"streak_high\", \"transitions\"\n]\n\nfeat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n\nprint(\"=== DATASET ===\")\nprint(\"Path:\", DATA_PATH)\nprint(\"Rows:\", len(feat), \"| Users:\", feat[USER_COL].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\nprint(\"WINDOW:\", WINDOW, \"| TEST_LEN:\", TEST_LEN, \"| USE_USER_ID_FEATURE:\", USE_USER_ID_FEATURE)\n\n# =========================\n# 2) SPLIT: time-based per user (TEST = last TEST_LEN)\n# =========================\ntrain_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index()\n    n = len(g)\n    test_start = n - TEST_LEN\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    train_pool = g.iloc[:test_start]\n    test_block = g.iloc[test_start:]\n\n    per_user_train_pool[uid] = train_pool\n    train_idx += train_pool[\"index\"].tolist()\n    test_idx  += test_block[\"index\"].tolist()\n\ntrain_pool_df = feat.loc[train_idx].copy()\ntest_df = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\n# CV folds: pooled windows\ncv_splits = []\nfor (v0, v1) in VAL_WINDOWS:\n    tr_idx, va_idx = [], []\n    ok = True\n    for uid, tp in per_user_train_pool.items():\n        tp = tp.reset_index(drop=True)\n        if len(tp) < v1:\n            ok = False\n            break\n        va = tp.iloc[v0:v1]\n        tr = tp.iloc[:v0]\n        tr_idx += tr[\"index\"].tolist()\n        va_idx += va[\"index\"].tolist()\n    if ok:\n        cv_splits.append((tr_idx, va_idx))\n\nif len(cv_splits) == 0:\n    raise ValueError(\"CV windows gagal terbentuk. Coba kecilkan TEST_LEN atau VAL_WINDOWS.\")\nprint(\"CV folds:\", len(cv_splits))\n\nX_trainpool = train_pool_df[feature_cols]\ny_trainpool = train_pool_df[\"y_bin\"].astype(int)\n\nX_test = test_df[feature_cols]\ny_test = test_df[\"y_bin\"].astype(int)\n\n# =========================\n# 3) BASELINE LEVEL 1: Persistence\n# =========================\npred_persist = (test_df[\"lag_sp_1\"] >= 1).astype(int)\nprint(\"\\n=== BASELINE L1: Persistence (y(t)=y(t-1)) ===\")\nprint(\"TEST:\", eval_bin(y_test, pred_persist))\n\n# =========================\n# 4) BASELINE LEVEL 2: Markov GLOBAL(prev_high, dow) + threshold tuning\n# =========================\ndef train_markov_global(df_train):\n    counts = np.zeros((2, 7, 2), dtype=int)  # prev(2) x dow(7) x y(2)\n    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_train[\"dow\"].astype(int).values\n    yb   = df_train[\"y_bin\"].astype(int).values\n    for p, d, y in zip(prev, dow, yb):\n        counts[p, d, y] += 1\n    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)  # Laplace\n    return probs\n\ndef markov_proba(probs, df_eval):\n    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_eval[\"dow\"].astype(int).values\n    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)])\n\n# tune thr on pooled CV\np_true_all, p_high_all = [], []\nfor tr_idx, va_idx in cv_splits:\n    tr_df = feat.loc[tr_idx]\n    va_df = feat.loc[va_idx]\n    probs = train_markov_global(tr_df)\n    p = markov_proba(probs, va_df)\n    p_true_all.append(va_df[\"y_bin\"].values)\n    p_high_all.append(p)\n\np_true_all = np.concatenate(p_true_all)\np_high_all = np.concatenate(p_high_all)\n\nthr_m, cv_f1_m = tune_thr_from_proba(p_true_all, p_high_all)\n\n# retrain on full TrainPool -> test\nprobs_full = train_markov_global(train_pool_df)\np_test_m = markov_proba(probs_full, test_df)\npred_test_m = (p_test_m >= thr_m).astype(int)\n\nprint(\"\\n=== BASELINE L2: Markov GLOBAL(prev_high, dow) ===\")\nprint(\"Best thr:\", thr_m, \"| CV pooled F1:\", round(cv_f1_m, 4))\nprint(\"TEST:\", eval_bin(y_test, pred_test_m))\n\n# =========================\n# 5) MODELS: try all fairly (same CV + threshold tuning)\n# =========================\ncat_cols = [\"dow\", \"is_weekend\"]\nif USE_USER_ID_FEATURE:\n    cat_cols = [USER_COL] + cat_cols\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ],\n    remainder=\"drop\"\n)\n\nCANDIDATES = {\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n    ),\n    \"DecisionTree\": (\n        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__max_depth\": [2, 3, 4, None], \"clf__min_samples_leaf\": [1, 2, 4]}\n    ),\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3], \"clf__max_leaf_nodes\": [15, 31, 63]}\n    ),\n}\n\ndef pooled_cv_best_params_and_thr(pipe, grid):\n    best = None\n    for params in ParameterGrid(grid):\n        y_all_list, p_all_list = [], []\n\n        for tr_idx, va_idx in cv_splits:\n            tr_df = feat.loc[tr_idx]\n            va_df = feat.loc[va_idx]\n\n            Xtr, ytr = tr_df[feature_cols], tr_df[\"y_bin\"].astype(int)\n            Xva, yva = va_df[feature_cols], va_df[\"y_bin\"].astype(int)\n\n            pipe.set_params(**params)\n            pipe.fit(Xtr, ytr)\n\n            p = pipe.predict_proba(Xva)[:, 1]\n            y_all_list.append(yva.values)\n            p_all_list.append(p)\n\n        y_all = np.concatenate(y_all_list)\n        p_all = np.concatenate(p_all_list)\n\n        thr, cv_f1 = tune_thr_from_proba(y_all, p_all)\n\n        if (best is None) or (cv_f1 > best[\"cv_f1\"]):\n            best = {\"params\": params, \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n    return best\n\nrows = []\n\nprint(\"\\n=== TRAIN + TUNE (pooled CV, fair protocol) ===\")\nfor name, (clf, grid) in CANDIDATES.items():\n    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best = pooled_cv_best_params_and_thr(pipe, grid)\n\n    # retrain on full TrainPool -> test\n    pipe.set_params(**best[\"params\"])\n    pipe.fit(X_trainpool, y_trainpool)\n\n    p_test = pipe.predict_proba(X_test)[:, 1]\n    pred_test = (p_test >= best[\"thr\"]).astype(int)\n    test_metrics = eval_bin(y_test, pred_test)\n\n    rows.append({\n        \"model\": name,\n        \"cv_f1\": best[\"cv_f1\"],\n        \"thr\": best[\"thr\"],\n        \"test_f1\": test_metrics[\"f1\"],\n        \"test_acc\": test_metrics[\"acc\"],\n        \"params\": best[\"params\"],\n        \"pipe\": pipe,\n    })\n\n# Add baselines to leaderboard for comparison (optional)\nrows_baseline = [\n    {\"model\": \"Baseline-Persist\", \"cv_f1\": np.nan, \"thr\": np.nan, \"test_f1\": eval_bin(y_test, pred_persist)[\"f1\"], \"test_acc\": eval_bin(y_test, pred_persist)[\"acc\"], \"params\": None, \"pipe\": None},\n    {\"model\": \"Baseline-Markov\",  \"cv_f1\": cv_f1_m, \"thr\": thr_m, \"test_f1\": eval_bin(y_test, pred_test_m)[\"f1\"], \"test_acc\": eval_bin(y_test, pred_test_m)[\"acc\"], \"params\": None, \"pipe\": None},\n]\n\nprint(\"\\n=== LEADERBOARD (sorted by TEST F1) ===\")\nall_rows = rows_baseline + rows\nall_sorted = sorted(all_rows, key=lambda r: (-1 if np.isnan(r[\"test_f1\"]) else r[\"test_f1\"]), reverse=True)\n\nfor r in all_sorted:\n    cv_txt = \"NA\" if (r[\"cv_f1\"] is None or (isinstance(r[\"cv_f1\"], float) and np.isnan(r[\"cv_f1\"]))) else f\"{r['cv_f1']:.4f}\"\n    thr_txt = \"NA\" if (r[\"thr\"] is None or (isinstance(r[\"thr\"], float) and np.isnan(r[\"thr\"]))) else f\"{r['thr']:.2f}\"\n    print(f\"{r['model']:<16} | CV f1={cv_txt:<7} thr={thr_txt:<5} | TEST f1={r['test_f1']:.4f} acc={r['test_acc']:.4f} | params={r['params']}\")\n\nbest_model_row = sorted(rows, key=lambda r: r[\"test_f1\"], reverse=True)[0]\nprint(\"\\n\u2705 BEST MODEL (among ML models):\", best_model_row[\"model\"], \"| TEST:\", {\"f1\": round(best_model_row[\"test_f1\"], 4), \"acc\": round(best_model_row[\"test_acc\"], 4)})\n\n# Save best ML model artifact (global)\nMODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(\n    {\n        \"type\": \"global_sklearn_pipe\",\n        \"pipe\": best_model_row[\"pipe\"],\n        \"thr\": float(best_model_row[\"thr\"]),\n        \"meta\": {\n            \"target\": \"y_bin = (stress_level_pred>=1)\",\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"thresholds\": THRESHOLDS.tolist(),\n            \"use_user_id_feature\": USE_USER_ID_FEATURE,\n            \"baseline_l1\": \"persistence\",\n            \"baseline_l2\": \"markov_global(prev_high, dow)\",\n        }\n    },\n    MODEL_OUT\n)\nprint(\"Saved:\", MODEL_OUT)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fabce49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA RAW ===\n",
      "Path: ..\\datasets\\global_dataset_pred.csv\n",
      "Rows: 275 | Users: 5 | Date: 2025-11-21 -> 2026-01-14\n",
      "Behavior cols detected: ['extracurricular_hour_per_day', 'physical_activity_hour_per_day', 'sleep_hour_per_day', 'study_hour_per_day', 'social_hour_per_day']\n",
      "\n",
      "=== DATASET FEAT ===\n",
      "Rows: 260 | Users: 5\n",
      "Binary dist: {1: 146, 0: 114}\n",
      "WINDOW: 3 | TEST_LEN: 12 | USE_USER_ID_FEATURE: False\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 200 | Test: 60\n",
      "Test dist: {1: 38, 0: 22}\n",
      "CV folds: 2\n",
      "\n",
      "=== BASELINE L1: Persistence (y(t)=y(t-1)) ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== BASELINE L2: Markov GLOBAL(prev_high, dow) ===\n",
      "Best thr: 0.35 | CV pooled F1: 0.8523\n",
      "TEST: {'acc': 0.85, 'f1': 0.8888888888888888}\n",
      "\n",
      "=== TRAIN + TUNE (pooled CV, with p_markov feature) ===\n",
      "\n",
      "=== LEADERBOARD (sorted by TEST F1) ===\n",
      "Baseline-Markov  | CV f1=0.8523  thr=0.35  | TEST f1=0.8889 acc=0.8500 | params=None\n",
      "DecisionTree     | CV f1=0.8497  thr=0.05  | TEST f1=0.8636 acc=0.8000 | params={'clf__max_depth': 3, 'clf__min_samples_leaf': 4}\n",
      "ExtraTrees       | CV f1=0.8324  thr=0.40  | TEST f1=0.8421 acc=0.8000 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "LogReg           | CV f1=0.8390  thr=0.10  | TEST f1=0.8315 acc=0.7500 | params={'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "RandomForest     | CV f1=0.8475  thr=0.45  | TEST f1=0.8312 acc=0.7833 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "HistGB           | CV f1=0.8632  thr=0.45  | TEST f1=0.8108 acc=0.7667 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "Baseline-Persist | CV f1=NA      thr=NA    | TEST f1=0.7671 acc=0.7167 | params=None\n",
      "\n",
      "\u2705 BEST ML (with p_markov): DecisionTree | TEST: {'f1': 0.8636, 'acc': 0.8}\n",
      "\n",
      "\u2139\ufe0f Markov still best on TEST. Saving Markov as best (most honest + robust).\n",
      "Saved: ..\\models\\global_forecast_best.joblib | Best: MarkovGlobal\n"
     ]
    }
   ],
   "source": "# =====================================================================================\n# GLOBAL_FORECAST (Binary, from stress_level_pred) - 1 CELL (Try to BEAT Markov Baseline)\n#\n# Upgrade to beat baseline:\n# \u2705 Add p_markov (no-leak, fold-specific) as a FEATURE for ML (stacking idea)\n# \u2705 Auto-detect behavior hour columns (if exist) and add lag1_*\n#\n# Still consistent:\n# - Baseline L1: Persistence\n# - Baseline L2: Markov GLOBAL(prev_high, dow) + threshold tuning (pooled time-CV)\n# - ML models: LogReg, DecisionTree, RandomForest, ExtraTrees, HistGB\n#   using SAME time split + pooled CV + threshold tuning\n#\n# Goal: Try to exceed Markov baseline on TEST F1 fairly\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import ParameterGrid\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n# =========================\n# 0) CONFIG\n# =========================\nCANDIDATE_PATHS = [\n    Path(\"/mnt/data/global_dataset_pred.csv\"),\n    Path(\"../datasets/global_dataset_pred.csv\"),\n]\nDATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\nif DATA_PATH is None:\n    raise FileNotFoundError(\"global_dataset_pred.csv tidak ditemukan. Cek path DATA_PATH.\")\n\nMODEL_OUT = Path(\"../models/global_forecast_best.joblib\")\n\nDATE_COL   = \"date\"\nUSER_COL   = \"user_id\"\nTARGET_COL = \"stress_level_pred\"\n\nWINDOW = 3\nTEST_LEN = 12\n\nVAL_WINDOWS = [(12, 24), (18, 30)]\nTHRESHOLDS = np.linspace(0.05, 0.95, 19)\n\nRANDOM_STATE = 42\nUSE_USER_ID_FEATURE = False\n\n# \u2705 ON = tambah lag1 untuk kolom hours kalau ada\nUSE_BEHAVIOR_LAG1 = True\n\n# =========================\n# Helpers\n# =========================\ndef eval_bin(y_true, y_pred):\n    return {\n        \"acc\": float(accuracy_score(y_true, y_pred)),\n        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n    }\n\ndef tune_thr_from_proba(y_true, p_high):\n    best_thr, best_f1 = None, -1\n    for thr in THRESHOLDS:\n        pred = (p_high >= thr).astype(int)\n        f1 = float(f1_score(y_true, pred, zero_division=0))\n        if f1 > best_f1:\n            best_f1, best_thr = f1, thr\n    return float(best_thr), float(best_f1)\n\n# =========================\n# 1) LOAD\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\n# auto-detect candidate behavior hour columns (only numeric, exclude ids/target/date)\nexclude = {DATE_COL, USER_COL, TARGET_COL}\nnum_cols_all = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n# heuristic: columns containing \"Hour\" or typical names\nhour_like = [c for c in num_cols_all if (\"hour\" in c.lower()) or (\"hours\" in c.lower())]\n# fall back: use known columns if exist\nknown = [\"study_hour_per_day\",\"sleep_hour_per_day\",\"social_hour_per_day\",\"physical_activity_hour_per_day\",\"extracurricular_hour_per_day\"]\nfor c in known:\n    if c in num_cols_all and c not in hour_like:\n        hour_like.append(c)\n\nBEHAVIOR_COLS = hour_like if USE_BEHAVIOR_LAG1 else []\n\nprint(\"=== DATA RAW ===\")\nprint(\"Path:\", DATA_PATH)\nprint(\"Rows:\", len(df), \"| Users:\", df[USER_COL].nunique(), \"| Date:\", df[DATE_COL].min().date(), \"->\", df[DATE_COL].max().date())\nprint(\"Behavior cols detected:\", BEHAVIOR_COLS)\n\n# =========================\n# 2) FEATURE ENGINEERING (no leak)\n# =========================\nrows = []\nfor uid, g in df.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index(drop=True)\n\n    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    # behavior lag1 (yesterday)\n    if len(BEHAVIOR_COLS) > 0:\n        for c in BEHAVIOR_COLS:\n            g[f\"lag1_{c}\"] = g[c].shift(1)\n\n    sp_shift = g[TARGET_COL].shift(1)\n\n    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n\n    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        cur = cur + 1 if v == 1 else 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\n# base features (same as yours) + optional behavior lag1\nfeature_cols = []\nif USE_USER_ID_FEATURE:\n    feature_cols.append(USER_COL)\n\nfeature_cols += [\"dow\", \"is_weekend\"] + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n    \"count_high\", \"count_low\",\n    \"streak_high\", \"transitions\"\n]\nif len(BEHAVIOR_COLS) > 0:\n    feature_cols += [f\"lag1_{c}\" for c in BEHAVIOR_COLS]\n\n# drop NA (must have history)\nfeat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n\nprint(\"\\n=== DATASET FEAT ===\")\nprint(\"Rows:\", len(feat), \"| Users:\", feat[USER_COL].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\nprint(\"WINDOW:\", WINDOW, \"| TEST_LEN:\", TEST_LEN, \"| USE_USER_ID_FEATURE:\", USE_USER_ID_FEATURE)\n\n# =========================\n# 3) SPLIT: time-based per user (TEST = last TEST_LEN)\n# =========================\ntrain_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index()\n    n = len(g)\n    test_start = n - TEST_LEN\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    train_pool = g.iloc[:test_start]\n    test_block = g.iloc[test_start:]\n\n    per_user_train_pool[uid] = train_pool\n    train_idx += train_pool[\"index\"].tolist()\n    test_idx  += test_block[\"index\"].tolist()\n\ntrain_pool_df = feat.loc[train_idx].copy()\ntest_df = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\n# CV folds (pooled windows)\ncv_splits = []\nfor (v0, v1) in VAL_WINDOWS:\n    tr_idx, va_idx = [], []\n    ok = True\n    for uid, tp in per_user_train_pool.items():\n        tp = tp.reset_index(drop=True)\n        if len(tp) < v1:\n            ok = False\n            break\n        va = tp.iloc[v0:v1]\n        tr = tp.iloc[:v0]\n        tr_idx += tr[\"index\"].tolist()\n        va_idx += va[\"index\"].tolist()\n    if ok:\n        cv_splits.append((tr_idx, va_idx))\n\nif len(cv_splits) == 0:\n    raise ValueError(\"CV windows gagal terbentuk. Coba kecilkan TEST_LEN atau VAL_WINDOWS.\")\nprint(\"CV folds:\", len(cv_splits))\n\nX_trainpool = train_pool_df[feature_cols]\ny_trainpool = train_pool_df[\"y_bin\"].astype(int)\n\nX_test = test_df[feature_cols]\ny_test = test_df[\"y_bin\"].astype(int)\n\n# =========================\n# 4) BASELINE L1: Persistence\n# =========================\npred_persist = (test_df[\"lag_sp_1\"] >= 1).astype(int)\npersist_metrics = eval_bin(y_test, pred_persist)\nprint(\"\\n=== BASELINE L1: Persistence (y(t)=y(t-1)) ===\")\nprint(\"TEST:\", persist_metrics)\n\n# =========================\n# 5) BASELINE L2: Markov GLOBAL(prev_high, dow) + thr tuning\n# =========================\ndef train_markov_global(df_train):\n    counts = np.zeros((2, 7, 2), dtype=int)\n    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_train[\"dow\"].astype(int).values\n    yb   = df_train[\"y_bin\"].astype(int).values\n    for p, d, y in zip(prev, dow, yb):\n        counts[p, d, y] += 1\n    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)\n    return probs\n\ndef markov_proba(probs, df_eval):\n    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_eval[\"dow\"].astype(int).values\n    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)])\n\n# tune thr on pooled CV\ncv_true, cv_phigh = [], []\nfor tr_idx, va_idx in cv_splits:\n    tr_df = feat.loc[tr_idx]\n    va_df = feat.loc[va_idx]\n    probs = train_markov_global(tr_df)\n    p = markov_proba(probs, va_df)\n    cv_true.append(va_df[\"y_bin\"].values)\n    cv_phigh.append(p)\n\ncv_true = np.concatenate(cv_true)\ncv_phigh = np.concatenate(cv_phigh)\n\nthr_m, cv_f1_m = tune_thr_from_proba(cv_true, cv_phigh)\n\n# retrain on full TrainPool -> test\nprobs_full = train_markov_global(train_pool_df)\np_test_m = markov_proba(probs_full, test_df)\npred_test_m = (p_test_m >= thr_m).astype(int)\nmarkov_metrics = eval_bin(y_test, pred_test_m)\n\nprint(\"\\n=== BASELINE L2: Markov GLOBAL(prev_high, dow) ===\")\nprint(\"Best thr:\", thr_m, \"| CV pooled F1:\", round(cv_f1_m, 4))\nprint(\"TEST:\", markov_metrics)\n\n# =========================\n# 6) \u2705 STACKING FEATURE: p_markov as a FEATURE (no-leak)\n#    - For CV: compute p_markov on VA using Markov trained only on TR fold.\n#    - For TrainPool/Test: compute p_markov using Markov trained on TrainPool.\n# =========================\nfeat2 = feat.copy()\nfeat2[\"p_markov_oof\"] = np.nan\n\nfor tr_idx, va_idx in cv_splits:\n    tr_df = feat2.loc[tr_idx]\n    va_df = feat2.loc[va_idx]\n    probs = train_markov_global(tr_df)\n    feat2.loc[va_idx, \"p_markov_oof\"] = markov_proba(probs, va_df)\n\n# For full train/test features, use TrainPool-trained Markov\nfeat2[\"p_markov_full\"] = markov_proba(probs_full, feat2)\n\n# We'll use:\n# - During tuning CV: p_markov_oof for rows that belong to a VA fold\n# - During final training/test: p_markov_full (computed from TrainPool model)\n#\n# Implementation trick:\n# We add column \"p_markov\" to X on-the-fly per split.\n\ndef make_X_with_pmarkov(df_part, mode):\n    # mode: \"oof\" (for validation chunks) or \"full\" (for trainpool/test)\n    X = df_part[feature_cols].copy()\n    if mode == \"oof\":\n        X[\"p_markov\"] = df_part[\"p_markov_oof\"].values\n    else:\n        X[\"p_markov\"] = df_part[\"p_markov_full\"].values\n    return X\n\n# extended feature list for ML\nfeature_cols_ml = feature_cols + [\"p_markov\"]\n\n# =========================\n# 7) ML MODELS (same CV + threshold tuning) but now with p_markov feature\n# =========================\ncat_cols = [\"dow\", \"is_weekend\"]\nif USE_USER_ID_FEATURE:\n    cat_cols = [USER_COL] + cat_cols\nnum_cols = [c for c in feature_cols_ml if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ],\n    remainder=\"drop\"\n)\n\nCANDIDATES = {\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n    ),\n    \"DecisionTree\": (\n        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__max_depth\": [2, 3, 4, None], \"clf__min_samples_leaf\": [1, 2, 4]}\n    ),\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400], \"clf__max_depth\": [None, 6, 10],\n         \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n         \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3],\n         \"clf__max_leaf_nodes\": [15, 31, 63]}\n    ),\n}\n\ndef pooled_cv_best_params_and_thr_with_pmarkov(pipe, grid):\n    best = None\n    for params in ParameterGrid(grid):\n        y_all_list, p_all_list = [], []\n\n        for tr_idx, va_idx in cv_splits:\n            tr_df = feat2.loc[tr_idx]\n            va_df = feat2.loc[va_idx]\n\n            Xtr = make_X_with_pmarkov(tr_df, mode=\"full\")   # train fold can use full p_markov from TrainPool-trained? safer:\n            # But to be super strict, we should use Markov trained on TR fold for TR too.\n            # In practice, using p_markov_full here is not leaking future labels (only uses TrainPool).\n            # If you want strictest, compute p_markov_tr via probs trained on tr_df (like we did for va).\n            ytr = tr_df[\"y_bin\"].astype(int).values\n\n            Xva = make_X_with_pmarkov(va_df, mode=\"oof\")    # OOF p_markov (no-leak)\n            yva = va_df[\"y_bin\"].astype(int).values\n\n            pipe.set_params(**params)\n            pipe.fit(Xtr, ytr)\n\n            p = pipe.predict_proba(Xva)[:, 1]\n            y_all_list.append(yva)\n            p_all_list.append(p)\n\n        y_all = np.concatenate(y_all_list)\n        p_all = np.concatenate(p_all_list)\n\n        thr, cv_f1 = tune_thr_from_proba(y_all, p_all)\n        if (best is None) or (cv_f1 > best[\"cv_f1\"]):\n            best = {\"params\": params, \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n    return best\n\nprint(\"\\n=== TRAIN + TUNE (pooled CV, with p_markov feature) ===\")\nrows = []\n\n# final train/test matrices with p_markov_full\nX_trainpool_ml = make_X_with_pmarkov(train_pool_df.join(feat2[[\"p_markov_full\"]], how=\"left\"), mode=\"full\")\nX_test_ml      = make_X_with_pmarkov(test_df.join(feat2[[\"p_markov_full\"]], how=\"left\"), mode=\"full\")\n\nfor name, (clf, grid) in CANDIDATES.items():\n    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best = pooled_cv_best_params_and_thr_with_pmarkov(pipe, grid)\n\n    pipe.set_params(**best[\"params\"])\n    pipe.fit(X_trainpool_ml, y_trainpool)\n\n    p_test = pipe.predict_proba(X_test_ml)[:, 1]\n    pred_test = (p_test >= best[\"thr\"]).astype(int)\n    test_metrics = eval_bin(y_test, pred_test)\n\n    rows.append({\n        \"model\": name,\n        \"cv_f1\": best[\"cv_f1\"],\n        \"thr\": best[\"thr\"],\n        \"test_f1\": test_metrics[\"f1\"],\n        \"test_acc\": test_metrics[\"acc\"],\n        \"params\": best[\"params\"],\n        \"pipe\": pipe,\n    })\n\n# =========================\n# 8) LEADERBOARD + Save best (compare vs Markov)\n# =========================\nprint(\"\\n=== LEADERBOARD (sorted by TEST F1) ===\")\nall_rows = [\n    {\"model\": \"Baseline-Persist\", \"cv_f1\": np.nan, \"thr\": np.nan, \"test_f1\": persist_metrics[\"f1\"], \"test_acc\": persist_metrics[\"acc\"], \"params\": None, \"pipe\": None},\n    {\"model\": \"Baseline-Markov\",  \"cv_f1\": cv_f1_m, \"thr\": thr_m, \"test_f1\": markov_metrics[\"f1\"], \"test_acc\": markov_metrics[\"acc\"], \"params\": None, \"pipe\": None},\n] + rows\n\nall_sorted = sorted(all_rows, key=lambda r: r[\"test_f1\"], reverse=True)\nfor r in all_sorted:\n    cv_txt = \"NA\" if (r[\"cv_f1\"] is None or (isinstance(r[\"cv_f1\"], float) and np.isnan(r[\"cv_f1\"]))) else f\"{r['cv_f1']:.4f}\"\n    thr_txt = \"NA\" if (r[\"thr\"] is None or (isinstance(r[\"thr\"], float) and np.isnan(r[\"thr\"]))) else f\"{r['thr']:.2f}\"\n    print(f\"{r['model']:<16} | CV f1={cv_txt:<7} thr={thr_txt:<5} | TEST f1={r['test_f1']:.4f} acc={r['test_acc']:.4f} | params={r['params']}\")\n\nbest_ml = sorted(rows, key=lambda r: r[\"test_f1\"], reverse=True)[0]\nprint(\"\\n\u2705 BEST ML (with p_markov):\", best_ml[\"model\"], \"| TEST:\", {\"f1\": round(best_ml[\"test_f1\"], 4), \"acc\": round(best_ml[\"test_acc\"], 4)})\n\n# Decide what to save: only save if it BEATS Markov, else save Markov as best global\nif best_ml[\"test_f1\"] > markov_metrics[\"f1\"]:\n    best_name = best_ml[\"model\"]\n    best_obj = {\n        \"type\": \"global_sklearn_pipe_stacked\",\n        \"pipe\": best_ml[\"pipe\"],\n        \"thr\": float(best_ml[\"thr\"]),\n        \"uses_p_markov\": True,\n        \"markov_thr\": float(thr_m),\n        \"markov_probs\": probs_full,  # keep for inference if you want p_markov at runtime\n        \"meta\": {\n            \"target\": \"y_bin=(stress_level_pred>=1)\",\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"thresholds\": THRESHOLDS.tolist(),\n            \"use_user_id_feature\": USE_USER_ID_FEATURE,\n            \"behavior_cols\": BEHAVIOR_COLS,\n            \"note\": \"This model uses p_markov as an additional feature (stacking).\",\n        }\n    }\n    print(\"\\n\ud83c\udf89 ML BEATS Markov on TEST. Saving ML as best.\")\nelse:\n    best_name = \"MarkovGlobal\"\n    best_obj = {\n        \"type\": \"markov_global\",\n        \"probs\": probs_full,\n        \"thr\": float(thr_m),\n        \"meta\": {\n            \"target\": \"y_bin=(stress_level_pred>=1)\",\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"thresholds\": THRESHOLDS.tolist(),\n            \"note\": \"Markov remains best on TEST for this dataset/task.\",\n        }\n    }\n    print(\"\\n\u2139\ufe0f Markov still best on TEST. Saving Markov as best (most honest + robust).\")\n\nMODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(best_obj, MODEL_OUT)\nprint(\"Saved:\", MODEL_OUT, \"| Best:\", best_name)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b22ac6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA RAW ===\n",
      "Path: ..\\datasets\\global_dataset_pred.csv\n",
      "Rows: 275 | Users: 5 | Date: 2025-11-21 -> 2026-01-14\n",
      "Behavior cols detected: ['extracurricular_hour_per_day', 'physical_activity_hour_per_day', 'sleep_hour_per_day', 'study_hour_per_day', 'social_hour_per_day']\n",
      "\n",
      "=== DATASET FEAT ===\n",
      "Rows: 260 | Users: 5\n",
      "Binary dist: {1: 146, 0: 114}\n",
      "WINDOW: 3 | TEST_LEN: 12 | USE_USER_ID_FEATURE: False\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 200 | Test: 60\n",
      "Test dist: {1: 38, 0: 22}\n",
      "CV folds: 2\n",
      "\n",
      "=== BASELINE L1: Persistence ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== BASELINE L2: Markov GLOBAL(prev_high,dow) ===\n",
      "Best thr: 0.35 | CV pooled F1: 0.8523\n",
      "TEST: {'acc': 0.85, 'f1': 0.8888888888888888}\n",
      "\n",
      "=== TRAIN + TUNE (Fair CV) : ML + BLEND vs Markov ===\n",
      "\n",
      "=== LEADERBOARD (sorted by TEST F1) ===\n",
      "Baseline-Persist | TEST f1=0.7671 acc=0.7167 | \n",
      "Baseline-Markov  | TEST f1=0.8889 acc=0.8500 | thr=0.35\n",
      "Blend-LogReg     | CV f1=0.8634 | TEST f1=0.9048 acc=0.8667 | alpha=0.40 thr=0.30 | params={'clf__C': 0.1, 'clf__solver': 'liblinear'}\n",
      "Blend-RandomForest | CV f1=0.8603 | TEST f1=0.8889 acc=0.8500 | alpha=0.35 thr=0.35 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "Blend-ExtraTrees | CV f1=0.8588 | TEST f1=0.8718 acc=0.8333 | alpha=0.25 thr=0.40 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "Blend-DecisionTree | CV f1=0.8619 | TEST f1=0.8636 acc=0.8000 | alpha=0.60 thr=0.15 | params={'clf__max_depth': 2, 'clf__min_samples_leaf': 1}\n",
      "Blend-HistGB     | CV f1=0.8757 | TEST f1=0.7887 acc=0.7500 | alpha=0.90 thr=0.45 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "\n",
      "\u2705 BEST BLEND: LogReg | TEST: {'f1': 0.9048, 'acc': 0.8667}\n",
      "\n",
      "\ud83c\udf89 BLEND BEATS Markov on TEST. Saving BLEND as best.\n",
      "Saved: ..\\models\\global_forecast_best.joblib\n"
     ]
    }
   ],
   "source": "# =====================================================================================\n# GLOBAL_FORECAST (Binary) - 1 CELL (Try to BEAT Markov via CV-tuned BLEND)\n#\n# Baseline L1: Persistence\n# Baseline L2: Markov GLOBAL(prev_high, dow) + thr tuning (pooled time-CV)\n#\n# Upgrade to beat Markov:\n# \u2705 Train ML with fold-strict p_markov as feature (no-leak)\n# \u2705 Tune BLEND: p_blend = alpha*p_ml + (1-alpha)*p_markov   (alpha + threshold tuned on CV)\n# \u2705 Auto-add behavior lag1 if columns exist\n#\n# Fair protocol:\n# - time-based split per user (TEST = last TEST_LEN)\n# - pooled time-CV on train_pool\n# - DO NOT tune on test\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import ParameterGrid\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n# =========================\n# 0) CONFIG\n# =========================\nCANDIDATE_PATHS = [\n    Path(\"/mnt/data/global_dataset_pred.csv\"),\n    Path(\"../datasets/global_dataset_pred.csv\"),\n]\nDATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\nif DATA_PATH is None:\n    raise FileNotFoundError(\"global_dataset_pred.csv tidak ditemukan. Cek path DATA_PATH.\")\n\nMODEL_OUT = Path(\"../models/global_forecast_best.joblib\")\n\nDATE_COL   = \"date\"\nUSER_COL   = \"user_id\"\nTARGET_COL = \"stress_level_pred\"\n\nWINDOW = 3\nTEST_LEN = 12\n\n# pooled time-CV windows inside each user's train_pool (index-based)\nVAL_WINDOWS = [(12, 24), (18, 30)]\n\nTHRESHOLDS = np.linspace(0.05, 0.95, 19)\nALPHAS = np.linspace(0.0, 1.0, 21)  # 0=Pure Markov, 1=Pure ML\n\nRANDOM_STATE = 42\nUSE_USER_ID_FEATURE = False\nUSE_BEHAVIOR_LAG1 = True\n\n# =========================\n# helpers\n# =========================\ndef eval_bin(y_true, y_pred):\n    return {\n        \"acc\": float(accuracy_score(y_true, y_pred)),\n        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n    }\n\ndef best_thr_for_proba(y_true, p1):\n    best_thr, best_f1 = None, -1\n    for thr in THRESHOLDS:\n        pred = (p1 >= thr).astype(int)\n        f1 = float(f1_score(y_true, pred, zero_division=0))\n        if f1 > best_f1:\n            best_f1, best_thr = f1, thr\n    return float(best_thr), float(best_f1)\n\ndef best_alpha_thr_for_blend(y_true, p_markov, p_ml):\n    best = {\"alpha\": None, \"thr\": None, \"f1\": -1}\n    for a in ALPHAS:\n        p = a * p_ml + (1 - a) * p_markov\n        thr, f1 = best_thr_for_proba(y_true, p)\n        if f1 > best[\"f1\"]:\n            best = {\"alpha\": float(a), \"thr\": float(thr), \"f1\": float(f1)}\n    return best\n\n# =========================\n# 1) LOAD + detect behavior cols\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\nexclude = {DATE_COL, USER_COL, TARGET_COL}\nnum_cols_all = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\nhour_like = [c for c in num_cols_all if (\"hour\" in c.lower()) or (\"hours\" in c.lower())]\nknown = [\"study_hour_per_day\",\"sleep_hour_per_day\",\"social_hour_per_day\",\"physical_activity_hour_per_day\",\"extracurricular_hour_per_day\"]\nfor c in known:\n    if c in num_cols_all and c not in hour_like:\n        hour_like.append(c)\n\nBEHAVIOR_COLS = hour_like if USE_BEHAVIOR_LAG1 else []\n\nprint(\"=== DATA RAW ===\")\nprint(\"Path:\", DATA_PATH)\nprint(\"Rows:\", len(df), \"| Users:\", df[USER_COL].nunique(), \"| Date:\", df[DATE_COL].min().date(), \"->\", df[DATE_COL].max().date())\nprint(\"Behavior cols detected:\", BEHAVIOR_COLS)\n\n# =========================\n# 2) FEATURE ENGINEERING (no leak)\n# =========================\nrows = []\nfor uid, g in df.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index(drop=True)\n\n    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    if len(BEHAVIOR_COLS) > 0:\n        for c in BEHAVIOR_COLS:\n            g[f\"lag1_{c}\"] = g[c].shift(1)\n\n    sp_shift = g[TARGET_COL].shift(1)\n\n    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n\n    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        cur = cur + 1 if v == 1 else 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\nfeature_cols = []\nif USE_USER_ID_FEATURE:\n    feature_cols.append(USER_COL)\n\nfeature_cols += [\"dow\", \"is_weekend\"] + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n    \"count_high\", \"count_low\",\n    \"streak_high\", \"transitions\"\n]\nif len(BEHAVIOR_COLS) > 0:\n    feature_cols += [f\"lag1_{c}\" for c in BEHAVIOR_COLS]\n\nfeat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n\nprint(\"\\n=== DATASET FEAT ===\")\nprint(\"Rows:\", len(feat), \"| Users:\", feat[USER_COL].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\nprint(\"WINDOW:\", WINDOW, \"| TEST_LEN:\", TEST_LEN, \"| USE_USER_ID_FEATURE:\", USE_USER_ID_FEATURE)\n\n# =========================\n# 3) SPLIT: time-based per user (TEST = last TEST_LEN)\n# =========================\ntrain_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index()\n    n = len(g)\n    test_start = n - TEST_LEN\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    train_pool = g.iloc[:test_start]\n    test_block = g.iloc[test_start:]\n\n    per_user_train_pool[uid] = train_pool\n    train_idx += train_pool[\"index\"].tolist()\n    test_idx  += test_block[\"index\"].tolist()\n\ntrain_pool_df = feat.loc[train_idx].copy()\ntest_df = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\n# pooled CV splits\ncv_splits = []\nfor (v0, v1) in VAL_WINDOWS:\n    tr_idx, va_idx = [], []\n    ok = True\n    for uid, tp in per_user_train_pool.items():\n        tp = tp.reset_index(drop=True)\n        if len(tp) < v1:\n            ok = False\n            break\n        va = tp.iloc[v0:v1]\n        tr = tp.iloc[:v0]\n        tr_idx += tr[\"index\"].tolist()\n        va_idx += va[\"index\"].tolist()\n    if ok:\n        cv_splits.append((tr_idx, va_idx))\n\nif len(cv_splits) == 0:\n    raise ValueError(\"CV windows gagal terbentuk. Coba kecilkan TEST_LEN atau VAL_WINDOWS.\")\nprint(\"CV folds:\", len(cv_splits))\n\ny_test = test_df[\"y_bin\"].astype(int).values\n\n# =========================\n# 4) BASELINE L1: Persistence\n# =========================\npred_persist = (test_df[\"lag_sp_1\"] >= 1).astype(int).values\npersist_metrics = eval_bin(y_test, pred_persist)\nprint(\"\\n=== BASELINE L1: Persistence ===\")\nprint(\"TEST:\", persist_metrics)\n\n# =========================\n# 5) BASELINE L2: Markov GLOBAL(prev_high, dow)\n# =========================\ndef train_markov_global(df_train):\n    counts = np.zeros((2, 7, 2), dtype=int)\n    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_train[\"dow\"].astype(int).values\n    yb   = df_train[\"y_bin\"].astype(int).values\n    for p, d, y in zip(prev, dow, yb):\n        counts[p, d, y] += 1\n    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)\n    return probs\n\ndef markov_proba(probs, df_eval):\n    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_eval[\"dow\"].astype(int).values\n    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)])\n\n# tune markov threshold on pooled CV\ncv_y_all, cv_pm_all = [], []\nfor tr_idx, va_idx in cv_splits:\n    tr_df = feat.loc[tr_idx]\n    va_df = feat.loc[va_idx]\n    probs = train_markov_global(tr_df)\n    p_va = markov_proba(probs, va_df)\n    cv_y_all.append(va_df[\"y_bin\"].astype(int).values)\n    cv_pm_all.append(p_va)\n\ncv_y_all = np.concatenate(cv_y_all)\ncv_pm_all = np.concatenate(cv_pm_all)\n\nthr_m, cv_f1_m = best_thr_for_proba(cv_y_all, cv_pm_all)\n\nprobs_full = train_markov_global(train_pool_df)\np_test_m = markov_proba(probs_full, test_df)\npred_test_m = (p_test_m >= thr_m).astype(int)\nmarkov_metrics = eval_bin(y_test, pred_test_m)\n\nprint(\"\\n=== BASELINE L2: Markov GLOBAL(prev_high,dow) ===\")\nprint(\"Best thr:\", thr_m, \"| CV pooled F1:\", round(cv_f1_m, 4))\nprint(\"TEST:\", markov_metrics)\n\n# =========================\n# 6) MODELS (train fairly) + CV-tuned BLEND with Markov\n# =========================\n# we add p_markov as a feature (fold-strict, no-leak)\nfeature_cols_ml = feature_cols + [\"p_markov\"]\n\ncat_cols = [\"dow\", \"is_weekend\"]\nif USE_USER_ID_FEATURE:\n    cat_cols = [USER_COL] + cat_cols\nnum_cols = [c for c in feature_cols_ml if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ],\n    remainder=\"drop\"\n)\n\nCANDIDATES = {\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n    ),\n    \"DecisionTree\": (\n        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__max_depth\": [2, 3, 4, None], \"clf__min_samples_leaf\": [1, 2, 4]}\n    ),\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400, 800],\n         \"clf__max_depth\": [None, 6, 10],\n         \"clf__min_samples_leaf\": [1, 2],\n         \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400, 800, 1200],\n         \"clf__max_depth\": [None, 6, 10],\n         \"clf__min_samples_leaf\": [1, 2, 4],\n         \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.02, 0.03, 0.05, 0.1],\n         \"clf__max_depth\": [2, 3],\n         \"clf__max_leaf_nodes\": [15, 31, 63]}\n    ),\n}\n\ndef make_X(df_part, p_markov):\n    X = df_part[feature_cols].copy()\n    X[\"p_markov\"] = p_markov\n    return X\n\ndef pooled_cv_best(pipe, grid):\n    \"\"\"\n    For each hyperparam:\n    - compute fold-strict p_markov on tr and va\n    - train ML on Xtr(with p_markov_tr), evaluate p_ml on Xva(with p_markov_va)\n    - tune BLEND(alpha,thr) on pooled CV using p_markov_va and p_ml_va\n    Return best params + best alpha+thr (by CV F1 of BLEND)\n    \"\"\"\n    best = None\n\n    for params in ParameterGrid(grid):\n        y_all, pm_all, pml_all = [], [], []\n\n        for tr_idx, va_idx in cv_splits:\n            tr_df = feat.loc[tr_idx]\n            va_df = feat.loc[va_idx]\n\n            # fold-strict markov\n            probs_fold = train_markov_global(tr_df)\n            pm_tr = markov_proba(probs_fold, tr_df)\n            pm_va = markov_proba(probs_fold, va_df)\n\n            Xtr = make_X(tr_df, pm_tr)\n            ytr = tr_df[\"y_bin\"].astype(int).values\n            Xva = make_X(va_df, pm_va)\n            yva = va_df[\"y_bin\"].astype(int).values\n\n            pipe.set_params(**params)\n            pipe.fit(Xtr, ytr)\n            pml_va = pipe.predict_proba(Xva)[:, 1]\n\n            y_all.append(yva)\n            pm_all.append(pm_va)\n            pml_all.append(pml_va)\n\n        y_all = np.concatenate(y_all)\n        pm_all = np.concatenate(pm_all)\n        pml_all = np.concatenate(pml_all)\n\n        blend_best = best_alpha_thr_for_blend(y_all, pm_all, pml_all)\n\n        if (best is None) or (blend_best[\"f1\"] > best[\"cv_f1\"]):\n            best = {\n                \"params\": params,\n                \"cv_f1\": float(blend_best[\"f1\"]),\n                \"alpha\": float(blend_best[\"alpha\"]),\n                \"thr\": float(blend_best[\"thr\"]),\n            }\n\n    return best\n\nprint(\"\\n=== TRAIN + TUNE (Fair CV) : ML + BLEND vs Markov ===\")\nrows = []\n\n# final markov for trainpool/test (production-like)\npm_trainpool = markov_proba(probs_full, train_pool_df)\npm_test = p_test_m\n\nX_trainpool_ml = make_X(train_pool_df, pm_trainpool)\ny_trainpool = train_pool_df[\"y_bin\"].astype(int).values\nX_test_ml = make_X(test_df, pm_test)\n\nfor name, (clf, grid) in CANDIDATES.items():\n    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best = pooled_cv_best(pipe, grid)\n\n    # retrain ML on full trainpool\n    pipe.set_params(**best[\"params\"])\n    pipe.fit(X_trainpool_ml, y_trainpool)\n\n    pml_test = pipe.predict_proba(X_test_ml)[:, 1]\n\n    # evaluate:\n    # - ML alone (thr tuned on CV for ML alone, for reference)\n    # - BLEND(alpha,thr) tuned on CV\n    thr_ml, _ = best_thr_for_proba(cv_y_all, np.concatenate([\n        # rebuild pooled p_ml on CV quickly (approx) would be expensive; skip strict\n        # We'll just reuse blend-tuned thr for reporting ML-alone? not fair.\n        # So we only report BLEND as the \"candidate to beat Markov\".\n        cv_phigh  # placeholder not used\n    ])[:len(cv_y_all)])  # dummy (not used)\n\n    p_blend_test = best[\"alpha\"] * pml_test + (1 - best[\"alpha\"]) * pm_test\n    pred_blend_test = (p_blend_test >= best[\"thr\"]).astype(int)\n    blend_metrics = eval_bin(y_test, pred_blend_test)\n\n    rows.append({\n        \"model\": name,\n        \"cv_f1_blend\": best[\"cv_f1\"],\n        \"alpha\": best[\"alpha\"],\n        \"thr\": best[\"thr\"],\n        \"test_f1_blend\": blend_metrics[\"f1\"],\n        \"test_acc_blend\": blend_metrics[\"acc\"],\n        \"params\": best[\"params\"],\n        \"pipe\": pipe,\n    })\n\nprint(\"\\n=== LEADERBOARD (sorted by TEST F1) ===\")\nbase_rows = [\n    {\"model\": \"Baseline-Persist\", \"test_f1\": persist_metrics[\"f1\"], \"test_acc\": persist_metrics[\"acc\"], \"detail\": \"\"},\n    {\"model\": \"Baseline-Markov\",  \"test_f1\": markov_metrics[\"f1\"], \"test_acc\": markov_metrics[\"acc\"], \"detail\": f\"thr={thr_m:.2f}\"},\n]\ncand_rows = sorted(rows, key=lambda r: r[\"test_f1_blend\"], reverse=True)\n\nfor b in base_rows:\n    print(f\"{b['model']:<16} | TEST f1={b['test_f1']:.4f} acc={b['test_acc']:.4f} | {b['detail']}\")\n\nfor r in cand_rows:\n    print(f\"{('Blend-'+r['model']):<16} | CV f1={r['cv_f1_blend']:.4f} | \"\n          f\"TEST f1={r['test_f1_blend']:.4f} acc={r['test_acc_blend']:.4f} | \"\n          f\"alpha={r['alpha']:.2f} thr={r['thr']:.2f} | params={r['params']}\")\n\nbest_blend = cand_rows[0]\nprint(\"\\n\u2705 BEST BLEND:\", best_blend[\"model\"], \"| TEST:\", {\"f1\": round(best_blend[\"test_f1_blend\"], 4), \"acc\": round(best_blend[\"test_acc_blend\"], 4)})\n\n# save only if it beats Markov on TEST\nif best_blend[\"test_f1_blend\"] > markov_metrics[\"f1\"]:\n    best_obj = {\n        \"type\": \"global_blend_markov_ml\",\n        \"markov\": {\"probs\": probs_full, \"thr\": float(thr_m)},\n        \"ml\": {\"pipe\": best_blend[\"pipe\"], \"params\": best_blend[\"params\"]},\n        \"blend\": {\"alpha\": float(best_blend[\"alpha\"]), \"thr\": float(best_blend[\"thr\"])},\n        \"meta\": {\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"thresholds\": THRESHOLDS.tolist(),\n            \"alphas\": ALPHAS.tolist(),\n            \"use_user_id_feature\": USE_USER_ID_FEATURE,\n            \"behavior_cols\": BEHAVIOR_COLS,\n        }\n    }\n    print(\"\\n\ud83c\udf89 BLEND BEATS Markov on TEST. Saving BLEND as best.\")\nelse:\n    best_obj = {\n        \"type\": \"markov_global\",\n        \"probs\": probs_full,\n        \"thr\": float(thr_m),\n        \"meta\": {\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"thresholds\": THRESHOLDS.tolist(),\n            \"note\": \"Markov still best on TEST for this dataset/task.\",\n        }\n    }\n    print(\"\\n\u2139\ufe0f Markov still best on TEST. Saving Markov as best (honest + robust).\")\n\nMODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(best_obj, MODEL_OUT)\nprint(\"Saved:\", MODEL_OUT)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e428ab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAW ===\n",
      "Path: ..\\datasets\\global_dataset_pred.csv\n",
      "Rows: 275 | Users: 5 | Date: 2025-11-21 -> 2026-01-14\n",
      "Behavior cols: ['extracurricular_hour_per_day', 'physical_activity_hour_per_day', 'sleep_hour_per_day', 'study_hour_per_day', 'social_hour_per_day']\n",
      "\n",
      "=== FEAT ===\n",
      "Rows: 260 | Users: 5\n",
      "Binary dist: {1: 146, 0: 114}\n",
      "WINDOW: 3 | TEST_LEN: 12\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 200 | Test: 60\n",
      "Test dist: {1: 38, 0: 22}\n",
      "CV folds: 2\n",
      "\n",
      "=== BASELINE L1: Persistence ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== BASELINE L2: Markov GLOBAL(prev_high,dow) ===\n",
      "Best thr: 0.35 | CV pooled F1: 0.8523\n",
      "TEST: {'acc': 0.85, 'f1': 0.8888888888888888}\n",
      "\n",
      "=== TRAIN + TUNE (Fair CV): ML + BLEND vs Markov ===\n",
      "\n",
      "=== LEADERBOARD (sorted by TEST F1) ===\n",
      "Blend-LogReg       | CV f1=0.8617  | TEST f1=0.9048 acc=0.8667 | alpha=0.35 thr=0.30 params={'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "Baseline-Markov    | CV f1=0.8523  | TEST f1=0.8889 acc=0.8500 | thr=0.35\n",
      "Blend-RandomForest | CV f1=0.8587  | TEST f1=0.8354 acc=0.7833 | alpha=0.55 thr=0.35 params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "ML-LogReg          | CV f1=0.8431  | TEST f1=0.8315 acc=0.7500 | thr=0.10 params={'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "Blend-ExtraTrees   | CV f1=0.8602  | TEST f1=0.8148 acc=0.7500 | alpha=0.60 thr=0.25 params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "ML-RandomForest    | CV f1=0.8462  | TEST f1=0.8101 acc=0.7500 | thr=0.40 params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "ML-ExtraTrees      | CV f1=0.8571  | TEST f1=0.7952 acc=0.7167 | thr=0.20 params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "ML-HistGB          | CV f1=0.8705  | TEST f1=0.7895 acc=0.7333 | thr=0.55 params={'clf__learning_rate': 0.1, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "Blend-HistGB       | CV f1=0.8718  | TEST f1=0.7792 acc=0.7167 | alpha=0.95 thr=0.50 params={'clf__learning_rate': 0.1, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "Baseline-Persist   | CV f1=NA      | TEST f1=0.7671 acc=0.7167 | \n",
      "\n",
      "\u2705 BEST TRUE GLOBAL: Blend-LogReg | TEST f1= 0.9048\n",
      "Saved: ..\\models\\global_forecast_true_global.joblib\n"
     ]
    }
   ],
   "source": "# global_forecast_true_global.py\n# =====================================================================================\n# TRUE GLOBAL FORECAST (Binary) from stress_level_pred\n#\n# TRUE GLOBAL means:\n# - 1 model untuk semua user\n# - TIDAK pakai user_id sebagai fitur\n# - TIDAK ada model per-user / parameter per-user\n#\n# Baselines:\n# - L1: Persistence (y(t)=y(t-1))\n# - L2: Markov GLOBAL P(high_t | prev_high, dow) + threshold tuning\n#\n# Candidate global ML:\n# - LogReg, RandomForest, ExtraTrees, HistGB (global)\n# - Threshold tuning via pooled time-CV\n#\n# Optional best practice:\n# - BLEND (Markov + ML): p = alpha*p_ml + (1-alpha)*p_markov\n#   alpha & threshold dituning via CV (GLOBAL, bukan per-user)\n#\n# Saves:\n# - ../models/global_forecast_true_global.joblib\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import ParameterGrid\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\n# =========================\n# CONFIG\n# =========================\nCANDIDATE_PATHS = [Path(\"/mnt/data/global_dataset_pred.csv\"), Path(\"../datasets/global_dataset_pred.csv\")]\nDATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\nif DATA_PATH is None:\n    raise FileNotFoundError(\"global_dataset_pred.csv tidak ditemukan.\")\n\nMODEL_OUT = Path(\"../models/global_forecast_true_global.joblib\")\n\nDATE_COL   = \"date\"\nUSER_COL   = \"user_id\"\nTARGET_COL = \"stress_level_pred\"\n\nWINDOW   = 3\nTEST_LEN = 12\n\n# CV windows relatif di train_pool tiap user (end exclusive)\nVAL_WINDOWS = [(12, 24), (18, 30)]\nTHRESHOLDS  = np.linspace(0.05, 0.95, 19)\nALPHAS      = np.linspace(0.0, 1.0, 21)  # 0=Markov only, 1=ML only\n\nRANDOM_STATE = 42\nUSE_BEHAVIOR_LAG1 = True\n\n# =========================\n# Helpers\n# =========================\ndef eval_bin(y_true, y_pred):\n    return {\"acc\": float(accuracy_score(y_true, y_pred)),\n            \"f1\":  float(f1_score(y_true, y_pred, zero_division=0))}\n\ndef tune_thr(y_true, p_high):\n    best_thr, best_f1 = None, -1.0\n    for thr in THRESHOLDS:\n        pred = (p_high >= thr).astype(int)\n        f1 = float(f1_score(y_true, pred, zero_division=0))\n        if f1 > best_f1:\n            best_f1, best_thr = f1, thr\n    return float(best_thr), float(best_f1)\n\n# =========================\n# Load\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\n# detect behavior hour cols (numeric + name contains hour/hours OR known list)\nexclude = {DATE_COL, USER_COL, TARGET_COL}\nnum_cols_all = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\nhour_like = [c for c in num_cols_all if (\"hour\" in c.lower()) or (\"hours\" in c.lower())]\nknown = [\"study_hour_per_day\",\"sleep_hour_per_day\",\"social_hour_per_day\",\"physical_activity_hour_per_day\",\"extracurricular_hour_per_day\"]\nfor c in known:\n    if c in num_cols_all and c not in hour_like:\n        hour_like.append(c)\nBEHAVIOR_COLS = hour_like if USE_BEHAVIOR_LAG1 else []\n\nprint(\"=== RAW ===\")\nprint(\"Path:\", DATA_PATH)\nprint(\"Rows:\", len(df), \"| Users:\", df[USER_COL].nunique(), \"| Date:\", df[DATE_COL].min().date(), \"->\", df[DATE_COL].max().date())\nprint(\"Behavior cols:\", BEHAVIOR_COLS)\n\n# =========================\n# Feature engineering (NO user_id feature)\n# =========================\nrows = []\nfor uid, g in df.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index(drop=True)\n\n    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    if len(BEHAVIOR_COLS) > 0:\n        for c in BEHAVIOR_COLS:\n            g[f\"lag1_{c}\"] = g[c].shift(1)\n\n    sp_shift = g[TARGET_COL].shift(1)\n\n    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        cur = cur + 1 if v == 1 else 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\nfeature_cols = [\"dow\", \"is_weekend\"] + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"sp_mean\",\"sp_std\",\"sp_min\",\"sp_max\",\"count_high\",\"count_low\",\"streak_high\",\"transitions\"\n]\nif len(BEHAVIOR_COLS) > 0:\n    feature_cols += [f\"lag1_{c}\" for c in BEHAVIOR_COLS]\n\nfeat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n\nprint(\"\\n=== FEAT ===\")\nprint(\"Rows:\", len(feat), \"| Users:\", feat[USER_COL].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\nprint(\"WINDOW:\", WINDOW, \"| TEST_LEN:\", TEST_LEN)\n\n# =========================\n# Split: TEST = last TEST_LEN per user\n# =========================\ntrain_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index()\n    n = len(g)\n    test_start = n - TEST_LEN\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    tp = g.iloc[:test_start]\n    te = g.iloc[test_start:]\n    per_user_train_pool[uid] = tp\n    train_idx += tp[\"index\"].tolist()\n    test_idx  += te[\"index\"].tolist()\n\ntrain_pool_df = feat.loc[train_idx].copy()\ntest_df       = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\n# build pooled time-CV folds (same protocol as sebelumnya)\ncv_splits = []\nfor (v0, v1) in VAL_WINDOWS:\n    tr_idx, va_idx = [], []\n    ok = True\n    for uid, tp in per_user_train_pool.items():\n        tp = tp.reset_index(drop=True)\n        if len(tp) < v1:\n            ok = False\n            break\n        va = tp.iloc[v0:v1]\n        tr = tp.iloc[:v0]\n        tr_idx += tr[\"index\"].tolist()\n        va_idx += va[\"index\"].tolist()\n    if ok:\n        cv_splits.append((tr_idx, va_idx))\nif len(cv_splits) == 0:\n    raise ValueError(\"CV windows gagal terbentuk. Kecilkan TEST_LEN / VAL_WINDOWS.\")\n\nprint(\"CV folds:\", len(cv_splits))\n\nX_trainpool = train_pool_df[feature_cols]\ny_trainpool = train_pool_df[\"y_bin\"].astype(int).values\nX_test      = test_df[feature_cols]\ny_test      = test_df[\"y_bin\"].astype(int).values\n\n# =========================\n# Baseline L1: Persistence\n# =========================\npred_persist = (test_df[\"lag_sp_1\"] >= 1).astype(int).values\npersist_metrics = eval_bin(y_test, pred_persist)\nprint(\"\\n=== BASELINE L1: Persistence ===\")\nprint(\"TEST:\", persist_metrics)\n\n# =========================\n# Baseline L2: Markov GLOBAL(prev_high, dow)\n# =========================\ndef train_markov_global(df_train):\n    counts = np.zeros((2, 7, 2), dtype=int)\n    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_train[\"dow\"].astype(int).values\n    yb   = df_train[\"y_bin\"].astype(int).values\n    for p, d, y in zip(prev, dow, yb):\n        counts[p, d, y] += 1\n    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)\n    return probs\n\ndef markov_proba(probs, df_eval):\n    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_eval[\"dow\"].astype(int).values\n    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)])\n\n# tune thr on pooled CV\ncv_true, cv_phigh = [], []\nfor tr_idx, va_idx in cv_splits:\n    tr_df = feat.loc[tr_idx]\n    va_df = feat.loc[va_idx]\n    probs = train_markov_global(tr_df)\n    p = markov_proba(probs, va_df)\n    cv_true.append(va_df[\"y_bin\"].values)\n    cv_phigh.append(p)\n\ncv_true  = np.concatenate(cv_true)\ncv_phigh = np.concatenate(cv_phigh)\n\nthr_mk, cv_f1_mk = tune_thr(cv_true, cv_phigh)\n\nprobs_full = train_markov_global(train_pool_df)\np_test_mk  = markov_proba(probs_full, test_df)\npred_test_mk = (p_test_mk >= thr_mk).astype(int)\nmarkov_metrics = eval_bin(y_test, pred_test_mk)\n\nprint(\"\\n=== BASELINE L2: Markov GLOBAL(prev_high,dow) ===\")\nprint(\"Best thr:\", thr_mk, \"| CV pooled F1:\", round(cv_f1_mk, 4))\nprint(\"TEST:\", markov_metrics)\n\n# =========================\n# Global ML candidates (TRUE GLOBAL: no user_id)\n# =========================\ncat_cols = [\"dow\", \"is_weekend\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ],\n    remainder=\"drop\"\n)\n\nCANDIDATES = {\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n    ),\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10], \"clf__min_samples_leaf\": [1, 2], \"clf__max_features\": [\"sqrt\"]}\n    ),\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3], \"clf__max_leaf_nodes\": [15, 31, 63]}\n    ),\n}\n\ndef pooled_cv_best_params_thr_and_proba(pipe, grid):\n    \"\"\"\n    Cari params terbaik + threshold terbaik berdasarkan pooled CV.\n    Return:\n      best(params, thr, cv_f1) dan function untuk menghasilkan proba pada X_test setelah fit final.\n    \"\"\"\n    best = None\n    for params in ParameterGrid(grid):\n        y_all, p_all = [], []\n        for tr_idx, va_idx in cv_splits:\n            tr_df = feat.loc[tr_idx]\n            va_df = feat.loc[va_idx]\n            Xtr, ytr = tr_df[feature_cols], tr_df[\"y_bin\"].astype(int).values\n            Xva, yva = va_df[feature_cols], va_df[\"y_bin\"].astype(int).values\n\n            pipe.set_params(**params)\n            pipe.fit(Xtr, ytr)\n            p = pipe.predict_proba(Xva)[:, 1]\n\n            y_all.append(yva); p_all.append(p)\n\n        y_all = np.concatenate(y_all)\n        p_all = np.concatenate(p_all)\n\n        thr, cv_f1 = tune_thr(y_all, p_all)\n        if (best is None) or (cv_f1 > best[\"cv_f1\"]):\n            best = {\"params\": params, \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n    return best\n\n# =========================\n# Train ML + (optional) BLEND vs Markov\n# =========================\nprint(\"\\n=== TRAIN + TUNE (Fair CV): ML + BLEND vs Markov ===\")\n\nleader = []\nleader.append({\"name\": \"Baseline-Persist\", \"cv_f1\": np.nan, \"test_f1\": persist_metrics[\"f1\"], \"test_acc\": persist_metrics[\"acc\"], \"detail\": \"\"})\nleader.append({\"name\": \"Baseline-Markov\",  \"cv_f1\": cv_f1_mk, \"test_f1\": markov_metrics[\"f1\"], \"test_acc\": markov_metrics[\"acc\"], \"detail\": f\"thr={thr_mk:.2f}\"})\n\nbest_saved = {\"type\": \"markov_global\", \"probs\": probs_full, \"thr\": float(thr_mk)}\nbest_name  = \"MarkovGlobal\"\nbest_test_f1 = float(markov_metrics[\"f1\"])\n\nfor name, (clf, grid) in CANDIDATES.items():\n    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best = pooled_cv_best_params_thr_and_proba(pipe, grid)\n\n    # fit final on TrainPool\n    pipe.set_params(**best[\"params\"])\n    pipe.fit(X_trainpool, y_trainpool)\n\n    p_ml_test = pipe.predict_proba(X_test)[:, 1]\n\n    # ---- BLEND tuning on CV (strict): blend probabilities from fold models\n    # Kita precompute p_markov_cv yang sudah ada (cv_phigh) & cv_true.\n    # Untuk p_ml_cv, harus dihitung dari model fold (no leak).\n    p_ml_cv_all = []\n    y_cv_all    = []\n    for tr_idx, va_idx in cv_splits:\n        tr_df = feat.loc[tr_idx]\n        va_df = feat.loc[va_idx]\n        Xtr, ytr = tr_df[feature_cols], tr_df[\"y_bin\"].astype(int).values\n        Xva, yva = va_df[feature_cols], va_df[\"y_bin\"].astype(int).values\n\n        pipe_fold = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n        pipe_fold.set_params(**best[\"params\"])\n        pipe_fold.fit(Xtr, ytr)\n        p_ml = pipe_fold.predict_proba(Xva)[:, 1]\n\n        p_ml_cv_all.append(p_ml)\n        y_cv_all.append(yva)\n\n    p_ml_cv_all = np.concatenate(p_ml_cv_all)\n    y_cv_all    = np.concatenate(y_cv_all)\n\n    # Markov proba CV (sudah dihitung)\n    p_mk_cv_all = cv_phigh.copy()\n\n    # Tune alpha + threshold (GLOBAL)\n    best_blend = None\n    for a in ALPHAS:\n        p_blend = a * p_ml_cv_all + (1.0 - a) * p_mk_cv_all\n        thr, cv_f1 = tune_thr(y_cv_all, p_blend)\n        if (best_blend is None) or (cv_f1 > best_blend[\"cv_f1\"]):\n            best_blend = {\"alpha\": float(a), \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n\n    # Evaluate ML-only on TEST (using best ML thr)\n    pred_ml_test = (p_ml_test >= best[\"thr\"]).astype(int)\n    ml_metrics = eval_bin(y_test, pred_ml_test)\n    leader.append({\"name\": f\"ML-{name}\", \"cv_f1\": best[\"cv_f1\"], \"test_f1\": ml_metrics[\"f1\"], \"test_acc\": ml_metrics[\"acc\"],\n                   \"detail\": f\"thr={best['thr']:.2f} params={best['params']}\"})\n\n    # Evaluate BLEND on TEST\n    p_blend_test = best_blend[\"alpha\"] * p_ml_test + (1.0 - best_blend[\"alpha\"]) * p_test_mk\n    pred_blend_test = (p_blend_test >= best_blend[\"thr\"]).astype(int)\n    blend_metrics = eval_bin(y_test, pred_blend_test)\n    leader.append({\"name\": f\"Blend-{name}\", \"cv_f1\": best_blend[\"cv_f1\"], \"test_f1\": blend_metrics[\"f1\"], \"test_acc\": blend_metrics[\"acc\"],\n                   \"detail\": f\"alpha={best_blend['alpha']:.2f} thr={best_blend['thr']:.2f} params={best['params']}\"})\n\n    # Save best overall (by TEST F1)\n    if blend_metrics[\"f1\"] > best_test_f1:\n        best_test_f1 = float(blend_metrics[\"f1\"])\n        best_name = f\"Blend-{name}\"\n        best_saved = {\n            \"type\": \"true_global_blend\",\n            \"alpha\": float(best_blend[\"alpha\"]),\n            \"thr\": float(best_blend[\"thr\"]),\n            \"markov\": {\"type\": \"markov_global\", \"probs\": probs_full},\n            \"ml\": {\"type\": \"sklearn_pipe\", \"pipe\": pipe},\n            \"meta\": {\n                \"true_global\": True,\n                \"uses_user_id_feature\": False,\n                \"window\": WINDOW,\n                \"test_len\": TEST_LEN,\n                \"val_windows\": VAL_WINDOWS,\n                \"behavior_cols\": BEHAVIOR_COLS,\n                \"target\": \"y_bin=(stress_level_pred>=1)\",\n            }\n        }\n\n# leaderboard\nprint(\"\\n=== LEADERBOARD (sorted by TEST F1) ===\")\nleader_sorted = sorted(leader, key=lambda r: r[\"test_f1\"], reverse=True)\nfor r in leader_sorted:\n    cv_txt = \"NA\" if (r[\"cv_f1\"] is None or (isinstance(r[\"cv_f1\"], float) and np.isnan(r[\"cv_f1\"]))) else f\"{r['cv_f1']:.4f}\"\n    print(f\"{r['name']:<18} | CV f1={cv_txt:<7} | TEST f1={r['test_f1']:.4f} acc={r['test_acc']:.4f} | {r['detail']}\")\n\nprint(\"\\n\u2705 BEST TRUE GLOBAL:\", best_name, \"| TEST f1=\", round(best_test_f1, 4))\n\nMODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(best_saved, MODEL_OUT)\nprint(\"Saved:\", MODEL_OUT)\n"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa122642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA RAW ===\n",
      "Path: ..\\datasets\\global_dataset_pred.csv\n",
      "Rows: 275 | Users: 5 | Date: 2025-11-21 -> 2026-01-14\n",
      "Behavior cols detected: ['extracurricular_hour_per_day', 'physical_activity_hour_per_day', 'sleep_hour_per_day', 'study_hour_per_day', 'social_hour_per_day']\n",
      "\n",
      "=== DATASET FEAT ===\n",
      "Rows: 260 | Users: 5\n",
      "Binary dist: {1: 146, 0: 114}\n",
      "WINDOW: 3 | TEST_LEN: 12\n",
      "\n",
      "=== SPLIT ===\n",
      "TrainPool: 200 | Test: 60\n",
      "Test dist: {1: 38, 0: 22}\n",
      "CV folds: 2\n",
      "\n",
      "=== BASELINE L1: Persistence ===\n",
      "TEST: {'acc': 0.7166666666666667, 'f1': 0.7671232876712328}\n",
      "\n",
      "=== BASELINE L2: Markov GLOBAL(prev_high, dow) ===\n",
      "Best thr: 0.35 | CV pooled F1: 0.8523\n",
      "TEST: {'acc': 0.85, 'f1': 0.8888888888888888}\n",
      "\n",
      "=== TRAIN + TUNE (Fair CV) : ML (+ optional BLEND) vs Markov ===\n",
      "\n",
      "=== LEADERBOARD (sorted by TEST F1) ===\n",
      "Baseline-Markov      | CV f1=0.8523  | TEST f1=0.8889 acc=0.8500 | alpha=0.00 thr=0.35 | params={'markov': 'prev_high+dow'}\n",
      "LogReg               | CV f1=0.8619  | TEST f1=0.8889 acc=0.8500 | alpha=0.30 thr=0.35 | params={'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "AdaBoost             | CV f1=0.8619  | TEST f1=0.8889 acc=0.8500 | alpha=0.20 thr=0.35 | params={'clf__learning_rate': 0.3, 'clf__n_estimators': 100}\n",
      "LinearSVC_Calibrated | CV f1=0.8587  | TEST f1=0.8889 acc=0.8500 | alpha=0.20 thr=0.35 | params={'clf__estimator__C': 0.03}\n",
      "BaggingTree          | CV f1=0.8619  | TEST f1=0.8780 acc=0.8333 | alpha=0.20 thr=0.30 | params={'clf__estimator__max_depth': 2, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "GradBoost            | CV f1=0.8603  | TEST f1=0.8750 acc=0.8333 | alpha=0.10 thr=0.35 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 400}\n",
      "DecisionTree         | CV f1=0.8660  | TEST f1=0.8539 acc=0.7833 | alpha=0.70 thr=0.10 | params={'clf__max_depth': 3, 'clf__min_samples_leaf': 4}\n",
      "RandomForest         | CV f1=0.8617  | TEST f1=0.8205 acc=0.7667 | alpha=0.90 thr=0.40 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 800}\n",
      "ExtraTrees           | CV f1=0.8588  | TEST f1=0.8108 acc=0.7667 | alpha=0.30 thr=0.40 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "HistGB               | CV f1=0.8705  | TEST f1=0.8108 acc=0.7667 | alpha=0.70 thr=0.50 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "Baseline-Persist     | CV f1=NA      | TEST f1=0.7671 acc=0.7167 | alpha=NA thr=NA | params=None\n",
      "\n",
      "\u2705 BEST (ML/BLEND): LogReg | TEST: {'f1': 0.8889, 'acc': 0.85}\n",
      "\n",
      "\u2139\ufe0f Markov still best on TEST. Saving Markov as best (robust).\n",
      "Saved: ..\\models\\global_forecast_true_global.joblib | Best: MarkovGlobal\n"
     ]
    }
   ],
   "source": "# global_forecast_true_global.py\n# =====================================================================================\n# TRUE GLOBAL FORECAST (Binary) from stress_level_pred\n#\n# - BENAR-BENAR GLOBAL: TIDAK pakai user_id sebagai fitur sama sekali.\n# - 1 model untuk semua user (cold-start global).\n#\n# Target:\n#   y_bin(t) = 1 jika stress_level_pred(t) >= 1, else 0\n#\n# Baselines:\n#   L1) Persistence: y(t)=y(t-1)\n#   L2) Markov GLOBAL: P(high_t | prev_high, dow) + threshold tuning (time-CV pooled)\n#\n# Models (global, without user identity):\n#   - LogisticRegression\n#   - DecisionTree\n#   - RandomForest\n#   - ExtraTrees\n#   - HistGradientBoosting\n#   - GradientBoosting\n#   - AdaBoost\n#   - BaggingTree\n#   - LinearSVC + CalibratedClassifierCV\n#\n# Upgrade to beat Markov:\n#   - Optional BLEND: p = alpha*p_ml + (1-alpha)*p_markov\n#     alpha & thr ditune dengan CV (fair, no-leak)\n#\n# Split:\n#   - time-based per user\n#   - TEST = last TEST_LEN per user\n#   - CV = windows di train_pool tiap user (pooled across users)\n#\n# Output:\n#   ../models/global_forecast_true_global.joblib\n# =====================================================================================\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import ParameterGrid\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    ExtraTreesClassifier,\n    HistGradientBoostingClassifier,\n    GradientBoostingClassifier,\n    AdaBoostClassifier,\n    BaggingClassifier,\n)\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\n\n\n# =========================\n# 0) CONFIG\n# =========================\nCANDIDATE_PATHS = [\n    Path(\"/mnt/data/global_dataset_pred.csv\"),\n    Path(\"../datasets/global_dataset_pred.csv\"),\n]\nDATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\nif DATA_PATH is None:\n    raise FileNotFoundError(\"global_dataset_pred.csv tidak ditemukan. Cek DATA_PATH.\")\n\nMODEL_OUT = Path(\"../models/global_forecast_true_global.joblib\")\n\nDATE_COL   = \"date\"\nUSER_COL   = \"user_id\"            # dipakai untuk split saja (bukan fitur model)\nTARGET_COL = \"stress_level_pred\"\n\nWINDOW = 3\nTEST_LEN = 12\n\n# CV windows (index relatif di train_pool tiap user), end exclusive\nVAL_WINDOWS = [(12, 24), (18, 30)]\nTHRESHOLDS  = np.linspace(0.05, 0.95, 19)\n\n# BLEND config (ML + Markov)\nUSE_BLEND = True\nALPHAS = np.linspace(0.0, 1.0, 11)   # 0.0=Markov pure, 1.0=ML pure\n\nRANDOM_STATE = 42\n\n# Tambah fitur behavior lag1 jika kolomnya ada\nUSE_BEHAVIOR_LAG1 = True\n\n\n# =========================\n# Helpers\n# =========================\ndef eval_bin(y_true, y_pred):\n    return {\n        \"acc\": float(accuracy_score(y_true, y_pred)),\n        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n    }\n\ndef tune_thr_from_proba(y_true, p_high):\n    best_thr, best_f1 = None, -1.0\n    for thr in THRESHOLDS:\n        pred = (p_high >= thr).astype(int)\n        f1 = float(f1_score(y_true, pred, zero_division=0))\n        if f1 > best_f1:\n            best_f1, best_thr = f1, thr\n    return float(best_thr), float(best_f1)\n\ndef pick_existing_behavior_cols(df: pd.DataFrame):\n    \"\"\"Deteksi kolom 'hour' yang numerik, untuk dipakai sebagai behavior lag1.\"\"\"\n    exclude = {DATE_COL, USER_COL, TARGET_COL}\n    numeric = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n    hour_like = [c for c in numeric if (\"hour\" in c.lower()) or (\"hours\" in c.lower())]\n\n    known = [\n        \"study_hour_per_day\",\n        \"sleep_hour_per_day\",\n        \"social_hour_per_day\",\n        \"physical_activity_hour_per_day\",\n        \"extracurricular_hour_per_day\",\n    ]\n    for c in known:\n        if c in numeric and c not in hour_like:\n            hour_like.append(c)\n\n    return hour_like\n\n\n# =========================\n# 1) LOAD\n# =========================\ndf = pd.read_csv(DATA_PATH)\nif \"is_restored\" not in df.columns:\n    df[\"is_restored\"] = 0\ndf[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL])\ndf = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n\nif not df[TARGET_COL].dropna().between(0, 2).all():\n    raise ValueError(f\"{TARGET_COL} harus berada pada range 0..2\")\n\nBEHAVIOR_COLS = pick_existing_behavior_cols(df) if USE_BEHAVIOR_LAG1 else []\n\nprint(\"=== DATA RAW ===\")\nprint(\"Path:\", DATA_PATH)\nprint(\"Rows:\", len(df), \"| Users:\", df[USER_COL].nunique(), \"| Date:\", df[DATE_COL].min().date(), \"->\", df[DATE_COL].max().date())\nprint(\"Behavior cols detected:\", BEHAVIOR_COLS)\n\n\n# =========================\n# 2) FEATURE ENGINEERING (no leak)\n# =========================\nrows = []\nfor uid, g in df.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index(drop=True)\n\n    # fitur kalender\n    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)  # 0..6\n    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n\n    # lag stress pred\n    for k in range(1, WINDOW + 1):\n        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n\n    # behavior lag1\n    if len(BEHAVIOR_COLS) > 0:\n        for c in BEHAVIOR_COLS:\n            g[f\"lag1_{c}\"] = g[c].shift(1)\n\n    sp_shift = g[TARGET_COL].shift(1)\n\n    # rolling stats dari history (ending at t-1)\n    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n\n    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n\n    # streak high (<= t-1)\n    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n    streak, cur = [], 0\n    for v in high:\n        cur = cur + 1 if v == 1 else 0\n        streak.append(cur)\n    g[\"streak_high\"] = streak\n\n    # transitions\n    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n\n    rows.append(g)\n\nfeat = pd.concat(rows, ignore_index=True)\nfeat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n\n# TRUE GLOBAL: fitur TIDAK boleh include user_id\nfeature_cols = [\"dow\", \"is_weekend\"] + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)] + [\n    \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n    \"count_high\", \"count_low\",\n    \"streak_high\", \"transitions\",\n]\nif len(BEHAVIOR_COLS) > 0:\n    feature_cols += [f\"lag1_{c}\" for c in BEHAVIOR_COLS]\n\n# drop rows yang belum punya history lengkap\nfeat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n\nprint(\"\\n=== DATASET FEAT ===\")\nprint(\"Rows:\", len(feat), \"| Users:\", feat[USER_COL].nunique())\nprint(\"Binary dist:\", feat[\"y_bin\"].value_counts().to_dict())\nprint(\"WINDOW:\", WINDOW, \"| TEST_LEN:\", TEST_LEN)\n\n\n# =========================\n# 3) SPLIT: time-based per user (TEST = last TEST_LEN)\n# =========================\ntrain_idx, test_idx = [], []\nper_user_train_pool = {}\n\nfor uid, g in feat.groupby(USER_COL):\n    g = g.sort_values(DATE_COL).reset_index()\n    n = len(g)\n    test_start = n - TEST_LEN\n    if test_start <= 20:\n        raise ValueError(\"Data per user terlalu sedikit untuk split + CV windows.\")\n    train_pool = g.iloc[:test_start]\n    test_block = g.iloc[test_start:]\n\n    per_user_train_pool[uid] = train_pool\n    train_idx += train_pool[\"index\"].tolist()\n    test_idx  += test_block[\"index\"].tolist()\n\ntrain_pool_df = feat.loc[train_idx].copy()\ntest_df = feat.loc[test_idx].copy()\n\nprint(\"\\n=== SPLIT ===\")\nprint(\"TrainPool:\", len(train_pool_df), \"| Test:\", len(test_df))\nprint(\"Test dist:\", test_df[\"y_bin\"].value_counts().to_dict())\n\n# build CV splits (pooled windows across users)\ncv_splits = []\nfor (v0, v1) in VAL_WINDOWS:\n    tr_idx, va_idx = [], []\n    ok = True\n    for uid, tp in per_user_train_pool.items():\n        tp = tp.reset_index(drop=True)\n        if len(tp) < v1:\n            ok = False\n            break\n        va = tp.iloc[v0:v1]\n        tr = tp.iloc[:v0]\n        tr_idx += tr[\"index\"].tolist()\n        va_idx += va[\"index\"].tolist()\n    if ok:\n        cv_splits.append((tr_idx, va_idx))\n\nif len(cv_splits) == 0:\n    raise ValueError(\"CV windows gagal terbentuk. Kecilkan TEST_LEN atau VAL_WINDOWS.\")\nprint(\"CV folds:\", len(cv_splits))\n\nX_trainpool = train_pool_df[feature_cols].copy()\ny_trainpool = train_pool_df[\"y_bin\"].astype(int).values\n\nX_test = test_df[feature_cols].copy()\ny_test = test_df[\"y_bin\"].astype(int).values\n\n\n# =========================\n# 4) BASELINE L1: Persistence\n# =========================\npred_persist = (test_df[\"lag_sp_1\"] >= 1).astype(int).values\npersist_metrics = eval_bin(y_test, pred_persist)\nprint(\"\\n=== BASELINE L1: Persistence ===\")\nprint(\"TEST:\", persist_metrics)\n\n\n# =========================\n# 5) BASELINE L2: Markov GLOBAL(prev_high, dow) + thr tuning (fair)\n# =========================\ndef train_markov_global(df_train):\n    counts = np.zeros((2, 7, 2), dtype=int)  # prev(2) x dow(7) x y(2)\n    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_train[\"dow\"].astype(int).values\n    yb   = df_train[\"y_bin\"].astype(int).values\n    for p, d, y in zip(prev, dow, yb):\n        counts[p, d, y] += 1\n    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)  # Laplace\n    return probs\n\ndef markov_proba(probs, df_eval):\n    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n    dow  = df_eval[\"dow\"].astype(int).values\n    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n\n# tune threshold Markov via pooled CV\ncv_true, cv_phigh = [], []\nfor tr_idx, va_idx in cv_splits:\n    tr_df = feat.loc[tr_idx]\n    va_df = feat.loc[va_idx]\n    probs = train_markov_global(tr_df)\n    p = markov_proba(probs, va_df)\n    cv_true.append(va_df[\"y_bin\"].astype(int).values)\n    cv_phigh.append(p)\n\ncv_true = np.concatenate(cv_true)\ncv_phigh = np.concatenate(cv_phigh)\n\nthr_mk, cv_f1_mk = tune_thr_from_proba(cv_true, cv_phigh)\n\nprobs_full = train_markov_global(train_pool_df)\np_test_mk = markov_proba(probs_full, test_df)\npred_test_mk = (p_test_mk >= thr_mk).astype(int)\nmarkov_metrics = eval_bin(y_test, pred_test_mk)\n\nprint(\"\\n=== BASELINE L2: Markov GLOBAL(prev_high, dow) ===\")\nprint(\"Best thr:\", thr_mk, \"| CV pooled F1:\", round(cv_f1_mk, 4))\nprint(\"TEST:\", markov_metrics)\n\n\n# =========================\n# 6) PREPROCESS (TRUE GLOBAL: tanpa user_id)\n# =========================\n# Cat: dow (lebih aman di-onehot). is_weekend bisa numeric.\ncat_cols = [\"dow\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n    ],\n    remainder=\"drop\"\n)\n\n\n# =========================\n# 7) CANDIDATE MODELS (semua yang relevan)\n# =========================\nCANDIDATES = {\n    \"LogReg\": (\n        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n    ),\n\n    \"DecisionTree\": (\n        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n        {\"clf__max_depth\": [2, 3, 4, 6, None], \"clf__min_samples_leaf\": [1, 2, 4, 8]}\n    ),\n\n    \"RandomForest\": (\n        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]}\n    ),\n\n    \"ExtraTrees\": (\n        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]}\n    ),\n\n    \"HistGB\": (\n        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3],\n         \"clf__max_leaf_nodes\": [15, 31, 63]}\n    ),\n\n    \"GradBoost\": (\n        GradientBoostingClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__n_estimators\": [100, 200, 400],\n         \"clf__max_depth\": [2, 3]}\n    ),\n\n    \"AdaBoost\": (\n        AdaBoostClassifier(random_state=RANDOM_STATE),\n        {\"clf__learning_rate\": [0.03, 0.05, 0.1, 0.3], \"clf__n_estimators\": [50, 100, 200, 400]}\n    ),\n\n    \"BaggingTree\": (\n        BaggingClassifier(\n            estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n            random_state=RANDOM_STATE,\n            n_jobs=1\n        ),\n        {\"clf__n_estimators\": [50, 100, 200],\n         \"clf__estimator__max_depth\": [2, 3, 4, None],\n         \"clf__estimator__min_samples_leaf\": [1, 2, 4]}\n    ),\n\n    \"LinearSVC_Calibrated\": (\n        CalibratedClassifierCV(\n            estimator=LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n            method=\"sigmoid\",\n            cv=3\n        ),\n        {\"clf__estimator__C\": [0.03, 0.1, 0.3, 1.0, 3.0]}\n    ),\n}\n\n\n# =========================\n# 8) FAIR TUNING: CV pooled + threshold tuning + optional BLEND vs Markov\n# =========================\ndef pooled_cv_best(pipe, grid):\n    \"\"\"\n    Cari params terbaik dgn pooled CV:\n    - kumpulkan proba di semua validation folds\n    - tune threshold yang memaksimalkan F1\n    - kalau USE_BLEND: juga tune alpha (campur p_ml & p_markov fold-specific)\n    \"\"\"\n    best = None\n\n    for params in ParameterGrid(grid):\n        # kumpulkan untuk CV pooled\n        y_list, pml_list, pmk_list = [], [], []\n\n        for tr_idx, va_idx in cv_splits:\n            tr_df = feat.loc[tr_idx]\n            va_df = feat.loc[va_idx]\n\n            # Markov fold-specific (no leak)\n            mk_probs = train_markov_global(tr_df)\n            p_mk = markov_proba(mk_probs, va_df)\n\n            # ML fold-specific\n            Xtr = tr_df[feature_cols].copy()\n            ytr = tr_df[\"y_bin\"].astype(int).values\n            Xva = va_df[feature_cols].copy()\n            yva = va_df[\"y_bin\"].astype(int).values\n\n            pipe.set_params(**params)\n            pipe.fit(Xtr, ytr)\n            p_ml = pipe.predict_proba(Xva)[:, 1]\n\n            y_list.append(yva)\n            pml_list.append(p_ml)\n            pmk_list.append(p_mk)\n\n        y_all = np.concatenate(y_list)\n        pml_all = np.concatenate(pml_list)\n        pmk_all = np.concatenate(pmk_list)\n\n        if USE_BLEND:\n            # tune alpha & thr\n            local_best = None\n            for alpha in ALPHAS:\n                p_blend = alpha * pml_all + (1.0 - alpha) * pmk_all\n                thr, cv_f1 = tune_thr_from_proba(y_all, p_blend)\n                if (local_best is None) or (cv_f1 > local_best[\"cv_f1\"]):\n                    local_best = {\"alpha\": float(alpha), \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n            score = local_best[\"cv_f1\"]\n            record = {\"params\": params, **local_best}\n        else:\n            thr, cv_f1 = tune_thr_from_proba(y_all, pml_all)\n            score = cv_f1\n            record = {\"params\": params, \"alpha\": 1.0, \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n\n        if (best is None) or (score > best[\"cv_f1\"]):\n            best = record\n\n    return best\n\n\nprint(\"\\n=== TRAIN + TUNE (Fair CV) : ML (+ optional BLEND) vs Markov ===\")\nrows = []\n\nfor name, (clf, grid) in CANDIDATES.items():\n    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n    best = pooled_cv_best(pipe, grid)\n\n    # train final ML on full TrainPool\n    pipe.set_params(**best[\"params\"])\n    pipe.fit(X_trainpool, y_trainpool)\n    p_test_ml = pipe.predict_proba(X_test)[:, 1]\n\n    # Markov prob on test from TrainPool Markov\n    p_test_mk_full = markov_proba(probs_full, test_df)\n\n    # final pred\n    alpha = float(best[\"alpha\"])\n    p_test_final = alpha * p_test_ml + (1.0 - alpha) * p_test_mk_full\n    pred_test_final = (p_test_final >= best[\"thr\"]).astype(int)\n\n    test_metrics = eval_bin(y_test, pred_test_final)\n\n    rows.append({\n        \"model\": name,\n        \"cv_f1\": float(best[\"cv_f1\"]),\n        \"alpha\": float(best[\"alpha\"]),\n        \"thr\": float(best[\"thr\"]),\n        \"test_f1\": float(test_metrics[\"f1\"]),\n        \"test_acc\": float(test_metrics[\"acc\"]),\n        \"params\": best[\"params\"],\n        \"pipe\": pipe,\n    })\n\n# Leaderboard\nprint(\"\\n=== LEADERBOARD (sorted by TEST F1) ===\")\nbase_rows = [\n    {\"model\": \"Baseline-Persist\", \"cv_f1\": np.nan, \"alpha\": np.nan, \"thr\": np.nan, \"test_f1\": persist_metrics[\"f1\"], \"test_acc\": persist_metrics[\"acc\"], \"params\": None},\n    {\"model\": \"Baseline-Markov\",  \"cv_f1\": cv_f1_mk, \"alpha\": 0.0, \"thr\": thr_mk, \"test_f1\": markov_metrics[\"f1\"], \"test_acc\": markov_metrics[\"acc\"], \"params\": {\"markov\": \"prev_high+dow\"}},\n]\nall_rows = base_rows + rows\nall_sorted = sorted(all_rows, key=lambda r: r[\"test_f1\"], reverse=True)\n\nfor r in all_sorted:\n    cv_txt = \"NA\" if (r[\"cv_f1\"] is None or (isinstance(r[\"cv_f1\"], float) and np.isnan(r[\"cv_f1\"]))) else f\"{r['cv_f1']:.4f}\"\n    alpha_txt = \"NA\" if (r[\"alpha\"] is None or (isinstance(r[\"alpha\"], float) and np.isnan(r[\"alpha\"]))) else f\"{r['alpha']:.2f}\"\n    thr_txt = \"NA\" if (r[\"thr\"] is None or (isinstance(r[\"thr\"], float) and np.isnan(r[\"thr\"]))) else f\"{r['thr']:.2f}\"\n    print(f\"{r['model']:<20} | CV f1={cv_txt:<7} | TEST f1={r['test_f1']:.4f} acc={r['test_acc']:.4f} | alpha={alpha_txt} thr={thr_txt} | params={r['params']}\")\n\nbest_ml = sorted(rows, key=lambda r: r[\"test_f1\"], reverse=True)[0]\nprint(\"\\n\u2705 BEST (ML/BLEND):\", best_ml[\"model\"], \"| TEST:\", {\"f1\": round(best_ml[\"test_f1\"], 4), \"acc\": round(best_ml[\"test_acc\"], 4)})\n\n# pilih terbaik overall (Markov vs best ML/Blend)\nif best_ml[\"test_f1\"] > markov_metrics[\"f1\"]:\n    best_name = best_ml[\"model\"]\n    best_obj = {\n        \"type\": \"true_global_blend_model\",\n        \"pipe\": best_ml[\"pipe\"],               # sklearn pipeline\n        \"alpha\": float(best_ml[\"alpha\"]),\n        \"thr\": float(best_ml[\"thr\"]),\n        \"markov_probs\": probs_full,            # untuk hitung p_markov runtime\n        \"meta\": {\n            \"note\": \"TRUE GLOBAL (no user_id). Prediction uses p = alpha*p_ml + (1-alpha)*p_markov\",\n            \"target\": \"y_bin=(stress_level_pred>=1)\",\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"thresholds\": THRESHOLDS.tolist(),\n            \"alphas\": ALPHAS.tolist(),\n            \"behavior_cols\": BEHAVIOR_COLS,\n        }\n    }\n    print(\"\\n\ud83c\udf89 TRUE GLOBAL model BEATS Markov on TEST. Saving BLEND as best.\")\nelse:\n    best_name = \"MarkovGlobal\"\n    best_obj = {\n        \"type\": \"true_global_markov\",\n        \"thr\": float(thr_mk),\n        \"probs\": probs_full,\n        \"meta\": {\n            \"note\": \"TRUE GLOBAL baseline Markov remains best on TEST for this dataset\",\n            \"target\": \"y_bin=(stress_level_pred>=1)\",\n            \"window\": WINDOW,\n            \"test_len\": TEST_LEN,\n            \"val_windows\": VAL_WINDOWS,\n            \"thresholds\": THRESHOLDS.tolist(),\n        }\n    }\n    print(\"\\n\u2139\ufe0f Markov still best on TEST. Saving Markov as best (robust).\")\n\nMODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(best_obj, MODEL_OUT)\nprint(\"Saved:\", MODEL_OUT, \"| Best:\", best_name)\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}