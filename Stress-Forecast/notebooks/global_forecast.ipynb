{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4f077d",
   "metadata": {},
   "source": [
    "# Imports and Setup\n",
    "\n",
    "Bagian ini memuat:\n",
    "- Library inti (numpy/pandas) dan tooling (Path/joblib)\n",
    "- Konfigurasi untuk skenario **GLOBAL** (user_id hanya untuk grouping & split, bukan fitur)\n",
    "- Utility untuk evaluasi metrik dan tuning threshold\n",
    "\n",
    "- Semua nama kolom kini snake_case (mis. `user_id`, `stress_level`, `created_at`, `study_hour_per_day`).\n",
    "- Kolom `is_restored` adalah metadata input/restore dan **tidak** dipakai sebagai fitur model (dipakai sebagai quality flag melalui sample_weight).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde02602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# =============================================================================\n",
    "# 0) CONFIG\n",
    "# =============================================================================\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"../datasets/stress_forecast.csv\"),\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"stress_forecast.csv not found. Check CANDIDATE_PATHS / DATA_PATH.\")\n",
    "\n",
    "MODEL_OUT = Path(\"../models/global_forecast.joblib\")\n",
    "\n",
    "DATE_COL   = \"date\"\n",
    "USER_COL   = \"user_id\"             # used only for split/grouping (never as features)\n",
    "TARGET_COL = \"stress_level\"    # 0..2\n",
    "\n",
    "RESTORE_COL = \"is_restored\"\n",
    "# RESTORE_STRATEGY: \"sample_weight\" or \"filter\"\n",
    "RESTORE_STRATEGY = \"sample_weight\"\n",
    "RESTORE_WEIGHT = 0.5\n",
    "\n",
    "WINDOW   = 7\n",
    "TEST_LEN = 12\n",
    "\n",
    "# CV windows (relative index inside each user's train_pool), end exclusive\n",
    "VAL_WINDOWS = [(12, 24), (18, 30)]\n",
    "\n",
    "# Threshold search for decision rule from probabilities\n",
    "THRESHOLDS = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "# Blend config: p = alpha*p_ml + (1-alpha)*p_markov\n",
    "USE_BLEND = True\n",
    "ALPHAS = np.linspace(0.0, 1.0, 11)\n",
    "\n",
    "RANDOM_STATE = 26\n",
    "\n",
    "# Optional: add behavior lag1 if hour-like numeric columns exist\n",
    "USE_BEHAVIOR_LAG1 = True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Utilities\n",
    "# =============================================================================\n",
    "def eval_bin(y_true, y_pred):\n",
    "    return {\n",
    "        \"acc\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "    }\n",
    "\n",
    "def tune_thr_from_proba(y_true, p_high, thresholds=THRESHOLDS):\n",
    "    best_thr, best_f1 = None, -1.0\n",
    "    for thr in thresholds:\n",
    "        pred = (p_high >= thr).astype(int)\n",
    "        f1 = float(f1_score(y_true, pred, zero_division=0))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = f1, thr\n",
    "    return float(best_thr), float(best_f1)\n",
    "\n",
    "def safe_class_counts(y: np.ndarray):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    return {0: int((y == 0).sum()), 1: int((y == 1).sum())}\n",
    "\n",
    "def pick_existing_behavior_cols(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Detect hour-like numeric columns for optional lag1 behavior features.\n",
    "    This remains no-leak because shift(1) is applied during feature engineering.\n",
    "    \"\"\"\n",
    "    exclude = {DATE_COL, USER_COL, TARGET_COL}\n",
    "    numeric = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    hour_like = [c for c in numeric if (\"hour\" in c.lower()) or (\"hours\" in c.lower())]\n",
    "\n",
    "    known = [\n",
    "        \"study_hour_per_day\",\n",
    "        \"sleep_hour_per_day\",\n",
    "        \"social_hour_per_day\",\n",
    "        \"physical_activity_hour_per_day\",\n",
    "        \"extracurricular_hour_per_day\",\n",
    "    ]\n",
    "    for c in known:\n",
    "        if c in numeric and c not in hour_like:\n",
    "            hour_like.append(c)\n",
    "\n",
    "    return hour_like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e67a3",
   "metadata": {},
   "source": [
    "# Load and Explore Dataset\n",
    "\n",
    "Tujuan bagian ini:\n",
    "- Load dataset dari `DATA_PATH`\n",
    "- Validasi kolom penting: `date`, `user_id`, `stress_level`\n",
    "- Sort per user berdasarkan waktu\n",
    "- Deteksi `BEHAVIOR_COLS` (opsional) untuk fitur `lag1_*`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aecd1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH     : ..\\datasets\\stress_forecast.csv\n",
      "ROWS          : 300\n",
      "USERS         : 5\n",
      "DATE_RANGE    : 2025-11-21 -> 2026-01-19\n",
      "TARGET_COL    : stress_level\n",
      "BEHAVIOR_COLS : ['extracurricular_hour_per_day', 'physical_activity_hour_per_day', 'sleep_hour_per_day', 'study_hour_per_day', 'social_hour_per_day']\n",
      "\n",
      "HEAD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stress_level_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>gpa</th>\n",
       "      <th>extracurricular_hour_per_day</th>\n",
       "      <th>physical_activity_hour_per_day</th>\n",
       "      <th>sleep_hour_per_day</th>\n",
       "      <th>study_hour_per_day</th>\n",
       "      <th>social_hour_per_day</th>\n",
       "      <th>emoji</th>\n",
       "      <th>is_restored</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-21 21:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-22 20:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-23 22:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-24 19:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-25 21:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stress_level_id  user_id       date  stress_level   gpa  \\\n",
       "0                2        1 2025-11-21             1  3.82   \n",
       "1                7        1 2025-11-22             0  3.82   \n",
       "2               12        1 2025-11-23             0  3.82   \n",
       "3               17        1 2025-11-24             1  3.82   \n",
       "4               22        1 2025-11-25             1  3.82   \n",
       "\n",
       "   extracurricular_hour_per_day  physical_activity_hour_per_day  \\\n",
       "0                           0.0                             0.5   \n",
       "1                           0.0                             1.0   \n",
       "2                           0.0                             3.0   \n",
       "3                           0.0                             0.5   \n",
       "4                           0.0                             1.0   \n",
       "\n",
       "   sleep_hour_per_day  study_hour_per_day  social_hour_per_day  emoji  \\\n",
       "0                 7.0                 7.0                  2.0      1   \n",
       "1                 9.0                 2.0                  5.0      2   \n",
       "2                 9.0                 1.0                  6.0      1   \n",
       "3                 8.0                 7.0                  5.0      3   \n",
       "4                 7.0                 7.0                  4.0      3   \n",
       "\n",
       "   is_restored           created_at  \n",
       "0            0  2025-11-21 21:12:00  \n",
       "1            0  2025-11-22 20:07:00  \n",
       "2            0  2025-11-23 22:18:00  \n",
       "3            0  2025-11-24 19:55:00  \n",
       "4            0  2025-11-25 21:40:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "if RESTORE_COL not in df.columns:\n",
    "    df[RESTORE_COL] = 0\n",
    "df[RESTORE_COL] = df[RESTORE_COL].fillna(0).astype(int)\n",
    "\n",
    "for required_col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if required_col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{required_col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "target_ok = df[TARGET_COL].dropna().between(0, 2).all()\n",
    "if not target_ok:\n",
    "    raise ValueError(f\"'{TARGET_COL}' must be within range 0..2\")\n",
    "\n",
    "BEHAVIOR_COLS = pick_existing_behavior_cols(df) if USE_BEHAVIOR_LAG1 else []\n",
    "\n",
    "print(\"DATA_PATH     :\", str(DATA_PATH))\n",
    "print(\"ROWS          :\", len(df))\n",
    "print(\"USERS         :\", df[USER_COL].nunique())\n",
    "print(\"DATE_RANGE    :\", str(df[DATE_COL].min().date()), \"->\", str(df[DATE_COL].max().date()))\n",
    "print(\"TARGET_COL    :\", TARGET_COL)\n",
    "print(\"BEHAVIOR_COLS :\", BEHAVIOR_COLS)\n",
    "\n",
    "print(\"\\nHEAD:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba4842",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Ringkasan cepat yang relevan:\n",
    "- Distribusi `stress_level` (0â€“2) sebelum dibinarisasi\n",
    "- Distribusi jumlah data per user untuk memastikan split time-based aman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609053e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_DIST (0..2): {0: 124, 1: 91, 2: 85}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHCCAYAAAAJowgXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMGpJREFUeJzt3Q2cjXX+//HPjDHjdkZuhxo3SbnJUhSDRcyirNh0o7UliTZU2HUzu1GiUGKWhOwiG0m1SDbFEG3uKaXkpkZm06DVzIRmBnP+j8/3/7vO45wzM8zNMefMd17Px+Myc67rOtf5nnMuc97ne3eFuFwulwAAAFgqNNAFAAAAuJIIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7KNWeeeYZCQkJKZbH6ty5s1kcH330kXnst99+u1ge/6GHHpL69etLMDtz5ow88sgjEh0dbV6bESNGSGmnr4OepyWtLDt37pTw8HD57rvvJBh89dVXEhYWJvv37w90URAAhB1YY/HixeaPsbOUK1dO6tSpI927d5dZs2bJzz//7JfHOX78uPmD/9lnn0mwCeay5cfzzz9v3sfHHntM/vnPf8oDDzxQal+Lku6vf/2r3H///VKvXj2v9QcOHJAePXpIpUqVpGrVquY9PnXqVKEeIzs725wvd955p8TExEjFihXlxhtvlMmTJ0tGRobXvk2bNpWePXvKhAkTivS8UDKFBboAgL89++yz0qBBAzl//rykpKSYGhStIZgxY4a8++678qtf/cq971NPPSXjxo0r8IfoxIkTTS1Jy5Yt832/Dz/8UK60S5VtwYIF5sMhmG3cuFHatm0rTz/9dJGPVdj3CUWnAXPDhg2ydetWr/X//e9/pWPHjhIVFWWCrdbkTZ8+Xb744gt3TVBBnDt3TgYOHGjOmT/+8Y9Ss2ZN2bZtmzl/EhMTzfnkWXOr+9xxxx3yzTffSMOGDXmrSxHCDqxz++23S+vWrd234+PjzR+93/72t+YboH6zLF++vNmm1dq6XEn6B7lChQoF/kPub2XLlpVgd/LkSfMNPBCc9wlFt2jRIqlbt64JIZ404Jw9e1b27Nljtqtbb71VfvOb35gamiFDhhTocfT/1CeffCLt2rVzrxs8eLAJuE7giYuLc2/T36+66ip57bXXzJcilB40Y6FU6NKli4wfP970H3j99dcv2Wdn/fr10qFDB6lSpYqpar/hhhvkL3/5i9mmtUS33HKL+V2/UTpNZvqHWmmfHK1G1z/m+g1WPzyd+/r22XFcvHjR7KP9VLQaXgNZcnKy1z76x1v73PjyPOblypZbnx394PnTn/5kmgAiIiLMc9Vv2i6Xy2s/Pc7w4cNl1apV5vnpvs2aNZN169blO8QMGjRIatWqZZoXW7RoYT5wfPsvJSUlydq1a91lP3r0aJ7HvFLvU2ZmpvmgvO6668zz1NdmzJgxZn1+H98xe/Zs8zrp8fVDVkP4smXLpKi+//57efjhh83r6bwXCxcudG8/ceKECfFas+Xr4MGD5rV4+eWX3etSU1NN7adzHuhznzZtWqFrAvU80f9zvv+33nnnHfOlwwk6TgC5/vrrZcWKFQV+HA07nkHH8bvf/c781C82voFf3/vVq1cX+LFQslGzg1JD+wboh5E2J+m3v9x8+eWX5o+xNnXpNz/9w3/kyBHz7VE1adLErNd2f/0W+utf/9qs9/yD+7///c/ULvXr10/+8Ic/mA+kS3nuuefMh8LYsWNNKEhISDAfANoU4NRA5Ud+yuZJA40Gq02bNpkgok09H3zwgYwePdp8mM6cOdNr///85z/yr3/9S4YOHSqVK1c2/aD69u0rx44dk2rVquVZrl9++cV8wOjrqIFJmxjfeustE770Q/bJJ580Zdc+OiNHjpRrrrnGBDBVo0aNYn2f9MNdXxN9rno/PY42sehrcejQIfMhnp/Hd5oNn3jiCbn77rvNc9Q+JJ9//rns2LFDfv/730thaZDRGhMngOpr9P7775v3MD093YQWfS6dOnUyAcK3SfDNN9+UMmXKyD333OOu0dJ99T1/9NFHTRDR5ietEf3hhx/M+VgQehw9J26++eYc6/X89qx1dWjtzr///W/xF22+VtWrV8+xrVWrVibs6GsVGRnpt8dEkHMBlli0aJFWR7h27dqV5z5RUVGum266yX376aefNvdxzJw509w+depUnsfQ4+s++ni+OnXqZLbNmzcv1226ODZt2mT2vfrqq13p6enu9StWrDDr//a3v7nX1atXzzVgwIDLHvNSZdP763Ecq1atMvtOnjzZa7+7777bFRIS4jpy5Ih7ne4XHh7utW7fvn1m/ezZs12XkpCQYPZ7/fXX3euysrJcsbGxrkqVKnk9dy1fz549XZdzpd6nf/7zn67Q0FDXxx9/7LVe99P9P/nkk3w/fu/evV3NmjVzFZU+jp6njkGDBrlq167t+vHHH73269evnzm/z507Z27Pnz/f3PeLL77w2q9p06auLl26uG9PmjTJVbFiRdehQ4e89hs3bpyrTJkyrmPHjuVZltxs2LDB7LdmzZpc348lS5bkuM/o0aPNtoyMDJc/xMXFuSIjI10//fRTjm3Lli0zj7Vjxw6/PBZKBpqxUKpoc8OlRmVpk4TSb36FrcLXb/nadJJfDz74oKkpcWhNQO3atf36TTc3enz9hq+1D560VkU/17S2wJPWNnl26tRaDf1m/O233172cbSJTkfmeDYn6ONqB9XNmzcXuOxX6n3SGietzWncuLH8+OOP7kWbZJTWguX38XUf7ZC7a9cu8Rd9X7QpqFevXuZ3zzLqqMO0tDTZu3ev2feuu+4yTVlak+PQYdc6BPu+++7zes5a86XNbJ7H0/dbm1i3bNlSoDJqjZnS4/nW8Dmvuy9t2vTcpyi0X5B2jp46dar7ffLklEufI0oPwg5KFf1w9QwWvvRDoH379mauF20K0CYObQooyAfq1VdfXaDOyI0aNfK6rc0T2mfiUv1V/EH7L+nQfN/XQz/sne2ePPtZeH5w/PTTT5d9HH2OoaGh+Xqc/LhS79Phw4dNE5U2DXku2qdEaTNMfh9fmyU1XGsTjT7/YcOGeTVzFYYO0damv1dffTVHGZ3g5pRRm3C6du3q1RdGg48GIA1Cns9Z+175Hs/p2Oscr6B8+305TbK+fZ+UM0y8IM22udHnpyMstUlPpy+4VLmKa34tBAf67KDU0G/Z+s1Xg0Re9I+tfpPVb/DaUVY/BPQPqH6z174+WhNyOUX9g52bvP4w6zfv/JTJH/J6HN8PteJwpd4nDSvNmzc30xTkRjvw5vfxNcxpZ+D33nvPbNcamVdeecX0I8qt43B+OGFK+xgNGDAg1308p1bQEKYhSPt/aZ8sDT4agDz7sugxdTSUdsLOjRP08svpv+UbgrW2Umk/IF+6Tufcya3WJ7+0w7jWkupcOvPmzctzP6dcufXngb0IOyg1tAOs0ur+S9EaCP1A0EU/9LRaXCdI0w82/bbr72+E+s3aNzxoZ1fPDy2tQdFv9L60VuTaa6913y5I2XSyN63u12Y9z9qdr7/+2r3dH/Q42jFXP1Q9a3eK+jhX4n3SZrp9+/aZY17u/pd7fKWj67QWSJesrCxTo6Id0rXzr9N0UxBa46LvlYZczyHVeenTp4/pdOw0ZWkna31s3+esNZ75OV5+aBOg0pF1vjVpWv7du3fnuI/OsVOUuZC007eOwNLOzxroLjWdhJZL37uChjiUbDRjoVTQeXYmTZpkRgL1798/z/1Onz6dY53zR9ipftcPMJVb+CiMJUuWePUj0stH6DddHSnk+YG0fft284Hp0BoD3yHqBSmbTq6mH5qeQ5CVjjzSD3rPxy8KfRwdHePZd+TChQtmWLY28+hIoIK6Uu/Tvffea0YN6UgqX9qfRIfq5/fxnb4rDm0y0zmENMzqhJeFoTVGOgJOa4lyu+yB70zE2mdFw70GgOXLl5syaADyfc46EZ+OxPOlr52+VwWhoUZrwHILNVp23/NW58LREOaMDlP6+mgY9q0F0skAdfGkw8u1NkenVdBjX65mVacb0KH6OrEhSg9qdmAd7Virfyj1j7QO09Wgo1XcWoOgMyhf6hu1DiPW5gn946n7a38FbXrQ4dA6p4oTPPRDRKvK9Vu2fqi2adPGBKnC0Op7PbY2N2h5daivNrV5Do/XviEagnSaff1w0j/4Ol+Q7yywBSmbdnK97bbbTG2E9g/SuW+0CUY73erwZX/NMKtDuOfPn2+GmusHjX4o6XPR/iv6XC/Vh6q43yednkCDgc60qzU02i9HA6GeT7peA4HWHuTn8bt162Y6ZusxtF+PfihrsNT7FOY5O7TjrZZNn4ueIxqgNHxpx2StqfMNYlqrpM1eWj4NPr6ddnWqAf1/oUPp9T3Sodka6nTIvb5Pem4UtMmnd+/esnLlShPsPGvIdOoH7RCt550Ox9capRdffNE0HXp2FtfAqc2A2lTnzI2ktBZNOf3Z9EuCPidtmtLnoU2KnvQciI2N9QpR2iFep09AKRPo4WCAv4eeO4sOlY6Ojnb95je/McO4PYc45zX0PDEx0QwZrlOnjrm//rz//vtzDMtdvXq1GcIbFhbmNbxZhzTnNdw4r6Hnb7zxhis+Pt5Vs2ZNV/ny5c3Q6++++y7H/V966SUzTD0iIsLVvn171+7du3Mc81Jl8x16rn7++WfXyJEjzfMsW7asq1GjRq4XX3zRlZ2d7bWfHmfYsGE5ypTXkHhfJ06ccA0cONBVvXp187o2b9481yHh+R16fiXfJx0WP23aNLNdX+urrrrK1apVK9fEiRNdaWlp+X58HfrdsWNHV7Vq1cxxGjZsaIZYO8fIr9yGe+vrqe9HTEyMed/0PO/atavr1VdfzXF/Pe/1vPId/u97Hug5eN1115nno+9Tu3btXNOnTzevx6XKkpu9e/eafX2H8Kv9+/e7unXr5qpQoYKrSpUqrv79+7tSUlK89klKSjL39z239PzwPIed/fJafO///vvvm/WHDx++7HOAXUL0n0AHLgCAXbQWRkf7OX3lgoE24WlNk9Y6oXQh7AAA/E47Dev8PdoB31+d3YtCmxG1uUxHpumlQlC6EHYAoJhpPyDfzsS+tPO2LgCKjg7KAFDMdDTS5Tq06zWt9EK1AIqOsAMAxUxHaekIwUvxnD8JQNHQjAUAAKzGpIIAAMBqNGP937Vhjh8/bib64uJwAACUDDp7jk4uqdMc+F5s2BNhR8QEHecCfwAAoOR1+tcZzPNC2BFxT92uL1ZkZGTxvTsAAKDQ0tPTTWXF5S7BQtjxuFK0Bh3CDgAAJcvluqDQQRkAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgtbBAFwD5V3/cWl4uPzk6tSevJQCUEtTsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYLaBhZ8uWLdKrVy+pU6eOhISEyKpVq9zbzp8/L2PHjpXmzZtLxYoVzT4PPvigHD9+3OsYp0+flv79+0tkZKRUqVJFBg0aJGfOnAnAswEAAMEooGHn7Nmz0qJFC5kzZ06ObefOnZO9e/fK+PHjzc9//etfcvDgQbnzzju99tOg8+WXX8r69evlvffeMwFqyJAhxfgsAABAMAtxuVwuCQJas7Ny5Urp06dPnvvs2rVLbr31Vvnuu++kbt26cuDAAWnatKlZ37p1a7PPunXr5I477pD//ve/pjYoP9LT0yUqKkrS0tJMDVGwYlJB/2FSQQAo+fL7+V2i+uzok9FQpM1Vatu2beZ3J+iouLg4CQ0NlR07duR5nMzMTPMCeS4AAMBOJSbsZGRkmD48999/vzu9paSkSM2aNb32CwsLk6pVq5pteZkyZYpJgs4SExNzxcsPAAACo0SEHe2sfO+994q2uM2dO7fIx4uPjze1RM6SnJzsl3ICAIDgE1ZSgo7209m4caNXm1x0dLScPHnSa/8LFy6YEVq6LS8RERFmAQAA9gstCUHn8OHDsmHDBqlWrZrX9tjYWElNTZU9e/a412kgys7OljZt2gSgxAAAINgEtGZH58M5cuSI+3ZSUpJ89tlnps9N7dq15e677zbDznVI+cWLF939cHR7eHi4NGnSRHr06CGDBw+WefPmmXA0fPhw6devX75HYgEAALsFNOzs3r1bbrvtNvftUaNGmZ8DBgyQZ555Rt59911zu2XLll7327Rpk3Tu3Nn8vnTpUhNwunbtakZh9e3bV2bNmlWszwMAAASvgIYdDSyXmuYnP1MAaS3PsmXL/FwyAABgi6DuswMAAFBUhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWC2jY2bJli/Tq1Uvq1KkjISEhsmrVKq/tLpdLJkyYILVr15by5ctLXFycHD582Guf06dPS//+/SUyMlKqVKkigwYNkjNnzhTzMwEAAMEqoGHn7Nmz0qJFC5kzZ06u21944QWZNWuWzJs3T3bs2CEVK1aU7t27S0ZGhnsfDTpffvmlrF+/Xt577z0ToIYMGVKMzwIAAASzsEA++O23326W3GitTkJCgjz11FPSu3dvs27JkiVSq1YtUwPUr18/OXDggKxbt0527dolrVu3NvvMnj1b7rjjDpk+fbqpMQIAAKVb0PbZSUpKkpSUFNN05YiKipI2bdrItm3bzG39qU1XTtBRun9oaKipCcpLZmampKeney0AAMBOQRt2NOgorcnxpLedbfqzZs2aXtvDwsKkatWq7n1yM2XKFBOcnCUmJuaKPAcAABB4QRt2rqT4+HhJS0tzL8nJyYEuEgAAKG1hJzo62vw8ceKE13q97WzTnydPnvTafuHCBTNCy9knNxEREWb0lucCAADsFLRhp0GDBiawJCYmutdp3xrtixMbG2tu68/U1FTZs2ePe5+NGzdKdna26dsDAAAQ0NFYOh/OkSNHvDolf/bZZ6bPTd26dWXEiBEyefJkadSokQk/48ePNyOs+vTpY/Zv0qSJ9OjRQwYPHmyGp58/f16GDx9uRmoxEgsAAAQ87OzevVtuu+029+1Ro0aZnwMGDJDFixfLmDFjzFw8Om+O1uB06NDBDDUvV66c+z5Lly41Aadr165mFFbfvn3N3DwAAAAqxKUT2pRy2jymo7K0s3Iw99+pP25toItgjaNTewa6CACAYvr8Dto+OwAAAP5A2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWCwt0AQCUXPXHrQ10EaxxdGrPQBcBsBY1OwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVwgJdAAAA/Kn+uLW8oH5wdGpPa15HanYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNWCOuxcvHhRxo8fLw0aNJDy5ctLw4YNZdKkSeJyudz76O8TJkyQ2rVrm33i4uLk8OHDAS03AAAIHkEddqZNmyZz586Vl19+WQ4cOGBuv/DCCzJ79mz3Pnp71qxZMm/ePNmxY4dUrFhRunfvLhkZGQEtOwAACA5BfW2srVu3Su/evaVnz/9/fY769evLG2+8ITt37nTX6iQkJMhTTz1l9lNLliyRWrVqyapVq6Rfv34BLT8AAAi8oK7ZadeunSQmJsqhQ4fM7X379sl//vMfuf32283tpKQkSUlJMU1XjqioKGnTpo1s27YtYOUGAADBI6hrdsaNGyfp6enSuHFjKVOmjOnD89xzz0n//v3Ndg06SmtyPOltZ1tuMjMzzeLQxwAAAHYK6pqdFStWyNKlS2XZsmWyd+9eee2112T69OnmZ1FMmTLF1AA5S0xMjN/KDAAAgktQh53Ro0eb2h3te9O8eXN54IEHZOTIkSasqOjoaPPzxIkTXvfT28623MTHx0taWpp7SU5OvsLPBAAABEpQh51z585JaKh3EbU5Kzs72/yuQ9I11Gi/Hs8mKR2VFRsbm+dxIyIiJDIy0msBAAB2Cuo+O7169TJ9dOrWrSvNmjWTTz/9VGbMmCEPP/yw2R4SEiIjRoyQyZMnS6NGjUz40Xl56tSpI3369Al08QEAQBAI6rCj8+loeBk6dKicPHnShJhHH33UTCLoGDNmjJw9e1aGDBkiqamp0qFDB1m3bp2UK1cuoGUHAADBIajDTuXKlc08OrrkRWt3nn32WbMAAACUqD47AAAARUXYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsVKux06dJFUlNTc6xPT0832wAAAEp02Pnoo48kKysrx/qMjAz5+OOP/VEuAAAAvwgryM6ff/65+/evvvpKUlJS3LcvXrwo69atk6uvvto/JQMAACjusNOyZUsJCQkxS27NVeXLl5fZs2f7o1wAAADFH3aSkpLE5XLJtddeKzt37pQaNWq4t4WHh0vNmjWlTJky/ikZAABAcYedevXqmZ/Z2dn+eGwAAIDgCjueDh8+LJs2bZKTJ0/mCD8TJkzwR9kAAAACE3YWLFggjz32mFSvXl2io6NNHx6H/k7YAQAAJTrsTJ48WZ577jkZO3as/0sEAAAQ6Hl2fvrpJ7nnnnv8WQ4AAIDgCTsadD788EP/lwYAACAYmrGuu+46GT9+vGzfvl2aN28uZcuW9dr+xBNP+Kt8AAAAxR92Xn31ValUqZJs3rzZLJ60gzJhBwAAlOiwo5MLAgAAWNtnBwAAoKQoVM3Oww8/fMntCxcuLGx5AAAAAh92dOi5p/Pnz8v+/fslNTU11wuEAgAAlKiws3Llyhzr9JIROqtyw4YN/VEuAACA4OqzExoaKqNGjZKZM2f665AAAADB1UH5m2++kQsXLvjzkAAAAMXfjKU1OJ5cLpf88MMPsnbtWhkwYEDRSgQAABDosPPpp5/maMKqUaOGvPTSS5cdqQUAABD0YWfTpk3+LwkAAECwhB3HqVOn5ODBg+b3G264wdTuAAAAlPgOymfPnjXNVbVr15aOHTuapU6dOjJo0CA5d+6c/0sJAABQnGFHOyjrBUDXrFljJhLUZfXq1Wbdn/70p8KWBQAAIDiasd555x15++23pXPnzu51d9xxh5QvX17uvfdemTt3rj/LCAAAULw1O9pUVatWrRzra9as6fdmrO+//17+8Ic/SLVq1UyYat68uezevdtr2PuECRNMk5puj4uLk8OHD/u1DAAAoJSFndjYWHn66aclIyPDve6XX36RiRMnmm3+otfgat++vZQtW1bef/99+eqrr8zw9quuusq9zwsvvCCzZs2SefPmyY4dO6RixYrSvXt3r7IBAIDSq1DNWAkJCdKjRw+55pprpEWLFmbdvn37JCIiQj788EO/FW7atGkSExMjixYtcq9r0KCBV62OluWpp56S3r17m3VLliwxtU6rVq2Sfv36+a0sAACgFNXsaFOSNhVNmTJFWrZsaZapU6fKkSNHpFmzZn4r3LvvviutW7eWe+65xzSR3XTTTbJgwQL39qSkJElJSTFNV46oqChp06aNbNu2Lc/jZmZmSnp6utcCAADsVKiaHQ05WnsyePBgr/ULFy40c++MHTvWL4X79ttvTWdnHf31l7/8RXbt2iVPPPGEhIeHm8tSaNBRvv2H9LazLa/ya5MbAACwX6FqdubPny+NGzfOsV5rdbTvjL9kZ2fLzTffLM8//7yp1RkyZIgJWEV9jPj4eElLS3MvycnJfiszAACwIOxorYmOfvKlMyjrBUH9RR+jadOmXuuaNGkix44dM79HR0ebnydOnPDaR28723KjfYsiIyO9FgAAYKdChR3tNPzJJ5/kWK/rdCZlf9GRWM7lKByHDh2SevXquTsra6hJTEx0b9f+Nzoqy5+jwgAAQCnrs6NNSSNGjJDz589Lly5dzDoNHGPGjPHrDMojR46Udu3amWYsnaxw586d8uqrr5pFhYSEmHJMnjxZGjVqZMLP+PHjTeDq06eP38oBAABKWdgZPXq0/O9//5OhQ4dKVlaWWVeuXDnTMVn7w/jLLbfcIitXrjTHfPbZZ02Y0aHm/fv3d++jAUuv1aX9efSyFR06dJB169aZ8gAAAIS4dLKaQjpz5owcOHDAzFysNSvaF6Yk0qYvHbKunZWDuf9O/XFrA10Eaxyd2jPQRbAC56T/cE76D+dl6Tkn0/P5+V2omh1HpUqVTO0LAACAVR2UAQAASgrCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYrUWFn6tSpEhISIiNGjHCvy8jIkGHDhkm1atWkUqVK0rdvXzlx4kRAywkAAIJHiQk7u3btkvnz58uvfvUrr/UjR46UNWvWyFtvvSWbN2+W48ePy1133RWwcgIAgOBSIsLOmTNnpH///rJgwQK56qqr3OvT0tLkH//4h8yYMUO6dOkirVq1kkWLFsnWrVtl+/btAS0zAAAIDiUi7GgzVc+ePSUuLs5r/Z49e+T8+fNe6xs3bix169aVbdu25Xm8zMxMSU9P91oAAICdwiTILV++XPbu3WuasXylpKRIeHi4VKlSxWt9rVq1zLa8TJkyRSZOnHhFygsAAIJLUNfsJCcny5NPPilLly6VcuXK+e248fHxpgnMWfRxAACAnYI67Ggz1cmTJ+Xmm2+WsLAws2gn5FmzZpnftQYnKytLUlNTve6no7Gio6PzPG5ERIRERkZ6LQAAwE5B3YzVtWtX+eKLL7zWDRw40PTLGTt2rMTExEjZsmUlMTHRDDlXBw8elGPHjklsbGyASg0AAIJJUIedypUry4033ui1rmLFimZOHWf9oEGDZNSoUVK1alVTQ/P444+boNO2bdsAlRoAAASToA47+TFz5kwJDQ01NTs6yqp79+7yyiuvBLpYAAAgSJS4sPPRRx953daOy3PmzDELAABAieqgDAAAUFSEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYL6rAzZcoUueWWW6Ry5cpSs2ZN6dOnjxw8eNBrn4yMDBk2bJhUq1ZNKlWqJH379pUTJ04ErMwAACC4BHXY2bx5swky27dvl/Xr18v58+elW7ducvbsWfc+I0eOlDVr1shbb71l9j9+/LjcddddAS03AAAIHmESxNatW+d1e/HixaaGZ8+ePdKxY0dJS0uTf/zjH7Js2TLp0qWL2WfRokXSpEkTE5Datm0boJIDAIBgEdQ1O7403KiqVauanxp6tLYnLi7OvU/jxo2lbt26sm3btjyPk5mZKenp6V4LAACwU4kJO9nZ2TJixAhp37693HjjjWZdSkqKhIeHS5UqVbz2rVWrltl2qb5AUVFR7iUmJuaKlx8AAARGiQk72ndn//79snz58iIfKz4+3tQSOUtycrJfyggAAIJPUPfZcQwfPlzee+892bJli1xzzTXu9dHR0ZKVlSWpqaletTs6Gku35SUiIsIsAADAfkFds+NyuUzQWblypWzcuFEaNGjgtb1Vq1ZStmxZSUxMdK/ToenHjh2T2NjYAJQYAAAEm7Bgb7rSkVarV682c+04/XC0n0358uXNz0GDBsmoUaNMp+XIyEh5/PHHTdBhJBYAAAj6sDN37lzzs3Pnzl7rdXj5Qw89ZH6fOXOmhIaGmskEdZRV9+7d5ZVXXglIeQEAQPAJC/ZmrMspV66czJkzxywAAAAlqs8OAABAURF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsJo1YWfOnDlSv359KVeunLRp00Z27twZ6CIBAIAgYEXYefPNN2XUqFHy9NNPy969e6VFixbSvXt3OXnyZKCLBgAAAsyKsDNjxgwZPHiwDBw4UJo2bSrz5s2TChUqyMKFCwNdNAAAEGAlPuxkZWXJnj17JC4uzr0uNDTU3N62bVtAywYAAAIvTEq4H3/8US5evCi1atXyWq+3v/7661zvk5mZaRZHWlqa+Zmeni7BLDvzXKCLYI1gf69LCs5J/+Gc9B/Oy9JzTqb/XxldLpfdYacwpkyZIhMnTsyxPiYmJiDlQfGLSuBVR3DhnESwiSpBfyd//vlniYqKsjfsVK9eXcqUKSMnTpzwWq+3o6Ojc71PfHy86dDsyM7OltOnT0u1atUkJCTkipfZVpqwNTAmJydLZGRkoIsDGJyXCDack/6jNToadOrUqXPJ/Up82AkPD5dWrVpJYmKi9OnTxx1e9Pbw4cNzvU9ERIRZPFWpUqVYylsaaNAh7CDYcF4i2HBO+selanSsCTtKa2kGDBggrVu3lltvvVUSEhLk7NmzZnQWAAAo3awIO/fdd5+cOnVKJkyYICkpKdKyZUtZt25djk7LAACg9LEi7Chtssqr2QrFQ5sGdWJH3yZCIJA4LxFsOCeLX4jrcuO1AAAASrASP6kgAADApRB2AACA1Qg7AADAaoQdAABgNWtGYyEw1yXTK8vrBVd1yL/SWavbtWsnDz30kNSoUYO3BQAQcIzGQqHs2rVLunfvLhUqVDBXmHfmNNLLdOjs1efOnZMPPvjATPQIAKXZL7/8Inv27JGqVatK06ZNvbZlZGTIihUr5MEHHwxY+UoDwg4KpW3bttKiRQuZN29ejuuJ6WwGf/zjH+Xzzz83tT5AsNDrtulcUFojCRSHQ4cOSbdu3eTYsWPmb2WHDh1k+fLlUrt2bfcXRL2u08WLF3lDriD67KBQ9u3bJyNHjsz1wqm6Trd99tlnvLoIKnrB39deey3QxUApMnbsWLnxxhvl5MmTcvDgQalcubK0b9/ehB8UH/rsoFC0b87OnTulcePGuW7XbVyuA8Xt3XffveT2b7/9ttjKAqitW7fKhg0bpHr16mZZs2aNDB06VH7961/Lpk2bpGLFirxQxYCwg0L585//LEOGDDHt0F27ds3RZ2fBggUyffp0Xl0Uqz59+piaxUtNDJ9bbSRwJfvrhIWFeZ1/c+fONZc36tSpkyxbtowXvxgQdlAow4YNM99SZs6cKa+88oq7vblMmTLSqlUrWbx4sdx77728uihW2g9Cz8fevXvnul2bVvX8BIqL1n7v3r1bmjRp4rX+5ZdfNj/vvPNO3oxiQJ8dFOlq89u3bzcjr77//nuz6O+6jqCDQNAgo7WNeblcrQ/gb7/73e/kjTfeyHWbBp7777+fc7IYMBoLgDU+/vhjOXv2rPTo0SPX7bpNv2Vr8wGA0oOwAwAArEYzFgAAsBphBwAAWI2wAwAArEbYAVDq1a9fXxISEor1dejcubOMGDGi1L/2QHEg7AC4oh566CEz2R8ABAphB0BQOH/+fKCLAMBShB0AfvH2229L8+bNpXz58lKtWjWJi4uT0aNHmwtvrl692kzop8tHH30kR48eNb+/+eabZs6bcuXKydKlS81x/v73v5vZZnWdzj6rMyI7srKyzDT7OlOybq9Xr55MmTLFbNPJAp955hmpW7euREREmCtJP/HEE4V6LqmpqfLII49IjRo1JDIyUrp06WIufutcxVrL/vXXX3vdR2cTb9iwofv2/v375fbbb5dKlSqZy6k88MAD8uOPPxaqPACKhstFACiyH374wcwE+8ILL5gZY3/++Wczwd+DDz5oru6cnp4uixYtMvtWrVpVjh8/bn4fN26cvPTSS3LTTTe5A8+ECRPMzLK67tNPP5XBgwebiyUOGDBAZs2aZS72uWLFChNqkpOTzaLeeecdEziWL18uzZo1k5SUFHdAKah77rnHhLb3339foqKiZP78+eYacBp0rr/+emndurUp66RJk9z30du///3v3WFJA5IGJi2TXh9Jr36tM4tv3LiRMw4obi4AKKI9e/boNRhcR48ezbFtwIABrt69e3utS0pKMvsnJCR4rW/YsKFr2bJlXusmTZrkio2NNb8//vjjri5duriys7NzPM5LL73kuv76611ZWVkFLn+9evVcM2fONL9//PHHrsjISFdGRkaOss2fP9/8rvvqbcfBgwfN8zlw4IC7zN26dfO6f3JystlH91WdOnVyPfnkkwUuK4CCoxkLQJG1aNHC1HxoM5bWiuhV73/66afL3k9rSDwv5fDNN9/IoEGDTNOPs0yePNmsdzo768U8b7jhBtNE9eGHH7rvr4+rNSjXXnutqQ1auXKlXLhwocDPRWuDzpw5Y5riPMuRlJTkLke/fv1MU5xeB86p1bn55ptNs5tzjE2bNnnd39nmHANA8aEZC0CR6dXu169fL1u3bjUBZPbs2fLXv/5VduzYccn7afOUQwOG0qDUpk2bHMdXGig0dGjz0oYNG0yzkPYN0v5CMTExcvDgQbNeyzJ06FB58cUXZfPmzVK2bNl8Pxcth/YJ0r5FvqpUqWJ+RkdHm2aqZcuWSdu2bc3Pxx57zOsYvXr1kmnTpuU4hh4bQPEi7ADwC+202759e7NovxvtPKy1K+Hh4XLx4sXL3l878Wqn4m+//Vb69++f537aYfi+++4zy913320u+nn69GnTF0j72WjI0GXYsGGmNuWLL74wISm/dF/t7xMWFmbm38mLlnHMmDGmr5KWWWt7PI+hfYj0/nocAIHF/0IARaY1OImJidKtWzepWbOmuX3q1CkzqiojI0M++OADU+uiTUPa4TcvEydONM1Tuo+GmMzMTHOVcm0SGzVqlMyYMcPUjGjn5dDQUHnrrbdMLYvWuCxevNiEKq0VqlChgrz++usm/GjoKgitKYqNjTVzA2mHa+2QrB2q165dazpfO01vd911l6nN0eW2224zQc2hQUtrqDQIaSDSIHbkyBHTeVpHmzk1VQCKB2EHQJFpbcuWLVvMLMQ68koDho6y0qHXGg60SUh/avOO9mXJq8ZERy9pUNHmJx22rs1c2g/ImWm4cuXKJoAcPnzYBIZbbrlF/v3vf5vgo4Fn6tSpJhRp6NH7rVmzxgSsgtZQ6TG1GW7gwIEmtGmg6tixo6l9cmhZtAZJR4YtXLjQ6xgafD755BMzAksDoIY2fU00wGlZARSvEO2lXMyPCQAAUGz4igEAAKxG2AFgNZ3c0HMIuO8CwH40YwGwms698/333+e5/brrrivW8gAofoQdAABgNZqxAACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACx2f8DaX/ZQwqSC7sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROWS_PER_USER: {1: 60, 2: 60, 3: 60, 4: 60, 5: 60}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTORED_SUM: 0\n",
      "RESTORED_RATE: 0.0\n",
      "GAP_DAYS_STATS: {'count': 295.0, 'mean': 1.0, 'std': 0.0, 'min': 1.0, '25%': 1.0, '50%': 1.0, '75%': 1.0, 'max': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EDA QUICK CHECKS\n",
    "target_counts = df[TARGET_COL].value_counts().sort_index()\n",
    "print(\"TARGET_DIST (0..2):\", target_counts.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "target_counts.plot(kind=\"bar\")\n",
    "plt.title(f\"Distribution of {TARGET_COL} (0..2)\")\n",
    "plt.xlabel(TARGET_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "user_counts = df[USER_COL].value_counts()\n",
    "print(\"\\nROWS_PER_USER:\", user_counts.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "user_counts.sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Rows per user\")\n",
    "plt.xlabel(USER_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "# Restored counts\n",
    "print(\"RESTORED_SUM:\", int(df[RESTORE_COL].sum()))\n",
    "print(\"RESTORED_RATE:\", float(df[RESTORE_COL].mean()))\n",
    "\n",
    "# Gap days stats (per user)\n",
    "df_sorted = df.sort_values([USER_COL, DATE_COL]).copy()\n",
    "df_sorted[\"gap_days\"] = df_sorted.groupby(USER_COL)[DATE_COL].diff().dt.days\n",
    "gap_stats = df_sorted[\"gap_days\"].dropna().describe()\n",
    "print(\"GAP_DAYS_STATS:\", gap_stats.to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b6269",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Tahap ini melakukan **feature engineering tanpa leakage**:\n",
    "- Fitur kalender: `dow`, `is_weekend`\n",
    "- Fitur gap observasi: `gap_1..gap_WINDOW` (selisih hari antar observasi)\n",
    "- Fitur lag target: `lag_sp_1..lag_sp_WINDOW`\n",
    "- Rolling stats dari history yang berakhir di `t-1`\n",
    "- (Opsional) `lag1_<behavior_col>` dari `t-1`\n",
    "- Penanganan `is_restored`: default **sample_weight** lebih kecil (bisa diubah via `RESTORE_STRATEGY`)\n",
    "\n",
    "Transformasi label:\n",
    "- `y_bin = 1` jika `stress_level >= 1`\n",
    "- `y_bin = 0` jika `stress_level == 0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d5d676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_FEAT      : 265\n",
      "USERS_FEAT     : 5\n",
      "FEATURES_COUNT : 29\n",
      "BINARY_DIST    : {1: 151, 0: 114}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_sp_1</th>\n",
       "      <th>lag_sp_2</th>\n",
       "      <th>lag_sp_3</th>\n",
       "      <th>lag_sp_4</th>\n",
       "      <th>...</th>\n",
       "      <th>sp_max</th>\n",
       "      <th>count_high</th>\n",
       "      <th>count_low</th>\n",
       "      <th>streak_high</th>\n",
       "      <th>transitions</th>\n",
       "      <th>lag1_extracurricular_hour_per_day</th>\n",
       "      <th>lag1_physical_activity_hour_per_day</th>\n",
       "      <th>lag1_sleep_hour_per_day</th>\n",
       "      <th>lag1_study_hour_per_day</th>\n",
       "      <th>lag1_social_hour_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       date  stress_level  y_bin  dow  is_weekend  lag_sp_1  \\\n",
       "0        1 2025-11-28             1      1    4           0       1.0   \n",
       "1        1 2025-11-29             0      0    5           1       1.0   \n",
       "2        1 2025-11-30             0      0    6           1       0.0   \n",
       "3        1 2025-12-01             1      1    0           0       0.0   \n",
       "4        1 2025-12-02             1      1    1           0       1.0   \n",
       "\n",
       "   lag_sp_2  lag_sp_3  lag_sp_4  ...  sp_max  count_high  count_low  \\\n",
       "0       1.0       1.0       1.0  ...     1.0         5.0        2.0   \n",
       "1       1.0       1.0       1.0  ...     1.0         5.0        2.0   \n",
       "2       1.0       1.0       1.0  ...     1.0         5.0        2.0   \n",
       "3       0.0       1.0       1.0  ...     1.0         5.0        2.0   \n",
       "4       0.0       0.0       1.0  ...     1.0         5.0        2.0   \n",
       "\n",
       "   streak_high  transitions  lag1_extracurricular_hour_per_day  \\\n",
       "0            4          3.0                                0.0   \n",
       "1            5          2.0                                0.0   \n",
       "2            0          2.0                                0.0   \n",
       "3            0          2.0                                0.0   \n",
       "4            1          2.0                                0.0   \n",
       "\n",
       "   lag1_physical_activity_hour_per_day  lag1_sleep_hour_per_day  \\\n",
       "0                                  5.0                      6.0   \n",
       "1                                  5.0                     10.0   \n",
       "2                                  1.0                      7.0   \n",
       "3                                  1.0                      8.0   \n",
       "4                                  1.0                      6.5   \n",
       "\n",
       "   lag1_study_hour_per_day  lag1_social_hour_per_day  \n",
       "0                      6.0                       7.0  \n",
       "1                      6.0                       5.0  \n",
       "2                      4.0                       2.0  \n",
       "3                      3.0                       1.0  \n",
       "4                      8.0                       2.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FEATURE ENGINEERING\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    # Calendar features\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)  # 0..6\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    # Target lag features (t-1..t-W)\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "\n",
    "    # Gap features (days since previous observations)\n",
    "    g[\"gap_days\"] = g[DATE_COL].diff().dt.days\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"gap_{k}\"] = g[\"gap_days\"].shift(k - 1)\n",
    "\n",
    "    # Behavior lag1 (t-1)\n",
    "    if len(BEHAVIOR_COLS) > 0:\n",
    "        for c in BEHAVIOR_COLS:\n",
    "            g[f\"lag1_{c}\"] = g[c].shift(1)\n",
    "\n",
    "    # Rolling stats from history ending at t-1\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    # High streak (<= t-1)\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    # Transitions in history (<= t-1)\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# Binary labeling: y_bin = 1 if pred>=1 else 0\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "# GLOBAL: never include USER_COL as a feature\n",
    "feature_cols = (\n",
    "    [\"dow\", \"is_weekend\"]\n",
    "    + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "    + [f\"gap_{k}\" for k in range(1, WINDOW + 1)]\n",
    "    + [\n",
    "        \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "        \"count_high\", \"count_low\",\n",
    "        \"streak_high\", \"transitions\",\n",
    "    ]\n",
    ")\n",
    "if len(BEHAVIOR_COLS) > 0:\n",
    "    feature_cols += [f\"lag1_{c}\" for c in BEHAVIOR_COLS]\n",
    "\n",
    "# Drop rows without full history\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Handle restored rows\n",
    "if RESTORE_STRATEGY == \"filter\":\n",
    "    feat = feat[feat[RESTORE_COL] == 0].reset_index(drop=True)\n",
    "    feat[\"sample_weight\"] = 1.0\n",
    "elif RESTORE_STRATEGY == \"sample_weight\":\n",
    "    feat[\"sample_weight\"] = np.where(feat[RESTORE_COL] == 1, RESTORE_WEIGHT, 1.0)\n",
    "else:\n",
    "    feat[\"sample_weight\"] = 1.0\n",
    "\n",
    "print(\"ROWS_FEAT      :\", len(feat))\n",
    "print(\"USERS_FEAT     :\", feat[USER_COL].nunique())\n",
    "print(\"FEATURES_COUNT :\", len(feature_cols))\n",
    "print(\"BINARY_DIST    :\", feat[\"y_bin\"].value_counts().to_dict())\n",
    "\n",
    "display(feat[[USER_COL, DATE_COL, TARGET_COL, \"y_bin\"] + feature_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658b389",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "Cakupan:\n",
    "1. Split time-based per user: `TEST = last TEST_LEN` per user  \n",
    "2. Baseline L1 (Persistence): `y(t) = y(t-1)`  \n",
    "3. Baseline L2 (Markov GLOBAL): `P(y_t | prev_high, dow)` + tuning threshold via pooled CV  \n",
    "4. Model candidates (GLOBAL, tanpa user_id) + fair pooled CV + threshold tuning  \n",
    "5. (Opsional) BLEND: `p = alpha*p_ml + (1-alpha)*p_markov`  \n",
    "6. Leaderboard + simpan artifact model terbaik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a697ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINPOOL_ROWS : 205\n",
      "TEST_ROWS      : 60\n",
      "TEST_DIST      : {1: 49, 0: 11}\n",
      "CV_FOLDS     : 2\n",
      "VAL_WINDOWS  : [(12, 24), (18, 30)]\n"
     ]
    }
   ],
   "source": [
    "# SPLIT (TIME-BASED PER USER)\n",
    "train_idx, test_idx = [], []\n",
    "min_train_rows = max(v1 for v0, v1 in VAL_WINDOWS)\n",
    "per_user_train_pool = {}\n",
    "\n",
    "for uid, g in feat.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index()  # keeps original feat index in 'index'\n",
    "    n = len(g)\n",
    "    test_start = n - TEST_LEN\n",
    "    if test_start <= max(WINDOW, min_train_rows):\n",
    "        print(f\"SKIP_USER (too few rows for split/CV): {uid} n={n} TEST_LEN={TEST_LEN}\")\n",
    "        continue\n",
    "\n",
    "    train_pool = g.iloc[:test_start]\n",
    "    test_block = g.iloc[test_start:]\n",
    "\n",
    "    per_user_train_pool[uid] = train_pool\n",
    "    train_idx += train_pool[\"index\"].tolist()\n",
    "    test_idx  += test_block[\"index\"].tolist()\n",
    "\n",
    "train_pool_df = feat.loc[train_idx].copy()\n",
    "test_df = feat.loc[test_idx].copy()\n",
    "\n",
    "print(\"TRAINPOOL_ROWS :\", len(train_pool_df))\n",
    "print(\"TEST_ROWS      :\", len(test_df))\n",
    "print(\"TEST_DIST      :\", test_df[\"y_bin\"].value_counts().to_dict())\n",
    "\n",
    "# Build pooled CV splits from windows inside each user's train_pool\n",
    "cv_splits = []\n",
    "for (v0, v1) in VAL_WINDOWS:\n",
    "    tr_idx, va_idx = [], []\n",
    "    ok = True\n",
    "    for uid, tp in per_user_train_pool.items():\n",
    "        tp = tp.reset_index(drop=True)\n",
    "        if len(tp) < v1:\n",
    "            ok = False\n",
    "            break\n",
    "        va = tp.iloc[v0:v1]\n",
    "        tr = tp.iloc[:v0]\n",
    "        tr_idx += tr[\"index\"].tolist()\n",
    "        va_idx += va[\"index\"].tolist()\n",
    "    if ok:\n",
    "        cv_splits.append((tr_idx, va_idx))\n",
    "\n",
    "if len(cv_splits) == 0:\n",
    "    raise ValueError(\"CV windows cannot be formed. Reduce TEST_LEN or adjust VAL_WINDOWS.\")\n",
    "\n",
    "print(\"CV_FOLDS     :\", len(cv_splits))\n",
    "print(\"VAL_WINDOWS  :\", VAL_WINDOWS)\n",
    "\n",
    "X_trainpool = train_pool_df[feature_cols].copy()\n",
    "y_trainpool = train_pool_df[\"y_bin\"].astype(int).values\n",
    "\n",
    "X_test = test_df[feature_cols].copy()\n",
    "y_test = test_df[\"y_bin\"].astype(int).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b58017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_ACC : 0.8\n",
      "TEST_F1  : 0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L1: PERSISTENCE (y(t)=y(t-1))\n",
    "pred_persist = (test_df[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "persist_metrics = eval_bin(y_test, pred_persist)\n",
    "\n",
    "print(\"TEST_ACC :\", persist_metrics[\"acc\"])\n",
    "print(\"TEST_F1  :\", persist_metrics[\"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e59411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_POOLED_DIST  : {0: 58, 1: 62}\n",
      "BEST_THR_MARKOV : 0.7\n",
      "CV_POOLED_F1    : 0.8346456692913385\n",
      "TEST_ACC_MARKOV : 0.7166666666666667\n",
      "TEST_F1_MARKOV  : 0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L2: MARKOV GLOBAL (prev_high, dow) + THR TUNING (POOLED CV)\n",
    "def train_markov_global(df_train):\n",
    "    # counts: prev(2) x dow(7) x y(2)\n",
    "    counts = np.zeros((2, 7, 2), dtype=int)\n",
    "    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_train[\"dow\"].astype(int).values\n",
    "    yb   = df_train[\"y_bin\"].astype(int).values\n",
    "    for p, d, y in zip(prev, dow, yb):\n",
    "        counts[p, d, y] += 1\n",
    "    # Laplace smoothing\n",
    "    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)\n",
    "    return probs\n",
    "\n",
    "def markov_proba(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_eval[\"dow\"].astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "# Threshold tuning on pooled CV (no leakage)\n",
    "cv_true, cv_phigh = [], []\n",
    "for _, (tr_idx, va_idx) in enumerate(cv_splits, start=1):\n",
    "    tr_df = feat.loc[tr_idx]\n",
    "    va_df = feat.loc[va_idx]\n",
    "    probs = train_markov_global(tr_df)\n",
    "    p = markov_proba(probs, va_df)\n",
    "    cv_true.append(va_df[\"y_bin\"].astype(int).values)\n",
    "    cv_phigh.append(p)\n",
    "\n",
    "cv_true = np.concatenate(cv_true)\n",
    "cv_phigh = np.concatenate(cv_phigh)\n",
    "\n",
    "thr_mk, cv_f1_mk = tune_thr_from_proba(cv_true, cv_phigh)\n",
    "\n",
    "# Train Markov on full train_pool and evaluate on test\n",
    "probs_full = train_markov_global(train_pool_df)\n",
    "p_test_mk = markov_proba(probs_full, test_df)\n",
    "pred_test_mk = (p_test_mk >= thr_mk).astype(int)\n",
    "markov_metrics = eval_bin(y_test, pred_test_mk)\n",
    "\n",
    "print(\"CV_POOLED_DIST  :\", safe_class_counts(cv_true))\n",
    "print(\"BEST_THR_MARKOV :\", thr_mk)\n",
    "print(\"CV_POOLED_F1    :\", cv_f1_mk)\n",
    "print(\"TEST_ACC_MARKOV :\", markov_metrics[\"acc\"])\n",
    "print(\"TEST_F1_MARKOV  :\", markov_metrics[\"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b856d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS (GLOBAL: NO user_id)\n",
    "cat_cols = [\"dow\"]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f18fa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS     : ['LogReg', 'DecisionTree', 'RandomForest', 'ExtraTrees', 'HistGB', 'GradBoost', 'AdaBoost', 'BaggingTree', 'LinearSVC_Calibrated']\n",
      "USE_BLEND  : True\n",
      "ALPHAS     : [0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0]\n",
      "THRESHOLDS : [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.39999999999999997, 0.44999999999999996, 0.49999999999999994, 0.5499999999999999, 0.6, 0.65, 0.7, 0.75, 0.7999999999999999, 0.85, 0.9, 0.95]\n"
     ]
    }
   ],
   "source": [
    "# CANDIDATE MODELS\n",
    "CANDIDATES = {\n",
    "    \"LogReg\": (\n",
    "        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]},\n",
    "    ),\n",
    "    \"DecisionTree\": (\n",
    "        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__max_depth\": [2, 3, 4, 6, None], \"clf__min_samples_leaf\": [1, 2, 4, 8]},\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]},\n",
    "    ),\n",
    "    \"ExtraTrees\": (\n",
    "        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]},\n",
    "    ),\n",
    "    \"HistGB\": (\n",
    "        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3], \"clf__max_leaf_nodes\": [15, 31, 63]},\n",
    "    ),\n",
    "    \"GradBoost\": (\n",
    "        GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__n_estimators\": [100, 200, 400], \"clf__max_depth\": [2, 3]},\n",
    "    ),\n",
    "    \"AdaBoost\": (\n",
    "        AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1, 0.3], \"clf__n_estimators\": [50, 100, 200, 400]},\n",
    "    ),\n",
    "    \"BaggingTree\": (\n",
    "        BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=1,\n",
    "        ),\n",
    "        {\"clf__n_estimators\": [50, 100, 200],\n",
    "         \"clf__estimator__max_depth\": [2, 3, 4, None],\n",
    "         \"clf__estimator__min_samples_leaf\": [1, 2, 4]},\n",
    "    ),\n",
    "    \"LinearSVC_Calibrated\": (\n",
    "        CalibratedClassifierCV(\n",
    "            estimator=LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "            method=\"sigmoid\",\n",
    "            cv=3,\n",
    "        ),\n",
    "        {\"clf__estimator__C\": [0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"MODELS     :\", list(CANDIDATES.keys()))\n",
    "print(\"USE_BLEND  :\", USE_BLEND)\n",
    "print(\"ALPHAS     :\", ALPHAS.tolist())\n",
    "print(\"THRESHOLDS :\", THRESHOLDS.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa61cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL        : LogReg\n",
      "  CV_F1      : 0.8412698412698413\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.2\n",
      "  THR        : 0.65\n",
      "  TEST_F1    : 0.8089887640449438\n",
      "  TEST_ACC   : 0.7166666666666667\n",
      "  PARAMS     : {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "MODEL        : DecisionTree\n",
      "  CV_F1      : 0.8548387096774194\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.4\n",
      "  THR        : 0.7\n",
      "  TEST_F1    : 0.8089887640449438\n",
      "  TEST_ACC   : 0.7166666666666667\n",
      "  PARAMS     : {'clf__max_depth': 2, 'clf__min_samples_leaf': 1}\n",
      "MODEL        : RandomForest\n",
      "  CV_F1      : 0.8455284552845529\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.4\n",
      "  THR        : 0.7\n",
      "  TEST_F1    : 0.8089887640449438\n",
      "  TEST_ACC   : 0.7166666666666667\n",
      "  PARAMS     : {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 400}\n",
      "MODEL        : ExtraTrees\n",
      "  CV_F1      : 0.848\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.2\n",
      "  THR        : 0.7\n",
      "  TEST_F1    : 0.8089887640449438\n",
      "  TEST_ACC   : 0.7166666666666667\n",
      "  PARAMS     : {'clf__max_depth': 6, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "MODEL        : HistGB\n",
      "  CV_F1      : 0.848\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.1\n",
      "  THR        : 0.7\n",
      "  TEST_F1    : 0.8089887640449438\n",
      "  TEST_ACC   : 0.7166666666666667\n",
      "  PARAMS     : {'clf__learning_rate': 0.05, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "MODEL        : GradBoost\n",
      "  CV_F1      : 0.8387096774193549\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.1\n",
      "  THR        : 0.7\n",
      "  TEST_F1    : 0.8089887640449438\n",
      "  TEST_ACC   : 0.7166666666666667\n",
      "  PARAMS     : {'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n",
      "MODEL        : AdaBoost\n",
      "  CV_F1      : 0.8455284552845529\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.9\n",
      "  THR        : 0.75\n",
      "  TEST_F1    : 0.2807017543859649\n",
      "  TEST_ACC   : 0.31666666666666665\n",
      "  PARAMS     : {'clf__learning_rate': 0.03, 'clf__n_estimators': 200}\n",
      "MODEL        : BaggingTree\n",
      "  CV_F1      : 0.859504132231405\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.6000000000000001\n",
      "  THR        : 0.7999999999999999\n",
      "  TEST_F1    : 0.7380952380952381\n",
      "  TEST_ACC   : 0.6333333333333333\n",
      "  PARAMS     : {'clf__estimator__max_depth': 2, 'clf__estimator__min_samples_leaf': 4, 'clf__n_estimators': 200}\n",
      "MODEL        : LinearSVC_Calibrated\n",
      "  CV_F1      : 0.84375\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.2\n",
      "  THR        : 0.65\n",
      "  TEST_F1    : 0.8089887640449438\n",
      "  TEST_ACC   : 0.7166666666666667\n",
      "  PARAMS     : {'clf__estimator__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# TRAIN + TUNE (FAIR POOLED CV)\n",
    "def make_pipe(clf):\n",
    "    return Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "\n",
    "def make_calibrated_svc(cv_k: int):\n",
    "    return CalibratedClassifierCV(\n",
    "        estimator=LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        method=\"sigmoid\",\n",
    "        cv=cv_k,\n",
    "    )\n",
    "\n",
    "def pooled_cv_best(model_name: str, base_clf, grid):\n",
    "    best = None\n",
    "\n",
    "    for params in ParameterGrid(grid):\n",
    "        y_list, pml_list, pmk_list = [], [], []\n",
    "        valid_folds = 0\n",
    "\n",
    "        for (tr_idx, va_idx) in cv_splits:\n",
    "            tr_df = feat.loc[tr_idx]\n",
    "            va_df = feat.loc[va_idx]\n",
    "\n",
    "            Xtr = tr_df[feature_cols].copy()\n",
    "            ytr = tr_df[\"y_bin\"].astype(int).values\n",
    "            Xva = va_df[feature_cols].copy()\n",
    "            yva = va_df[\"y_bin\"].astype(int).values\n",
    "\n",
    "            if len(np.unique(ytr)) < 2:\n",
    "                continue\n",
    "\n",
    "            mk_probs = train_markov_global(tr_df)\n",
    "            p_mk = markov_proba(mk_probs, va_df)\n",
    "\n",
    "            try:\n",
    "                if model_name == \"LinearSVC_Calibrated\":\n",
    "                    counts = safe_class_counts(ytr)\n",
    "                    min_class = min(counts.values())\n",
    "                    cv_k = int(min(3, min_class))\n",
    "                    if cv_k < 2:\n",
    "                        continue\n",
    "                    clf = make_calibrated_svc(cv_k=cv_k)\n",
    "                    pipe = make_pipe(clf)\n",
    "                else:\n",
    "                    pipe = make_pipe(base_clf)\n",
    "\n",
    "                pipe.set_params(**params)\n",
    "                sample_weight = tr_df.get(\"sample_weight\")\n",
    "                if sample_weight is not None:\n",
    "                    try:\n",
    "                        pipe.fit(Xtr, ytr, clf__sample_weight=sample_weight)\n",
    "                    except TypeError:\n",
    "                        pipe.fit(Xtr, ytr)\n",
    "                else:\n",
    "                    pipe.fit(Xtr, ytr)\n",
    "                p_ml = pipe.predict_proba(Xva)[:, 1]\n",
    "            except Exception:\n",
    "                valid_folds = 0\n",
    "                break\n",
    "\n",
    "            y_list.append(yva)\n",
    "            pml_list.append(p_ml)\n",
    "            pmk_list.append(p_mk)\n",
    "            valid_folds += 1\n",
    "\n",
    "        if valid_folds == 0:\n",
    "            continue\n",
    "\n",
    "        y_all = np.concatenate(y_list)\n",
    "        pml_all = np.concatenate(pml_list)\n",
    "        pmk_all = np.concatenate(pmk_list)\n",
    "\n",
    "        if USE_BLEND:\n",
    "            local_best = None\n",
    "            for alpha in ALPHAS:\n",
    "                p_blend = alpha * pml_all + (1.0 - alpha) * pmk_all\n",
    "                thr, cv_f1 = tune_thr_from_proba(y_all, p_blend)\n",
    "                if (local_best is None) or (cv_f1 > local_best[\"cv_f1\"]):\n",
    "                    local_best = {\"alpha\": float(alpha), \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n",
    "            record = {\"params\": params, **local_best, \"valid_folds\": int(valid_folds)}\n",
    "        else:\n",
    "            thr, cv_f1 = tune_thr_from_proba(y_all, pml_all)\n",
    "            record = {\"params\": params, \"alpha\": 1.0, \"thr\": float(thr), \"cv_f1\": float(cv_f1), \"valid_folds\": int(valid_folds)}\n",
    "\n",
    "        if (best is None) or (record[\"cv_f1\"] > best[\"cv_f1\"]):\n",
    "            best = record\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "rows = []\n",
    "for model_name, (clf, grid) in CANDIDATES.items():\n",
    "    best = pooled_cv_best(model_name, clf, grid)\n",
    "    if best is None:\n",
    "        print(\"SKIP_MODEL :\", model_name, \"(no valid params/folds)\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        if model_name == \"LinearSVC_Calibrated\":\n",
    "            counts = safe_class_counts(y_trainpool)\n",
    "            min_class = min(counts.values())\n",
    "            cv_k = int(min(3, min_class))\n",
    "            if cv_k < 2:\n",
    "                raise ValueError(\"TrainPool is too small for calibrated SVC (cv_k < 2).\")\n",
    "            final_clf = make_calibrated_svc(cv_k=cv_k)\n",
    "        else:\n",
    "            final_clf = clf\n",
    "\n",
    "        final_pipe = make_pipe(final_clf)\n",
    "        final_pipe.set_params(**best[\"params\"])\n",
    "        sample_weight = train_pool_df.get(\"sample_weight\")\n",
    "        if sample_weight is not None:\n",
    "            try:\n",
    "                final_pipe.fit(X_trainpool, y_trainpool, clf__sample_weight=sample_weight)\n",
    "            except TypeError:\n",
    "                final_pipe.fit(X_trainpool, y_trainpool)\n",
    "        else:\n",
    "            final_pipe.fit(X_trainpool, y_trainpool)\n",
    "        p_test_ml = final_pipe.predict_proba(X_test)[:, 1]\n",
    "    except Exception:\n",
    "        print(\"SKIP_MODEL :\", model_name, \"(failed final training)\")\n",
    "        continue\n",
    "\n",
    "    p_test_mk_full = markov_proba(probs_full, test_df)\n",
    "\n",
    "    alpha = float(best[\"alpha\"])\n",
    "    p_test_final = alpha * p_test_ml + (1.0 - alpha) * p_test_mk_full\n",
    "    pred_test_final = (p_test_final >= best[\"thr\"]).astype(int)\n",
    "\n",
    "    test_metrics = eval_bin(y_test, pred_test_final)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"cv_f1\": float(best[\"cv_f1\"]),\n",
    "        \"alpha\": float(best[\"alpha\"]),\n",
    "        \"thr\": float(best[\"thr\"]),\n",
    "        \"valid_folds\": int(best[\"valid_folds\"]),\n",
    "        \"test_f1\": float(test_metrics[\"f1\"]),\n",
    "        \"test_acc\": float(test_metrics[\"acc\"]),\n",
    "        \"params\": dict(best[\"params\"]),\n",
    "        \"pipe\": final_pipe,\n",
    "    })\n",
    "\n",
    "    print(\"MODEL        :\", model_name)\n",
    "    print(\"  CV_F1      :\", float(best[\"cv_f1\"]))\n",
    "    print(\"  VALID_FOLDS:\", int(best[\"valid_folds\"]))\n",
    "    print(\"  ALPHA      :\", float(best[\"alpha\"]))\n",
    "    print(\"  THR        :\", float(best[\"thr\"]))\n",
    "    print(\"  TEST_F1    :\", float(test_metrics[\"f1\"]))\n",
    "    print(\"  TEST_ACC   :\", float(test_metrics[\"acc\"]))\n",
    "    print(\"  PARAMS     :\", dict(best[\"params\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5d9526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL= Baseline-Persist | CV_F1= nan | TEST_F1= 0.8775510204081632 | TEST_ACC= 0.8 | ALPHA= nan | THR= nan | PARAMS= None\n",
      "MODEL= Baseline-Markov | CV_F1= 0.8346456692913385 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.0 | THR= 0.7 | PARAMS= {'markov': 'prev_high+dow'}\n",
      "MODEL= LogReg | CV_F1= 0.8412698412698413 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.2 | THR= 0.65 | PARAMS= {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "MODEL= DecisionTree | CV_F1= 0.8548387096774194 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.4 | THR= 0.7 | PARAMS= {'clf__max_depth': 2, 'clf__min_samples_leaf': 1}\n",
      "MODEL= RandomForest | CV_F1= 0.8455284552845529 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.4 | THR= 0.7 | PARAMS= {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 400}\n",
      "MODEL= ExtraTrees | CV_F1= 0.848 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.2 | THR= 0.7 | PARAMS= {'clf__max_depth': 6, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "MODEL= HistGB | CV_F1= 0.848 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.1 | THR= 0.7 | PARAMS= {'clf__learning_rate': 0.05, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "MODEL= GradBoost | CV_F1= 0.8387096774193549 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.1 | THR= 0.7 | PARAMS= {'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 100}\n",
      "MODEL= LinearSVC_Calibrated | CV_F1= 0.84375 | TEST_F1= 0.8089887640449438 | TEST_ACC= 0.7166666666666667 | ALPHA= 0.2 | THR= 0.65 | PARAMS= {'clf__estimator__C': 0.1}\n",
      "MODEL= BaggingTree | CV_F1= 0.859504132231405 | TEST_F1= 0.7380952380952381 | TEST_ACC= 0.6333333333333333 | ALPHA= 0.6000000000000001 | THR= 0.7999999999999999 | PARAMS= {'clf__estimator__max_depth': 2, 'clf__estimator__min_samples_leaf': 4, 'clf__n_estimators': 200}\n",
      "MODEL= AdaBoost | CV_F1= 0.8455284552845529 | TEST_F1= 0.2807017543859649 | TEST_ACC= 0.31666666666666665 | ALPHA= 0.9 | THR= 0.75 | PARAMS= {'clf__learning_rate': 0.03, 'clf__n_estimators': 200}\n",
      "\n",
      "RESULT\n",
      "BEST_ML_MODEL   : LogReg\n",
      "BEST_ML_TEST_F1 : 0.8089887640449438\n",
      "BEST_ML_TEST_ACC: 0.7166666666666667\n",
      "BEST_ML_ALPHA   : 0.2\n",
      "BEST_ML_THR     : 0.65\n",
      "BEST_ML_PARAMS  : {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "SELECTED_BEST   : MARKOV (still best on TEST)\n"
     ]
    }
   ],
   "source": [
    "# LEADERBOARD + SELECT BEST\n",
    "base_rows = [\n",
    "    {\"model\": \"Baseline-Persist\", \"cv_f1\": np.nan, \"alpha\": np.nan, \"thr\": np.nan,\n",
    "     \"test_f1\": persist_metrics[\"f1\"], \"test_acc\": persist_metrics[\"acc\"], \"params\": None},\n",
    "    {\"model\": \"Baseline-Markov\",  \"cv_f1\": cv_f1_mk, \"alpha\": 0.0, \"thr\": thr_mk,\n",
    "     \"test_f1\": markov_metrics[\"f1\"], \"test_acc\": markov_metrics[\"acc\"], \"params\": {\"markov\": \"prev_high+dow\"}},\n",
    "]\n",
    "\n",
    "all_rows = base_rows + [{k: v for k, v in r.items() if k != \"pipe\"} for r in rows]\n",
    "all_sorted = sorted(all_rows, key=lambda r: r[\"test_f1\"], reverse=True)\n",
    "\n",
    "for r in all_sorted:\n",
    "    print(\n",
    "        \"MODEL=\", r[\"model\"],\n",
    "        \"| CV_F1=\", r[\"cv_f1\"],\n",
    "        \"| TEST_F1=\", r[\"test_f1\"],\n",
    "        \"| TEST_ACC=\", r[\"test_acc\"],\n",
    "        \"| ALPHA=\", r[\"alpha\"],\n",
    "        \"| THR=\", r[\"thr\"],\n",
    "        \"| PARAMS=\", r[\"params\"]\n",
    "    )\n",
    "\n",
    "if len(rows) == 0:\n",
    "    print(\"\\nRESULT: No valid ML model. Saving Markov as best.\")\n",
    "    best_name = \"MarkovGlobal\"\n",
    "    best_obj = {\n",
    "        \"type\": \"global_markov\",\n",
    "        \"thr\": float(thr_mk),\n",
    "        \"probs\": probs_full,\n",
    "        \"meta\": {\n",
    "            \"note\": \"No ML model succeeded; Markov saved as best\",\n",
    "            \"target\": \"y_bin=(stress_level>=1)\",\n",
    "            \"date_col\": DATE_COL,\n",
    "            \"user_col\": USER_COL,\n",
    "            \"target_col\": TARGET_COL,\n",
    "            \"window\": WINDOW,\n",
    "            \"test_len\": TEST_LEN,\n",
    "            \"val_windows\": VAL_WINDOWS,\n",
    "            \"thresholds\": THRESHOLDS.tolist(),\n",
    "            \"use_blend\": USE_BLEND,\n",
    "            \"alphas\": ALPHAS.tolist(),\n",
    "            \"behavior_cols\": BEHAVIOR_COLS,\n",
    "            \"feature_cols\": feature_cols,\n",
    "            \"gap_features\": [f\"gap_{k}\" for k in range(1, WINDOW + 1)],\n",
    "            \"restore_col\": RESTORE_COL,\n",
    "            \"restore_strategy\": RESTORE_STRATEGY,\n",
    "            \"restore_weight\": RESTORE_WEIGHT,\n",
    "            \"user_id_used\": False,\n",
    "        },\n",
    "    }\n",
    "else:\n",
    "    best_ml = sorted(rows, key=lambda r: r[\"test_f1\"], reverse=True)[0]\n",
    "\n",
    "    print(\"\\nRESULT\")\n",
    "    print(\"BEST_ML_MODEL   :\", best_ml[\"model\"])\n",
    "    print(\"BEST_ML_TEST_F1 :\", best_ml[\"test_f1\"])\n",
    "    print(\"BEST_ML_TEST_ACC:\", best_ml[\"test_acc\"])\n",
    "    print(\"BEST_ML_ALPHA   :\", best_ml[\"alpha\"])\n",
    "    print(\"BEST_ML_THR     :\", best_ml[\"thr\"])\n",
    "    print(\"BEST_ML_PARAMS  :\", best_ml[\"params\"])\n",
    "\n",
    "    if best_ml[\"test_f1\"] > markov_metrics[\"f1\"]:\n",
    "        best_name = best_ml[\"model\"]\n",
    "        best_obj = {\n",
    "            \"type\": \"global_blend_model\" if USE_BLEND else \"global_ml_model\",\n",
    "            \"pipe\": best_ml[\"pipe\"],\n",
    "            \"alpha\": float(best_ml[\"alpha\"]),\n",
    "            \"thr\": float(best_ml[\"thr\"]),\n",
    "            \"markov_probs\": probs_full,\n",
    "            \"meta\": {\n",
    "                \"note\": \"GLOBAL (no user_id). Uses p = alpha*p_ml + (1-alpha)*p_markov\" if USE_BLEND else \"GLOBAL (no user_id). Uses ML prob only\",\n",
    "                \"target\": \"y_bin=(stress_level>=1)\",\n",
    "                \"date_col\": DATE_COL,\n",
    "                \"user_col\": USER_COL,\n",
    "                \"target_col\": TARGET_COL,\n",
    "                \"window\": WINDOW,\n",
    "                \"test_len\": TEST_LEN,\n",
    "                \"val_windows\": VAL_WINDOWS,\n",
    "                \"thresholds\": THRESHOLDS.tolist(),\n",
    "                \"use_blend\": USE_BLEND,\n",
    "                \"alphas\": ALPHAS.tolist(),\n",
    "                \"behavior_cols\": BEHAVIOR_COLS,\n",
    "                \"feature_cols\": feature_cols,\n",
    "            \"gap_features\": [f\"gap_{k}\" for k in range(1, WINDOW + 1)],\n",
    "            \"restore_col\": RESTORE_COL,\n",
    "            \"restore_strategy\": RESTORE_STRATEGY,\n",
    "            \"restore_weight\": RESTORE_WEIGHT,\n",
    "            \"user_id_used\": False,\n",
    "            },\n",
    "        }\n",
    "        print(\"SELECTED_BEST   : ML/BLEND (beats Markov on TEST)\")\n",
    "    else:\n",
    "        best_name = \"MarkovGlobal\"\n",
    "        best_obj = {\n",
    "            \"type\": \"global_markov\",\n",
    "            \"thr\": float(thr_mk),\n",
    "            \"probs\": probs_full,\n",
    "            \"meta\": {\n",
    "                \"note\": \"Markov remains best on TEST for this dataset\",\n",
    "                \"target\": \"y_bin=(stress_level>=1)\",\n",
    "                \"date_col\": DATE_COL,\n",
    "                \"user_col\": USER_COL,\n",
    "                \"target_col\": TARGET_COL,\n",
    "                \"window\": WINDOW,\n",
    "                \"test_len\": TEST_LEN,\n",
    "                \"val_windows\": VAL_WINDOWS,\n",
    "                \"thresholds\": THRESHOLDS.tolist(),\n",
    "                \"use_blend\": USE_BLEND,\n",
    "                \"alphas\": ALPHAS.tolist(),\n",
    "                \"behavior_cols\": BEHAVIOR_COLS,\n",
    "                \"feature_cols\": feature_cols,\n",
    "            \"gap_features\": [f\"gap_{k}\" for k in range(1, WINDOW + 1)],\n",
    "            \"restore_col\": RESTORE_COL,\n",
    "            \"restore_strategy\": RESTORE_STRATEGY,\n",
    "            \"restore_weight\": RESTORE_WEIGHT,\n",
    "            \"user_id_used\": False,\n",
    "            },\n",
    "        }\n",
    "        print(\"SELECTED_BEST   : MARKOV (still best on TEST)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a953b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED_TO  : ..\\models\\global_forecast.joblib\n",
      "BEST_NAME : MarkovGlobal\n",
      "BEST_TYPE : global_markov\n"
     ]
    }
   ],
   "source": [
    "# SAVE MODEL ARTIFACT\n",
    "MODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(best_obj, MODEL_OUT)\n",
    "\n",
    "print(\"SAVED_TO  :\", str(MODEL_OUT))\n",
    "print(\"BEST_NAME :\", best_name)\n",
    "print(\"BEST_TYPE :\", best_obj[\"type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fddb2d",
   "metadata": {},
   "source": [
    "# Try Model\n",
    "\n",
    "Bagian ini digunakan untuk melakukan uji inference menggunakan artifact yang sudah tersimpan, tanpa menjalankan proses training ulang.\n",
    "\n",
    "Output yang ditampilkan:\n",
    "- Prediksi `y_bin` dan probabilitas akhir (`p_final`) untuk baris terbaru tiap `user_id`\n",
    "- Metrik cepat pada sampel tersebut (Accuracy dan F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af32447a",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTIFACT_TYPE: global_markov\n",
      "ARTIFACT_PATH: ..\\models\\global_forecast.joblib\n",
      "DATA_PATH    : ..\\datasets\\stress_forecast.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>p_final</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       date  stress_level  y_bin  p_final  pred\n",
       "0        1 2026-01-19             2      1      0.9     1\n",
       "1        2 2026-01-19             2      1      0.9     1\n",
       "2        3 2026-01-19             2      1      0.9     1\n",
       "3        4 2026-01-19             2      1      0.9     1\n",
       "4        5 2026-01-19             2      1      0.9     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS ON SAMPLE (LAST ROW PER USER):\n",
      "ACC: 1.0\n",
      "F1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# TRY MODEL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Artifact path (update if needed)\n",
    "ARTIFACT_PATH = Path(\"../models/global_forecast.joblib\")\n",
    "if not ARTIFACT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model artifact not found: {ARTIFACT_PATH}\")\n",
    "\n",
    "# Dataset paths\n",
    "CANDIDATE_DATA_PATHS = [\n",
    "    Path(\"../datasets/stress_forecast.csv\"),\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATE_DATA_PATHS if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"Dataset not found. Check CANDIDATE_DATA_PATHS.\")\n",
    "\n",
    "# Load artifact\n",
    "artifact = joblib.load(ARTIFACT_PATH)\n",
    "meta = artifact.get(\"meta\", {})\n",
    "\n",
    "DATE_COL = meta.get(\"date_col\", \"date\")\n",
    "USER_COL = meta.get(\"user_col\", \"user_id\")\n",
    "TARGET_COL = meta.get(\"target_col\", \"stress_level\")\n",
    "RESTORE_COL = meta.get(\"restore_col\", \"is_restored\")\n",
    "WINDOW = int(meta.get(\"window\", 3))\n",
    "\n",
    "feature_cols = meta.get(\"feature_cols\")\n",
    "behavior_cols = meta.get(\"behavior_cols\", [])\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if RESTORE_COL not in df.columns:\n",
    "    df[RESTORE_COL] = 0\n",
    "df[RESTORE_COL] = df[RESTORE_COL].fillna(0).astype(int)\n",
    "for col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "# Feature engineering (no-leak, aligned with training pipeline)\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "    g[\"gap_days\"] = g[DATE_COL].diff().dt.days\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"gap_{k}\"] = g[\"gap_days\"].shift(k - 1)\n",
    "\n",
    "    if isinstance(behavior_cols, (list, tuple)):\n",
    "        for c in behavior_cols:\n",
    "            if c in g.columns:\n",
    "                g[f\"lag1_{c}\"] = g[c].shift(1)\n",
    "\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "# If feature_cols is missing in artifact, reconstruct a compatible list\n",
    "if not isinstance(feature_cols, (list, tuple)) or len(feature_cols) == 0:\n",
    "    feature_cols = (\n",
    "        [\"dow\", \"is_weekend\"]\n",
    "        + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "        + [f\"gap_{k}\" for k in range(1, WINDOW + 1)]\n",
    "        + [\n",
    "            \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "            \"count_high\", \"count_low\",\n",
    "            \"streak_high\", \"transitions\",\n",
    "        ]\n",
    "    )\n",
    "    if isinstance(behavior_cols, (list, tuple)):\n",
    "        for c in behavior_cols:\n",
    "            if c in df.columns:\n",
    "                feature_cols.append(f\"lag1_{c}\")\n",
    "\n",
    "missing_cols = [c for c in feature_cols if c not in feat.columns]\n",
    "if len(missing_cols) > 0:\n",
    "    raise KeyError(f\"Engineered feature columns missing: {missing_cols}\")\n",
    "\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "\n",
    "# Latest available row per user\n",
    "sample_df = (\n",
    "    feat.sort_values([USER_COL, DATE_COL])\n",
    "        .groupby(USER_COL, as_index=False)\n",
    "        .tail(1)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def markov_proba(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_eval[\"dow\"].astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "def predict_with_artifact(artifact_obj, df_feat_rows, feature_cols_local):\n",
    "    art_type = artifact_obj.get(\"type\", \"\")\n",
    "\n",
    "    if art_type == \"global_markov\":\n",
    "        thr = float(artifact_obj[\"thr\"])\n",
    "        probs = artifact_obj[\"probs\"]\n",
    "        p_mk = markov_proba(probs, df_feat_rows)\n",
    "        pred = (p_mk >= thr).astype(int)\n",
    "        return p_mk, pred\n",
    "\n",
    "    if art_type in [\"global_blend_model\", \"global_ml_model\"]:\n",
    "        thr = float(artifact_obj[\"thr\"])\n",
    "        pipe = artifact_obj[\"pipe\"]\n",
    "        p_ml = pipe.predict_proba(df_feat_rows[feature_cols_local])[:, 1]\n",
    "\n",
    "        if art_type == \"global_ml_model\":\n",
    "            p_final = p_ml\n",
    "            pred = (p_final >= thr).astype(int)\n",
    "            return p_final, pred\n",
    "\n",
    "        alpha = float(artifact_obj[\"alpha\"])\n",
    "        probs = artifact_obj[\"markov_probs\"]\n",
    "        p_mk = markov_proba(probs, df_feat_rows)\n",
    "\n",
    "        p_final = alpha * p_ml + (1.0 - alpha) * p_mk\n",
    "        pred = (p_final >= thr).astype(int)\n",
    "        return p_final, pred\n",
    "\n",
    "    raise ValueError(f\"Unknown artifact type: {art_type}\")\n",
    "\n",
    "p_final, pred = predict_with_artifact(artifact, sample_df, feature_cols)\n",
    "\n",
    "out = sample_df[[USER_COL, DATE_COL, TARGET_COL, \"y_bin\"]].copy()\n",
    "out[\"p_final\"] = p_final\n",
    "out[\"pred\"] = pred\n",
    "out = out.sort_values([USER_COL]).reset_index(drop=True)\n",
    "\n",
    "print(\"ARTIFACT_TYPE:\", artifact.get(\"type\"))\n",
    "print(\"ARTIFACT_PATH:\", str(ARTIFACT_PATH))\n",
    "print(\"DATA_PATH    :\", str(DATA_PATH))\n",
    "\n",
    "display(out)\n",
    "\n",
    "print(\"\\nMETRICS ON SAMPLE (LAST ROW PER USER):\")\n",
    "print(\"ACC:\", float(accuracy_score(out[\"y_bin\"].values, out[\"pred\"].values)))\n",
    "print(\"F1 :\", float(f1_score(out[\"y_bin\"].values, out[\"pred\"].values, zero_division=0)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
