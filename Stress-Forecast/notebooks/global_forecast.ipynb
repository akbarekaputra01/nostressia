{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4f077d",
   "metadata": {},
   "source": [
    "# Imports and Setup\n",
    "\n",
    "Bagian ini memuat:\n",
    "- Library inti (numpy/pandas) dan tooling (Path/joblib)\n",
    "- Konfigurasi untuk skenario **GLOBAL** (userID hanya untuk grouping & split, bukan fitur)\n",
    "- Utility untuk evaluasi metrik dan tuning threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde02602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# =============================================================================\n",
    "# 0) CONFIG\n",
    "# =============================================================================\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"../datasets/stress_forecast.csv\"),\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"stress_forecast.csv not found. Check CANDIDATE_PATHS / DATA_PATH.\")\n",
    "\n",
    "MODEL_OUT = Path(\"../models/global_forecast.joblib\")\n",
    "\n",
    "DATE_COL   = \"date\"\n",
    "USER_COL   = \"userID\"             # used only for split/grouping (never as features)\n",
    "TARGET_COL = \"stressLevel\"    # 0..2\n",
    "\n",
    "WINDOW   = 3\n",
    "TEST_LEN = 12\n",
    "\n",
    "# CV windows (relative index inside each user's train_pool), end exclusive\n",
    "VAL_WINDOWS = [(12, 24), (18, 30)]\n",
    "\n",
    "# Threshold search for decision rule from probabilities\n",
    "THRESHOLDS = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "# Blend config: p = alpha*p_ml + (1-alpha)*p_markov\n",
    "USE_BLEND = True\n",
    "ALPHAS = np.linspace(0.0, 1.0, 11)\n",
    "\n",
    "RANDOM_STATE = 26\n",
    "\n",
    "# Optional: add behavior lag1 if hour-like numeric columns exist\n",
    "USE_BEHAVIOR_LAG1 = True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Utilities\n",
    "# =============================================================================\n",
    "def eval_bin(y_true, y_pred):\n",
    "    return {\n",
    "        \"acc\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "    }\n",
    "\n",
    "def tune_thr_from_proba(y_true, p_high, thresholds=THRESHOLDS):\n",
    "    best_thr, best_f1 = None, -1.0\n",
    "    for thr in thresholds:\n",
    "        pred = (p_high >= thr).astype(int)\n",
    "        f1 = float(f1_score(y_true, pred, zero_division=0))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = f1, thr\n",
    "    return float(best_thr), float(best_f1)\n",
    "\n",
    "def safe_class_counts(y: np.ndarray):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    return {0: int((y == 0).sum()), 1: int((y == 1).sum())}\n",
    "\n",
    "def pick_existing_behavior_cols(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Detect hour-like numeric columns for optional lag1 behavior features.\n",
    "    This remains no-leak because shift(1) is applied during feature engineering.\n",
    "    \"\"\"\n",
    "    exclude = {DATE_COL, USER_COL, TARGET_COL}\n",
    "    numeric = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    hour_like = [c for c in numeric if (\"hour\" in c.lower()) or (\"hours\" in c.lower())]\n",
    "\n",
    "    known = [\n",
    "        \"studyHourPerDay\",\n",
    "        \"sleepHourPerDay\",\n",
    "        \"socialHourPerDay\",\n",
    "        \"physicalActivityHourPerDay\",\n",
    "        \"extracurricularHourPerDay\",\n",
    "    ]\n",
    "    for c in known:\n",
    "        if c in numeric and c not in hour_like:\n",
    "            hour_like.append(c)\n",
    "\n",
    "    return hour_like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e67a3",
   "metadata": {},
   "source": [
    "# Load and Explore Dataset\n",
    "\n",
    "Tujuan bagian ini:\n",
    "- Load dataset dari `DATA_PATH`\n",
    "- Validasi kolom penting: `date`, `userID`, `stressLevel`\n",
    "- Sort per user berdasarkan waktu\n",
    "- Deteksi `BEHAVIOR_COLS` (opsional) untuk fitur `lag1_*`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aecd1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH     : ..\\datasets\\stress_forecast.csv\n",
      "ROWS          : 300\n",
      "USERS         : 5\n",
      "DATE_RANGE    : 2025-11-21 -> 2026-01-19\n",
      "TARGET_COL    : stressLevel\n",
      "BEHAVIOR_COLS : ['extracurricularHourPerDay', 'physicalActivityHourPerDay', 'sleepHourPerDay', 'studyHourPerDay', 'socialHourPerDay']\n",
      "\n",
      "HEAD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stressLevelID</th>\n",
       "      <th>userID</th>\n",
       "      <th>date</th>\n",
       "      <th>stressLevel</th>\n",
       "      <th>GPA</th>\n",
       "      <th>extracurricularHourPerDay</th>\n",
       "      <th>physicalActivityHourPerDay</th>\n",
       "      <th>sleepHourPerDay</th>\n",
       "      <th>studyHourPerDay</th>\n",
       "      <th>socialHourPerDay</th>\n",
       "      <th>emoji</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-21 21:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-22 20:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-23 22:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-11-24 19:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-11-25 21:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stressLevelID  userID       date  stressLevel   GPA  \\\n",
       "0              2       1 2025-11-21            1  3.82   \n",
       "1              7       1 2025-11-22            0  3.82   \n",
       "2             12       1 2025-11-23            0  3.82   \n",
       "3             17       1 2025-11-24            1  3.82   \n",
       "4             22       1 2025-11-25            1  3.82   \n",
       "\n",
       "   extracurricularHourPerDay  physicalActivityHourPerDay  sleepHourPerDay  \\\n",
       "0                        0.0                         0.5              7.0   \n",
       "1                        0.0                         1.0              9.0   \n",
       "2                        0.0                         3.0              9.0   \n",
       "3                        0.0                         0.5              8.0   \n",
       "4                        0.0                         1.0              7.0   \n",
       "\n",
       "   studyHourPerDay  socialHourPerDay  emoji            createdAt  \n",
       "0              7.0               2.0      1  2025-11-21 21:12:00  \n",
       "1              2.0               5.0      2  2025-11-22 20:07:00  \n",
       "2              1.0               6.0      1  2025-11-23 22:18:00  \n",
       "3              7.0               5.0      3  2025-11-24 19:55:00  \n",
       "4              7.0               4.0      3  2025-11-25 21:40:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "for required_col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if required_col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{required_col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "target_ok = df[TARGET_COL].dropna().between(0, 2).all()\n",
    "if not target_ok:\n",
    "    raise ValueError(f\"'{TARGET_COL}' must be within range 0..2\")\n",
    "\n",
    "BEHAVIOR_COLS = pick_existing_behavior_cols(df) if USE_BEHAVIOR_LAG1 else []\n",
    "\n",
    "print(\"DATA_PATH     :\", str(DATA_PATH))\n",
    "print(\"ROWS          :\", len(df))\n",
    "print(\"USERS         :\", df[USER_COL].nunique())\n",
    "print(\"DATE_RANGE    :\", str(df[DATE_COL].min().date()), \"->\", str(df[DATE_COL].max().date()))\n",
    "print(\"TARGET_COL    :\", TARGET_COL)\n",
    "print(\"BEHAVIOR_COLS :\", BEHAVIOR_COLS)\n",
    "\n",
    "print(\"\\nHEAD:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba4842",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Ringkasan cepat yang relevan:\n",
    "- Distribusi `stressLevel` (0â€“2) sebelum dibinarisasi\n",
    "- Distribusi jumlah data per user untuk memastikan split time-based aman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609053e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_DIST (0..2): {0: 124, 1: 91, 2: 85}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHCCAYAAAAJowgXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMAJJREFUeJzt3Q2cjXX+//HPjDGDYca9ocZNUihRFIOVmIyyYlNWazdqlnZRYVdMGyJFJSyJ2I1sdKNCalNMonJPKbFuMjKbxmgxE5oZzPV/fL7/3zmPc87cmOGYc+Y7r+fjcZk513Wd63zPjbne53t3hTiO4wgAAIClQgNdAAAAgMuJsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wA4jIk08+KSEhISXyWnTu3NksLp9++ql57LfffrtEHn/gwIHSsGFDCWanTp2SP/7xjxITE2Nem+HDhwe6SGWavgf6f6QotmzZIuHh4fL9999LMNi9e7eEhYXJrl27Al0UBBBhB9ZZuHCh+ePsWipUqCD16tWThIQEmTlzpvz8889+eZwjR46YE8BXX30lwSaYy1YUzzzzjHkf//znP8u//vUv+cMf/mD1a+H6zG7btk1Ku7/97W9y3333SYMGDbzW79mzR7p37y6VK1eW6tWrm/f02LFjF/UYubm55jW76667JDY2ViIjI+X666+XSZMmSVZWlte+zZs3lx49esi4ceMu6XmhdAsLdAGAy2XixInSqFEjOXv2rKSlpZkaFK0hmDZtmrz33ntyww03uPd94oknZMyYMcU+iU6YMMHUkrRq1arI9/v444/lciusbPPnzzcni2D2ySefSLt27WT8+PGXfKyLfZ9QfBoo16xZIxs2bPBa/9///lc6deok0dHRJshqzd3UqVPlm2++cdcEFceZM2fkgQceMJ+RP/3pT1K7dm3ZuHGj+bwkJyebz49nTa3uc+edd8p3330njRs35q0tgwg7sNYdd9whbdq0cd9OSkoyfwR//etfm2+E+k2zYsWKZptWc+tyOekf6EqVKhX7D7u/lS9fXoJdenq6+UYeCK73CcW3YMECqV+/vgkhnjTgnD59WrZv3262q1tuuUVuv/12U0MzePDgYj2O/h/64osvpH379u51gwYNMoHWFXji4+Pd2/T3atWqyauvvmq+BKHsoRkLZUqXLl1k7Nixpj/Ba6+9VmifndWrV0vHjh2latWqpur92muvlccff9xs01qim2++2fyu3zBdTWb6h1tpnxytVtc/7vqNVk+ervv69tlxOX/+vNlH+6lotbwGstTUVK999I+59rnx5XnMC5Utvz47eiL6y1/+YpoEIiIizHPVb96O43jtp8cZNmyYLF++3Dw/3fe6666TVatWFTnEJCYmSp06dUzzYsuWLc0JyLf/UkpKinzwwQfush86dKjAY16u9yk7O9ucOK+++mrzPPW1eeyxx8z6oj6+y6xZs8zrpMfXk66G8CVLlkhx/fDDD/Lggw+a18/12r/yyivu7UePHjWhXWuyfO3du9c89xdffNG97uTJk6a20/W+63N99tlnL7rmTz8X+n/M9//SO++8Y75kuIKOK4Bcc8018tZbbxX7cTTseAYdl9/85jfmp36R8Q34+l6vWLGi2I8FO1CzgzJH+wroyUibk/TbYH6+/fZb88dZm7r0m6CeCA4cOGC+TapmzZqZ9doPQL+V/upXvzLrPf8A/+9//zO1S/369ZPf//735gRVmKefftqcJEaPHm1CwYwZM8wJQZsGXDVQRVGUsnnSQKPBau3atSaIaFPPRx99JKNGjTIn1+nTp3vt//nnn8u7774rQ4YMkSpVqph+UH369JHDhw9LjRo1CizXL7/8Yk44+jpqYNImxqVLl5rwpSfdRx991JRd++iMGDFCrrzyShPAVK1atUr0fdKTvb4m+lz1fnocbXLR12Lfvn3mpF6Ux3c1Gz7yyCNyzz33mOeofUq+/vpr2bx5s/zud78r8vuqQUZrTFyBU1+TDz/80LxnmZmZJrRo2W+99VYTIHybAN98800pV66c3Hvvve4aLN1X3+OHHnrIBBFtftIa0B9//NF8/opDj6OfgZtuuinPev08e9ayumjtzr///W/xF22uVjVr1syzrXXr1ibs6GsVFRXlt8dEKeEAllmwYIFWRzhbt24tcJ/o6GjnxhtvdN8eP368uY/L9OnTze1jx44VeAw9vu6jj+fr1ltvNdvmzp2b7zZdXNauXWv2veKKK5zMzEz3+rfeesus//vf/+5e16BBA2fAgAEXPGZhZdP763Fcli9fbvadNGmS13733HOPExIS4hw4cMC9TvcLDw/3Wrdz506zftasWU5hZsyYYfZ77bXX3OtycnKcuLg4p3Llyl7PXcvXo0cP50Iu1/v0r3/9ywkNDXU+++wzr/W6n+7/xRdfFPnxe/Xq5Vx33XWX/JlNTEx06tat6/z0009e6/v162c+z2fOnDG3X375ZXOsb775xmu/5s2bO126dHHffuqpp5zIyEhn3759XvuNGTPGKVeunHP48GH3Oj2e/h8pzJo1a8x+K1euzPf1X7RoUZ77jBo1ymzLyspy/CE+Pt6JiopyTpw4kWfbkiVLzGNt3rzZL4+F0oVmLJRJ2txQ2KgsbZJQ+k3wYqv09Vu+Np0U1f33329qSly0JqBu3bp+/eabHz2+fuPX2gdPWqui5zmtPfCktU2enTy1VkO/KR88ePCCj6NNdDpSx7N5QR9XO6yuW7eu2GW/XO+T1jhpbU7Tpk3lp59+ci/aRKO0Fqyoj6/7aAfdrVu3ysXS90Gbgnr27Gl+9yyTjjLMyMiQHTt2mH3vvvtu05SlNTkuOuxah2D/9re/9XqOWtOlzWqex9P3V5tU169fX6wyag2Z0uP51ui5Xmdf2pTpuc+l0H5B2jl6ypQp7vfFk6tc+hxR9hB2UCbpydUzWPjSk0KHDh3MXC/aNKBNHNo0UJwT6hVXXFGszshNmjTxuq3NFdqHorD+Kv6g/Zd0aL7v66Ene9d2T579LjxPJCdOnLjg4+hzDA0NLdLjFMXlep/2799vmqi0qchz0T4mSptlivr42iyp4VqbbPT5Dx061KuZqyh0iLY29c2bNy9PmVxBzVUmbcLp2rWrV18YDT4agDQIeT5H7WvlezxXx17X8YrLt5+XqwnWt6+Tcg0TL04zbX70+emISm3S0+kKCitXSc2nheBCnx2UOfotW78Ja5AoiP7x1W+2+g1eO8rqSUH/oOo3e+3rozUhF3Kpf8DzU9Afav0mXpQy+UNBj+N7kisJl+t90rDSokULM01BfrRDb1EfX8Ocdg5+//33zXatoXnppZdMP6L8OhLnxxWetE/RgAED8t3HcyoFDV0agrS/l/bB0uCjAcizL4seU0dDaafr/LiCXVG5+mv5hl6tnVTaD8iXrtM5d/Kr9Skq7SCutaI6l87cuXML3M9Vrvz688B+hB2UOdoBVmn1f2G0BkJPELroSU+ryXXCND2x6bdff39D1G/avuFBO7t6nsS0BkW/4fvSWpGrrrrKfbs4ZdPJ37T6X5v1PGt3/vOf/7i3+4MeRzvm6knWs3bnUh/ncrxP2ky3c+dOc8wL3f9Cj690dJ3WAumSk5Njali0Q7p2BnY15RRGa1z0vdFQ6zmkuiC9e/c2nY5dTVnaqVofy/c5ag1nUY5XFNrkp3QknW/NmZY/vwkTdY6dS5n7SDt56wgs7fysga6w6SO0XPpeFTfEwQ40Y6FM0Xl2nnrqKTMSqH///gXud/z48TzrXH+UXdXxegJT+YWPi7Fo0SKvfkR6+Qj95qsjhTxPUJs2bTInTBetMfAdol6csulka3oS9RySrHTkkZ7oPR//Uujj6GgZz74k586dM8OytZlHRwYV1+V6n/r27WtGEelIKl/av0SH6hf18V19WVy0yUznENIwqxNeFoXWEOmIN60Vyu+yB74zEWufFQ3zGgDeeOMN85gagHyfo07EpyPvfOlrpe9NcWio0Rqv/EKNlt33c6pz4WgIc40OU/p6aPj1rQXSyQB18aTDy7U2R6dR0GNfqCZVpxfQofo6sSHKHmp2YC3tWKt/OPWPtg7b1aCjVd5ag6AzKBf2jVqHEWvzhP4x1f21/4I2PehwaJ1TxRU89KSiVef6rVtPqm3btjVB6mJodb4eW5sftLw69Feb2jyHx2vfEA1BOu2+nqz0BKDzBfnOClucsmmn19tuu83URmj/IJ37RptgtNOtDmf214yzOoT75ZdfNkPN9cSjJyl9Ltp/RZ9rYX2oSvp90ukJNCjozLtaQ6P9cjQQ6udJ12tA0NqEojx+t27dTMdsPYb269GTtAZLvY/vc9Y5c/Kbs0iHrGvHWy2Lll0/ExqYNGxpx2StmfMNXlqLpM1eWh4NPr6ddnVqAf1/oEPn9T3Rodka4nSIvb4v+lkobpNPr169ZNmyZSbIedaI6VQP2iFaP2f6XLRG6fnnnzdNhZ6dwzVgarOfNtW55kJSWmumXP3X9EuBPidtmtLnoU2InvQ9j4uL8wpR2gFep0tAGRXo4WCAv7mG8boWHSodExPj3H777WYYt+cQ54KGnicnJ5shw/Xq1TP315/33XdfnmG6K1asMEN6w8LCvIY365DmgoYbFzT0/PXXX3eSkpKc2rVrOxUrVjRDr7///vs893/hhRfMMPWIiAinQ4cOzrZt2/Ics7Cy+Q49Vz///LMzYsQI8zzLly/vNGnSxHn++eed3Nxcr/30OEOHDs1TpoKGxPs6evSo88ADDzg1a9Y0r2uLFi3yHRJe1KHnl/N90mHxzz77rNmur3W1atWc1q1bOxMmTHAyMjKK/Pg6FLxTp05OjRo1zHEaN25shly7jpHfZ9Z3SU1Ndb9++vrHxsaa90k/1127dnXmzZuXp/z6OdfPke9wf9/3XT9zV199tSm/vi/t27d3pk6dap5/cYaeqx07dph9fYfsq127djndunVzKlWq5FStWtXp37+/k5aW5rVPSkqKub/vZ0k/D56fWdd+BS2+9//www/N+v3791/wOcBOIfpPoAMXAMAOWgujo/tcfeOCgTbhaU2T1jqhbCLsAAD8RjsN6/w92uHeX53bL4U2G2pzmY5M00uDoGwi7AAAAKsxGgsAAFiNsAMAAKxG2AEAAFYj7AAAAKsxqeD/XSPmyJEjZoIvLhIHAEDpoLPn6CSTOt2B70WGPRF2REzQcV3YDwAAlC56KRKdubwghB0R95Tt+mJFRUWV3LsDAAAuWmZmpqmsuNDlZgg7HleI1qBD2AEAoHS5UBcUOigDAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArBYW6AKg6BqO+YCXy08OTenBawkAZQQ1OwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAVgto2Fm/fr307NlT6tWrJyEhIbJ8+XL3trNnz8ro0aOlRYsWEhkZafa5//775ciRI17HOH78uPTv31+ioqKkatWqkpiYKKdOnQrAswEAAMEooGHn9OnT0rJlS5k9e3aebWfOnJEdO3bI2LFjzc93331X9u7dK3fddZfXfhp0vv32W1m9erW8//77JkANHjy4BJ8FAAAIZiGO4zgSBLRmZ9myZdK7d+8C99m6davccsst8v3330v9+vVlz5490rx5c7O+TZs2Zp9Vq1bJnXfeKf/9739NbVBRZGZmSnR0tGRkZJgaomDFpIL+w6SCAFD6FfX8Xar67OiT0VCkzVVq48aN5ndX0FHx8fESGhoqmzdvLvA42dnZ5gXyXAAAgJ1KTdjJysoyfXjuu+8+d3pLS0uT2rVre+0XFhYm1atXN9sKMnnyZJMEXUtsbOxlLz8AAAiMUhF2tLNy3759RVvc5syZc8nHS0pKMrVEriU1NdUv5QQAAMEnrLQEHe2n88knn3i1ycXExEh6errX/ufOnTMjtHRbQSIiIswCAADsF1oags7+/ftlzZo1UqNGDa/tcXFxcvLkSdm+fbt7nQai3Nxcadu2bQBKDAAAgk1Aa3Z0PpwDBw64b6ekpMhXX31l+tzUrVtX7rnnHjPsXIeUnz9/3t0PR7eHh4dLs2bNpHv37jJo0CCZO3euCUfDhg2Tfv36FXkkFgAAsFtAw862bdvktttuc98eOXKk+TlgwAB58skn5b333jO3W7Vq5XW/tWvXSufOnc3vixcvNgGna9euZhRWnz59ZObMmSX6PAAAQPAKaNjRwFLYND9FmQJIa3mWLFni55IBAABbBHWfHQAAgEtF2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGC1gIad9evXS8+ePaVevXoSEhIiy5cv99ruOI6MGzdO6tatKxUrVpT4+HjZv3+/1z7Hjx+X/v37S1RUlFStWlUSExPl1KlTJfxMAABAsApo2Dl9+rS0bNlSZs+ene/25557TmbOnClz586VzZs3S2RkpCQkJEhWVpZ7Hw063377raxevVref/99E6AGDx5cgs8CAAAEs7BAPvgdd9xhlvxorc6MGTPkiSeekF69epl1ixYtkjp16pgaoH79+smePXtk1apVsnXrVmnTpo3ZZ9asWXLnnXfK1KlTTY0RAAAo24K2z05KSoqkpaWZpiuX6Ohoadu2rWzcuNHc1p/adOUKOkr3Dw0NNTVBBcnOzpbMzEyvBQAA2Clow44GHaU1OZ70tmub/qxdu7bX9rCwMKlevbp7n/xMnjzZBCfXEhsbe1meAwAACLygDTuXU1JSkmRkZLiX1NTUQBcJAACUtbATExNjfh49etRrvd52bdOf6enpXtvPnTtnRmi59slPRESEGb3luQAAADsFbdhp1KiRCSzJycnuddq3RvvixMXFmdv68+TJk7J9+3b3Pp988onk5uaavj0AAAABHY2l8+EcOHDAq1PyV199Zfrc1K9fX4YPHy6TJk2SJk2amPAzduxYM8Kqd+/eZv9mzZpJ9+7dZdCgQWZ4+tmzZ2XYsGFmpBYjsQAAQMDDzrZt2+S2225z3x45cqT5OWDAAFm4cKE89thjZi4enTdHa3A6duxohppXqFDBfZ/FixebgNO1a1czCqtPnz5mbh4AAAAV4uiENmWcNo/pqCztrBzM/Xcajvkg0EWwxqEpPQJdBABACZ2/g7bPDgAAgD8QdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqYYEuAIDSq+GYDwJdBGscmtIj0EUArEXNDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGC1sEAXAAAAf2o45gNeUD84NKWHNa8jNTsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNWCOuycP39exo4dK40aNZKKFStK48aN5amnnhLHcdz76O/jxo2TunXrmn3i4+Nl//79AS03AAAIHkEddp599lmZM2eOvPjii7Jnzx5z+7nnnpNZs2a599HbM2fOlLlz58rmzZslMjJSEhISJCsrK6BlBwAAwSGoLxexYcMG6dWrl/To8f+nrG7YsKG8/vrrsmXLFnetzowZM+SJJ54w+6lFixZJnTp1ZPny5dKvX7+Alh8AAAReUNfstG/fXpKTk2Xfvn3m9s6dO+Xzzz+XO+64w9xOSUmRtLQ003TlEh0dLW3btpWNGzcGrNwAACB4BHXNzpgxYyQzM1OaNm0q5cqVM314nn76aenfv7/ZrkFHaU2OJ73t2paf7Oxss7joYwAAADsFdc3OW2+9JYsXL5YlS5bIjh075NVXX5WpU6ean5di8uTJpgbItcTGxvqtzAAAILgEddgZNWqUqd3RvjctWrSQP/zhDzJixAgTVlRMTIz5efToUa/76W3XtvwkJSVJRkaGe0lNTb3MzwQAAARKUIedM2fOSGiodxG1OSs3N9f8rkPSNdRovx7PJikdlRUXF1fgcSMiIiQqKsprAQAAdgrqPjs9e/Y0fXTq168v1113nXz55Zcybdo0efDBB832kJAQGT58uEyaNEmaNGliwo/Oy1OvXj3p3bt3oIsPAACCQFCHHZ1PR8PLkCFDJD093YSYhx56yEwi6PLYY4/J6dOnZfDgwXLy5Enp2LGjrFq1SipUqBDQsgMAgOAQ1GGnSpUqZh4dXQqitTsTJ040CwAAQKnqswMAAHCpCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgtYsKO126dJGTJ0/mWZ+ZmWm2AQAAlOqw8+mnn0pOTk6e9VlZWfLZZ5/5o1wAAAB+EVacnb/++mv377t375a0tDT37fPnz8uqVavkiiuu8E/JAAAASjrstGrVSkJCQsySX3NVxYoVZdasWf4oFwAAQMmHnZSUFHEcR6666irZsmWL1KpVy70tPDxcateuLeXKlfNPyQAAAEo67DRo0MD8zM3N9cdjAwAABFfY8bR//35Zu3atpKen5wk/48aN80fZAAAAAhN25s+fL3/+85+lZs2aEhMTY/rwuOjvhB0AAFCqw86kSZPk6aefltGjR/u/RAAAAIGeZ+fEiRNy7733+rMcAAAAwRN2NOh8/PHH/i8NAABAMDRjXX311TJ27FjZtGmTtGjRQsqXL++1/ZFHHvFX+QAAAEo+7MybN08qV64s69atM4sn7aBM2AEAAKU67OjkggAAANb22QEAACgtLqpm58EHHyx0+yuvvHKx5QEAAAh82NGh557Onj0ru3btkpMnT+Z7gVAAAIBSFXaWLVuWZ51eMkJnVW7cuLE/ygUAABBcfXZCQ0Nl5MiRMn36dH8dEgAAILg6KH/33Xdy7tw5fx4SAACg5JuxtAbHk+M48uOPP8oHH3wgAwYMuLQSAQAABDrsfPnll3masGrVqiUvvPDCBUdqAQAABH3YWbt2rf9LAgAAECxhx+XYsWOyd+9e8/u1115rancAAABKfQfl06dPm+aqunXrSqdOncxSr149SUxMlDNnzvi/lAAAACUZdrSDsl4AdOXKlWYiQV1WrFhh1v3lL3+52LIAAAAERzPWO++8I2+//bZ07tzZve7OO++UihUrSt++fWXOnDn+LCMAAEDJ1uxoU1WdOnXyrK9du7bfm7F++OEH+f3vfy81atQwYapFixaybds2r2Hv48aNM01quj0+Pl7279/v1zIAAIAyFnbi4uJk/PjxkpWV5V73yy+/yIQJE8w2f9FrcHXo0EHKly8vH374oezevdsMb69WrZp7n+eee05mzpwpc+fOlc2bN0tkZKQkJCR4lQ0AAJRdF9WMNWPGDOnevbtceeWV0rJlS7Nu586dEhERIR9//LHfCvfss89KbGysLFiwwL2uUaNGXrU6WpYnnnhCevXqZdYtWrTI1DotX75c+vXr57eyAACAMlSzo01J2lQ0efJkadWqlVmmTJkiBw4ckOuuu85vhXvvvfekTZs2cu+995omshtvvFHmz5/v3p6SkiJpaWmm6colOjpa2rZtKxs3bvRbOQAAQBmr2dGQo7UngwYN8lr/yiuvmLl3Ro8e7ZfCHTx40HR21tFfjz/+uGzdulUeeeQRCQ8PN5el0KCjfPsP6W3XtvxkZ2ebxSUzM9Mv5QUAAJbU7Lz88svStGnTPOu1Vkf7zvhLbm6u3HTTTfLMM8+YWp3BgwebgHWpj6FhTWuAXIs2lQEAADtdVNjRWhMd/eRLZ1DWC4L6iz5G8+bNvdY1a9ZMDh8+bH6PiYkxP48ePeq1j952bctPUlKSZGRkuJfU1FS/lRkAAFgQdrQm5IsvvsizXtfpTMr+oiOxXJejcNm3b580aNDA3VlZQ01ycrJXk5SOyipsVJh2pI6KivJaAACAnS6qz442JQ0fPlzOnj0rXbp0Mes0cDz22GN+nUF5xIgR0r59e9OMpZMVbtmyRebNm2cWFRISYsoxadIkadKkiQk/Y8eONYGrd+/efisHAAAoY2Fn1KhR8r///U+GDBkiOTk5Zl2FChVMx2RtIvKXm2++WZYtW2aOOXHiRBNmdKh5//793ftowNJrdWl/Hr1sRceOHWXVqlWmPAAAACGOTlZzkU6dOiV79uwxMxdrzYo2D5VG2vSlHZW1/04wN2k1HPNBoItgjUNTegS6CFbgM+k/fCb9h89l2flMZhbx/H1RNTsulStXNrUvAAAAVnVQBgAAKC0IOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFitVIWdKVOmSEhIiAwfPty9LisrS4YOHSo1atSQypUrS58+feTo0aMBLScAAAgepSbsbN26VV5++WW54YYbvNaPGDFCVq5cKUuXLpV169bJkSNH5O677w5YOQEAQHApFWHn1KlT0r9/f5k/f75Uq1bNvT4jI0P++c9/yrRp06RLly7SunVrWbBggWzYsEE2bdoU0DIDAIDgUCrCjjZT9ejRQ+Lj473Wb9++Xc6ePeu1vmnTplK/fn3ZuHFjgcfLzs6WzMxMrwUAANgpTILcG2+8ITt27DDNWL7S0tIkPDxcqlat6rW+Tp06ZltBJk+eLBMmTLgs5QUAAMElqGt2UlNT5dFHH5XFixdLhQoV/HbcpKQk0wTmWvRxAACAnYI67GgzVXp6utx0000SFhZmFu2EPHPmTPO71uDk5OTIyZMnve6no7FiYmIKPG5ERIRERUV5LQAAwE5B3YzVtWtX+eabb7zWPfDAA6ZfzujRoyU2NlbKly8vycnJZsi52rt3rxw+fFji4uICVGoAABBMgjrsVKlSRa6//nqvdZGRkWZOHdf6xMREGTlypFSvXt3U0Dz88MMm6LRr1y5ApQYAAMEkqMNOUUyfPl1CQ0NNzY6OskpISJCXXnop0MUCAABBotSFnU8//dTrtnZcnj17tlkAAABKVQdlAACAS0XYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYLWgDjuTJ0+Wm2++WapUqSK1a9eW3r17y969e732ycrKkqFDh0qNGjWkcuXK0qdPHzl69GjAygwAAIJLUIeddevWmSCzadMmWb16tZw9e1a6desmp0+fdu8zYsQIWblypSxdutTsf+TIEbn77rsDWm4AABA8wiSIrVq1yuv2woULTQ3P9u3bpVOnTpKRkSH//Oc/ZcmSJdKlSxezz4IFC6RZs2YmILVr1y5AJQcAAMEiqGt2fGm4UdWrVzc/NfRobU98fLx7n6ZNm0r9+vVl48aNBR4nOztbMjMzvRYAAGCnUhN2cnNzZfjw4dKhQwe5/vrrzbq0tDQJDw+XqlWreu1bp04ds62wvkDR0dHuJTY29rKXHwAABEapCTvad2fXrl3yxhtvXPKxkpKSTC2Ra0lNTfVLGQEAQPAJ6j47LsOGDZP3339f1q9fL1deeaV7fUxMjOTk5MjJkye9and0NJZuK0hERIRZAACA/YK6ZsdxHBN0li1bJp988ok0atTIa3vr1q2lfPnykpyc7F6nQ9MPHz4scXFxASgxAAAINmHB3nSlI61WrFhh5tpx9cPRfjYVK1Y0PxMTE2XkyJGm03JUVJQ8/PDDJugwEgsAAAR92JkzZ4752blzZ6/1Orx84MCB5vfp06dLaGiomUxQR1klJCTISy+9FJDyAgCA4BMW7M1YF1KhQgWZPXu2WQAAAEpVnx0AAIBLRdgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAataEndmzZ0vDhg2lQoUK0rZtW9myZUugiwQAAIKAFWHnzTfflJEjR8r48eNlx44d0rJlS0lISJD09PRAFw0AAASYFWFn2rRpMmjQIHnggQekefPmMnfuXKlUqZK88sorgS4aAAAIsFIfdnJycmT79u0SHx/vXhcaGmpub9y4MaBlAwAAgRcmpdxPP/0k58+flzp16nit19v/+c9/8r1Pdna2WVwyMjLMz8zMTAlmudlnAl0EawT7e11a8Jn0Hz6T/sPnsux8JjP/r4yO49gddi7G5MmTZcKECXnWx8bGBqQ8KHnRM3jVEVz4TCLYRJeiv5M///yzREdH2xt2atasKeXKlZOjR496rdfbMTEx+d4nKSnJdGh2yc3NlePHj0uNGjUkJCTkspfZVpqwNTCmpqZKVFRUoIsDGHwuEWz4TPqP1uho0KlXr16h+5X6sBMeHi6tW7eW5ORk6d27tzu86O1hw4ble5+IiAizeKpatWqJlLcs0KBD2EGw4XOJYMNn0j8Kq9GxJuworaUZMGCAtGnTRm655RaZMWOGnD592ozOAgAAZZsVYee3v/2tHDt2TMaNGydpaWnSqlUrWbVqVZ5OywAAoOyxIuwobbIqqNkKJUObBnViR98mQiCQ+Fwi2PCZLHkhzoXGawEAAJRipX5SQQAAgMIQdgAAgNUIOwAAwGqEHQAAYDVrRmMhMNcl0yvL6wVXdci/0lmr27dvLwMHDpRatWrxtgAAAo7RWLgoW7dulYSEBKlUqZK5wrxrTiO9TIfOXn3mzBn56KOPzESPAFCW/fLLL7J9+3apXr26NG/e3GtbVlaWvPXWW3L//fcHrHxlAWEHF6Vdu3bSsmVLmTt3bp7rielsBn/605/k66+/NrU+QLDQ67bpXFBaIwmUhH379km3bt3k8OHD5m9lx44d5Y033pC6deu6vyDqdZ3Onz/PG3IZ0WcHF2Xnzp0yYsSIfC+cqut021dffcWri6CiF/x99dVXA10MlCGjR4+W66+/XtLT02Xv3r1SpUoV6dChgwk/KDn02cFF0b45W7ZskaZNm+a7XbdxuQ6UtPfee6/Q7QcPHiyxsgBqw4YNsmbNGqlZs6ZZVq5cKUOGDJFf/epXsnbtWomMjOSFKgGEHVyUv/71rzJ48GDTDt21a9c8fXbmz58vU6dO5dVFierdu7epWSxsYvj8aiOBy9lfJywszOvzN2fOHHN5o1tvvVWWLFnCi18CCDu4KEOHDjXfUqZPny4vvfSSu725XLly0rp1a1m4cKH07duXVxclSvtB6OexV69e+W7XplX9fAIlRWu/t23bJs2aNfNa/+KLL5qfd911F29GCaDPDi7pavObNm0yI69++OEHs+jvuo6gg0DQIKO1jQW5UK0P4G+/+c1v5PXXX893mwae++67j89kCWA0FgBrfPbZZ3L69Gnp3r17vtt1m37L1uYDAGUHYQcAAFiNZiwAAGA1wg4AALAaYQcAAFiNsAMAJejQoUNmVBgzjAMlh7ADoEQMHDjQTPoXaJ07d5bhw4cHuhgAShBhB0BQOXv2bKCLAMAyhB0AfvX2229LixYtpGLFilKjRg2Jj4+XUaNGmQtwrlixwjTh6PLpp5+6m3TefPNNM/dNhQoVZPHixeY4//jHP8yss7pOZ6HVmZFdcnJyzHT7OmOybm/QoIFMnjzZbNNJA5988kmpX7++REREmCtKP/LII0Uu/+eff26uW6Tlj42NNffV+XnU448/Lm3bts1zn5YtW8rEiRPdtwsrO4AAcADAT44cOeKEhYU506ZNc1JSUpyvv/7amT17tvPzzz87ffv2dbp37+78+OOPZsnOzjb76J+hhg0bOu+8845z8OBBc4zXXnvNqVu3rnud/qxevbqzcOFC8zjPP/+8Exsb66xfv945dOiQ89lnnzlLliwx25YuXepERUU5//73v53vv//e2bx5szNv3jx3GW+99Vbn0Ucfzbf8Bw4ccCIjI53p06c7+/btc7744gvnxhtvdAYOHGi279q1y5RX93Nxrdu/f7+5faGyu57zl19+yecOKCGEHQB+s337dnMi1wDia8CAAU6vXr281rlO/DNmzPBa37hxY3d4cXnqqaecuLg48/vDDz/sdOnSxcnNzc3zOC+88IJzzTXXODk5OfmWsbCwk5iY6AwePNhrnQap0NBQ55dffjG3W7Zs6UycONG9PSkpyWnbtm2Ry07YAUoezVgA/Eabc7p27Wqase69916ZP3++nDhx4oL3a9Omjft3bTL67rvvJDExUSpXruxeJk2aZNa7OjvraKZrr73WNDN9/PHH7vvr4+qVpq+66ioZNGiQLFu2TM6dO1ek8u/cudNcxNbzcRMSEiQ3N1dSUlLMPv3793dfqVq/MOp1j3RdUcsOoORx1XMAfqNXvV+9erVs2LDBBJBZs2bJ3/72N9m8eXOh94uMjHT/furUKfNTg5Jv/xg9vrrppptM+Pjwww9lzZo15sKz2jdI+wtpP5u9e/ea9VqWIUOGyPPPPy/r1q2T8uXLF1oOfeyHHnoo3z4+2gdI6YUbR48eLTt27DChKjU11VwUt6hlB1DyCDsA/Eo7HHfo0MEs48aNM52HtXYlPDxczp8/f8H716lTx3QqPnjwoLvGJD9RUVEmZOhyzz33mIt/Hj9+XKpXr246F/fs2dMsQ4cONZ2Ev/nmGxOSCqPbd+/eLVdffXWB+1x55ZWmM7V2pNawc/vtt0vt2rWLVXYAJYuwA8BvtAYnOTlZunXrZgKA3j527JgZmZSVlSUfffSRqXXRUVrR0dEFHmfChAmmdkX30RCTnZ1trlauTWIjR46UadOmmZFYN954o4SGhsrSpUslJiZGqlatapqhNFRpzUqlSpXktddeM+FHQ5eLlsl3Uj89ntbYtGvXzoz0+uMf/2hqnDT8aA3Riy++6N5Xg8z48ePNqLDp06cXq+wAAiAA/YQAWGr37t1OQkKCU6tWLSciIsJ0FJ41a5bZlp6e7tx+++1O5cqVTafktWvXFtpZd/HixU6rVq2c8PBwp1q1ak6nTp2cd99912zT0VW6TUdO6cirrl27Ojt27DDbli1bZjoM63rd3q5dO2fNmjVeHZT1MX0X7USstmzZ4i6n3v+GG25wnn76aa+ynThxwjy/SpUqmZFmxSk7HZSBkhei/wQiZAEAAJQERmMBAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAIDb7f+CXH5gyev3OAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROWS_PER_USER: {1: 60, 2: 60, 3: 60, 4: 60, 5: 60}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EDA QUICK CHECKS\n",
    "target_counts = df[TARGET_COL].value_counts().sort_index()\n",
    "print(\"TARGET_DIST (0..2):\", target_counts.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "target_counts.plot(kind=\"bar\")\n",
    "plt.title(f\"Distribution of {TARGET_COL} (0..2)\")\n",
    "plt.xlabel(TARGET_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "user_counts = df[USER_COL].value_counts()\n",
    "print(\"\\nROWS_PER_USER:\", user_counts.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "user_counts.sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Rows per user\")\n",
    "plt.xlabel(USER_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b6269",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Tahap ini melakukan **feature engineering tanpa leakage**:\n",
    "- Fitur kalender: `dow`, `is_weekend`\n",
    "- Fitur lag target: `lag_sp_1..lag_sp_WINDOW`\n",
    "- Rolling stats dari history yang berakhir di `t-1`\n",
    "- (Opsional) `lag1_<behavior_col>` dari `t-1`\n",
    "\n",
    "Transformasi label:\n",
    "- `y_bin = 1` jika `stressLevel >= 1`\n",
    "- `y_bin = 0` jika `stressLevel == 0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d5d676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_FEAT      : 285\n",
      "USERS_FEAT     : 5\n",
      "FEATURES_COUNT : 18\n",
      "BINARY_DIST    : {1: 171, 0: 114}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>date</th>\n",
       "      <th>stressLevel</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_sp_1</th>\n",
       "      <th>lag_sp_2</th>\n",
       "      <th>lag_sp_3</th>\n",
       "      <th>sp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>sp_max</th>\n",
       "      <th>count_high</th>\n",
       "      <th>count_low</th>\n",
       "      <th>streak_high</th>\n",
       "      <th>transitions</th>\n",
       "      <th>lag1_extracurricularHourPerDay</th>\n",
       "      <th>lag1_physicalActivityHourPerDay</th>\n",
       "      <th>lag1_sleepHourPerDay</th>\n",
       "      <th>lag1_studyHourPerDay</th>\n",
       "      <th>lag1_socialHourPerDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID       date  stressLevel  y_bin  dow  is_weekend  lag_sp_1  lag_sp_2  \\\n",
       "0       1 2025-11-24            1      1    0           0       0.0       0.0   \n",
       "1       1 2025-11-25            1      1    1           0       1.0       0.0   \n",
       "2       1 2025-11-26            1      1    2           0       1.0       1.0   \n",
       "3       1 2025-11-27            1      1    3           0       1.0       1.0   \n",
       "4       1 2025-11-28            1      1    4           0       1.0       1.0   \n",
       "\n",
       "   lag_sp_3   sp_mean  ...  sp_max  count_high  count_low  streak_high  \\\n",
       "0       1.0  0.333333  ...     1.0         1.0        2.0            0   \n",
       "1       0.0  0.333333  ...     1.0         1.0        2.0            1   \n",
       "2       0.0  0.666667  ...     1.0         2.0        1.0            2   \n",
       "3       1.0  1.000000  ...     1.0         3.0        0.0            3   \n",
       "4       1.0  1.000000  ...     1.0         3.0        0.0            4   \n",
       "\n",
       "   transitions  lag1_extracurricularHourPerDay  \\\n",
       "0          2.0                             0.0   \n",
       "1          2.0                             0.0   \n",
       "2          1.0                             0.0   \n",
       "3          1.0                             0.0   \n",
       "4          0.0                             0.0   \n",
       "\n",
       "   lag1_physicalActivityHourPerDay  lag1_sleepHourPerDay  \\\n",
       "0                              3.0                   9.0   \n",
       "1                              0.5                   8.0   \n",
       "2                              1.0                   7.0   \n",
       "3                              0.5                   7.0   \n",
       "4                              5.0                   6.0   \n",
       "\n",
       "   lag1_studyHourPerDay  lag1_socialHourPerDay  \n",
       "0                   1.0                    6.0  \n",
       "1                   7.0                    5.0  \n",
       "2                   7.0                    4.0  \n",
       "3                   8.0                    3.0  \n",
       "4                   6.0                    7.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FEATURE ENGINEERING\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    # Calendar features\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)  # 0..6\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    # Target lag features (t-1..t-W)\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "    # Behavior lag1 (t-1)\n",
    "    if len(BEHAVIOR_COLS) > 0:\n",
    "        for c in BEHAVIOR_COLS:\n",
    "            g[f\"lag1_{c}\"] = g[c].shift(1)\n",
    "\n",
    "    # Rolling stats from history ending at t-1\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    # High streak (<= t-1)\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    # Transitions in history (<= t-1)\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# Binary labeling: y_bin = 1 if pred>=1 else 0\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "# GLOBAL: never include USER_COL as a feature\n",
    "feature_cols = (\n",
    "    [\"dow\", \"is_weekend\"]\n",
    "    + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "    + [\n",
    "        \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "        \"count_high\", \"count_low\",\n",
    "        \"streak_high\", \"transitions\",\n",
    "    ]\n",
    ")\n",
    "if len(BEHAVIOR_COLS) > 0:\n",
    "    feature_cols += [f\"lag1_{c}\" for c in BEHAVIOR_COLS]\n",
    "\n",
    "# Drop rows without full history\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"ROWS_FEAT      :\", len(feat))\n",
    "print(\"USERS_FEAT     :\", feat[USER_COL].nunique())\n",
    "print(\"FEATURES_COUNT :\", len(feature_cols))\n",
    "print(\"BINARY_DIST    :\", feat[\"y_bin\"].value_counts().to_dict())\n",
    "\n",
    "display(feat[[USER_COL, DATE_COL, TARGET_COL, \"y_bin\"] + feature_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658b389",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "Cakupan:\n",
    "1. Split time-based per user: `TEST = last TEST_LEN` per user  \n",
    "2. Baseline L1 (Persistence): `y(t) = y(t-1)`  \n",
    "3. Baseline L2 (Markov GLOBAL): `P(y_t | prev_high, dow)` + tuning threshold via pooled CV  \n",
    "4. Model candidates (GLOBAL, tanpa userID) + fair pooled CV + threshold tuning  \n",
    "5. (Opsional) BLEND: `p = alpha*p_ml + (1-alpha)*p_markov`  \n",
    "6. Leaderboard + simpan artifact model terbaik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a697ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINPOOL_ROWS : 225\n",
      "TEST_ROWS      : 60\n",
      "TEST_DIST      : {1: 49, 0: 11}\n",
      "CV_FOLDS     : 2\n",
      "VAL_WINDOWS  : [(12, 24), (18, 30)]\n"
     ]
    }
   ],
   "source": [
    "# SPLIT (TIME-BASED PER USER)\n",
    "train_idx, test_idx = [], []\n",
    "per_user_train_pool = {}\n",
    "\n",
    "for uid, g in feat.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index()  # keeps original feat index in 'index'\n",
    "    n = len(g)\n",
    "    test_start = n - TEST_LEN\n",
    "    if test_start <= 20:\n",
    "        raise ValueError(f\"User {uid} has too few rows for split+CV. n={n}, TEST_LEN={TEST_LEN}\")\n",
    "\n",
    "    train_pool = g.iloc[:test_start]\n",
    "    test_block = g.iloc[test_start:]\n",
    "\n",
    "    per_user_train_pool[uid] = train_pool\n",
    "    train_idx += train_pool[\"index\"].tolist()\n",
    "    test_idx  += test_block[\"index\"].tolist()\n",
    "\n",
    "train_pool_df = feat.loc[train_idx].copy()\n",
    "test_df = feat.loc[test_idx].copy()\n",
    "\n",
    "print(\"TRAINPOOL_ROWS :\", len(train_pool_df))\n",
    "print(\"TEST_ROWS      :\", len(test_df))\n",
    "print(\"TEST_DIST      :\", test_df[\"y_bin\"].value_counts().to_dict())\n",
    "\n",
    "# Build pooled CV splits from windows inside each user's train_pool\n",
    "cv_splits = []\n",
    "for (v0, v1) in VAL_WINDOWS:\n",
    "    tr_idx, va_idx = [], []\n",
    "    ok = True\n",
    "    for uid, tp in per_user_train_pool.items():\n",
    "        tp = tp.reset_index(drop=True)\n",
    "        if len(tp) < v1:\n",
    "            ok = False\n",
    "            break\n",
    "        va = tp.iloc[v0:v1]\n",
    "        tr = tp.iloc[:v0]\n",
    "        tr_idx += tr[\"index\"].tolist()\n",
    "        va_idx += va[\"index\"].tolist()\n",
    "    if ok:\n",
    "        cv_splits.append((tr_idx, va_idx))\n",
    "\n",
    "if len(cv_splits) == 0:\n",
    "    raise ValueError(\"CV windows cannot be formed. Reduce TEST_LEN or adjust VAL_WINDOWS.\")\n",
    "\n",
    "print(\"CV_FOLDS     :\", len(cv_splits))\n",
    "print(\"VAL_WINDOWS  :\", VAL_WINDOWS)\n",
    "\n",
    "X_trainpool = train_pool_df[feature_cols].copy()\n",
    "y_trainpool = train_pool_df[\"y_bin\"].astype(int).values\n",
    "\n",
    "X_test = test_df[feature_cols].copy()\n",
    "y_test = test_df[\"y_bin\"].astype(int).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b58017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_ACC : 0.8\n",
      "TEST_F1  : 0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L1: PERSISTENCE (y(t)=y(t-1))\n",
    "pred_persist = (test_df[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "persist_metrics = eval_bin(y_test, pred_persist)\n",
    "\n",
    "print(\"TEST_ACC :\", persist_metrics[\"acc\"])\n",
    "print(\"TEST_F1  :\", persist_metrics[\"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e59411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_POOLED_DIST  : {0: 34, 1: 86}\n",
      "BEST_THR_MARKOV : 0.35\n",
      "CV_POOLED_F1    : 0.8522727272727273\n",
      "TEST_ACC_MARKOV : 0.85\n",
      "TEST_F1_MARKOV  : 0.9108910891089109\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L2: MARKOV GLOBAL (prev_high, dow) + THR TUNING (POOLED CV)\n",
    "def train_markov_global(df_train):\n",
    "    # counts: prev(2) x dow(7) x y(2)\n",
    "    counts = np.zeros((2, 7, 2), dtype=int)\n",
    "    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_train[\"dow\"].astype(int).values\n",
    "    yb   = df_train[\"y_bin\"].astype(int).values\n",
    "    for p, d, y in zip(prev, dow, yb):\n",
    "        counts[p, d, y] += 1\n",
    "    # Laplace smoothing\n",
    "    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)\n",
    "    return probs\n",
    "\n",
    "def markov_proba(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_eval[\"dow\"].astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "# Threshold tuning on pooled CV (no leakage)\n",
    "cv_true, cv_phigh = [], []\n",
    "for _, (tr_idx, va_idx) in enumerate(cv_splits, start=1):\n",
    "    tr_df = feat.loc[tr_idx]\n",
    "    va_df = feat.loc[va_idx]\n",
    "    probs = train_markov_global(tr_df)\n",
    "    p = markov_proba(probs, va_df)\n",
    "    cv_true.append(va_df[\"y_bin\"].astype(int).values)\n",
    "    cv_phigh.append(p)\n",
    "\n",
    "cv_true = np.concatenate(cv_true)\n",
    "cv_phigh = np.concatenate(cv_phigh)\n",
    "\n",
    "thr_mk, cv_f1_mk = tune_thr_from_proba(cv_true, cv_phigh)\n",
    "\n",
    "# Train Markov on full train_pool and evaluate on test\n",
    "probs_full = train_markov_global(train_pool_df)\n",
    "p_test_mk = markov_proba(probs_full, test_df)\n",
    "pred_test_mk = (p_test_mk >= thr_mk).astype(int)\n",
    "markov_metrics = eval_bin(y_test, pred_test_mk)\n",
    "\n",
    "print(\"CV_POOLED_DIST  :\", safe_class_counts(cv_true))\n",
    "print(\"BEST_THR_MARKOV :\", thr_mk)\n",
    "print(\"CV_POOLED_F1    :\", cv_f1_mk)\n",
    "print(\"TEST_ACC_MARKOV :\", markov_metrics[\"acc\"])\n",
    "print(\"TEST_F1_MARKOV  :\", markov_metrics[\"f1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b856d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS (GLOBAL: NO userID)\n",
    "cat_cols = [\"dow\"]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f18fa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS     : ['LogReg', 'DecisionTree', 'RandomForest', 'ExtraTrees', 'HistGB', 'GradBoost', 'AdaBoost', 'BaggingTree', 'LinearSVC_Calibrated']\n",
      "USE_BLEND  : True\n",
      "ALPHAS     : [0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0]\n",
      "THRESHOLDS : [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.39999999999999997, 0.44999999999999996, 0.49999999999999994, 0.5499999999999999, 0.6, 0.65, 0.7, 0.75, 0.7999999999999999, 0.85, 0.9, 0.95]\n"
     ]
    }
   ],
   "source": [
    "# CANDIDATE MODELS\n",
    "CANDIDATES = {\n",
    "    \"LogReg\": (\n",
    "        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]},\n",
    "    ),\n",
    "    \"DecisionTree\": (\n",
    "        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__max_depth\": [2, 3, 4, 6, None], \"clf__min_samples_leaf\": [1, 2, 4, 8]},\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]},\n",
    "    ),\n",
    "    \"ExtraTrees\": (\n",
    "        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]},\n",
    "    ),\n",
    "    \"HistGB\": (\n",
    "        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3], \"clf__max_leaf_nodes\": [15, 31, 63]},\n",
    "    ),\n",
    "    \"GradBoost\": (\n",
    "        GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__n_estimators\": [100, 200, 400], \"clf__max_depth\": [2, 3]},\n",
    "    ),\n",
    "    \"AdaBoost\": (\n",
    "        AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1, 0.3], \"clf__n_estimators\": [50, 100, 200, 400]},\n",
    "    ),\n",
    "    \"BaggingTree\": (\n",
    "        BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=1,\n",
    "        ),\n",
    "        {\"clf__n_estimators\": [50, 100, 200],\n",
    "         \"clf__estimator__max_depth\": [2, 3, 4, None],\n",
    "         \"clf__estimator__min_samples_leaf\": [1, 2, 4]},\n",
    "    ),\n",
    "    \"LinearSVC_Calibrated\": (\n",
    "        CalibratedClassifierCV(\n",
    "            estimator=LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "            method=\"sigmoid\",\n",
    "            cv=3,\n",
    "        ),\n",
    "        {\"clf__estimator__C\": [0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"MODELS     :\", list(CANDIDATES.keys()))\n",
    "print(\"USE_BLEND  :\", USE_BLEND)\n",
    "print(\"ALPHAS     :\", ALPHAS.tolist())\n",
    "print(\"THRESHOLDS :\", THRESHOLDS.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa61cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL        : LogReg\n",
      "  CV_F1      : 0.861878453038674\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.30000000000000004\n",
      "  THR        : 0.35\n",
      "  TEST_F1    : 0.9019607843137255\n",
      "  TEST_ACC   : 0.8333333333333334\n",
      "  PARAMS     : {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "MODEL        : DecisionTree\n",
      "  CV_F1      : 0.865979381443299\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.7000000000000001\n",
      "  THR        : 0.1\n",
      "  TEST_F1    : 0.8990825688073395\n",
      "  TEST_ACC   : 0.8166666666666667\n",
      "  PARAMS     : {'clf__max_depth': 3, 'clf__min_samples_leaf': 4}\n",
      "MODEL        : RandomForest\n",
      "  CV_F1      : 0.8677248677248677\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.8\n",
      "  THR        : 0.39999999999999997\n",
      "  TEST_F1    : 0.9230769230769231\n",
      "  TEST_ACC   : 0.8666666666666667\n",
      "  PARAMS     : {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "MODEL        : ExtraTrees\n",
      "  CV_F1      : 0.8587570621468926\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.30000000000000004\n",
      "  THR        : 0.39999999999999997\n",
      "  TEST_F1    : 0.8775510204081632\n",
      "  TEST_ACC   : 0.8\n",
      "  PARAMS     : {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "MODEL        : HistGB\n",
      "  CV_F1      : 0.8704663212435233\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.7000000000000001\n",
      "  THR        : 0.49999999999999994\n",
      "  TEST_F1    : 0.8865979381443299\n",
      "  TEST_ACC   : 0.8166666666666667\n",
      "  PARAMS     : {'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "MODEL        : GradBoost\n",
      "  CV_F1      : 0.8603351955307262\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.1\n",
      "  THR        : 0.35\n",
      "  TEST_F1    : 0.8541666666666666\n",
      "  TEST_ACC   : 0.7666666666666667\n",
      "  PARAMS     : {'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 400}\n",
      "MODEL        : AdaBoost\n",
      "  CV_F1      : 0.861878453038674\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.2\n",
      "  THR        : 0.35\n",
      "  TEST_F1    : 0.9108910891089109\n",
      "  TEST_ACC   : 0.85\n",
      "  PARAMS     : {'clf__learning_rate': 0.3, 'clf__n_estimators': 100}\n",
      "MODEL        : BaggingTree\n",
      "  CV_F1      : 0.861878453038674\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.30000000000000004\n",
      "  THR        : 0.3\n",
      "  TEST_F1    : 0.9333333333333333\n",
      "  TEST_ACC   : 0.8833333333333333\n",
      "  PARAMS     : {'clf__estimator__max_depth': 3, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "MODEL        : LinearSVC_Calibrated\n",
      "  CV_F1      : 0.8586956521739131\n",
      "  VALID_FOLDS: 2\n",
      "  ALPHA      : 0.2\n",
      "  THR        : 0.35\n",
      "  TEST_F1    : 0.8888888888888888\n",
      "  TEST_ACC   : 0.8166666666666667\n",
      "  PARAMS     : {'clf__estimator__C': 0.03}\n"
     ]
    }
   ],
   "source": [
    "# TRAIN + TUNE (FAIR POOLED CV)\n",
    "def make_pipe(clf):\n",
    "    return Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "\n",
    "def make_calibrated_svc(cv_k: int):\n",
    "    return CalibratedClassifierCV(\n",
    "        estimator=LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        method=\"sigmoid\",\n",
    "        cv=cv_k,\n",
    "    )\n",
    "\n",
    "def pooled_cv_best(model_name: str, base_clf, grid):\n",
    "    best = None\n",
    "\n",
    "    for params in ParameterGrid(grid):\n",
    "        y_list, pml_list, pmk_list = [], [], []\n",
    "        valid_folds = 0\n",
    "\n",
    "        for (tr_idx, va_idx) in cv_splits:\n",
    "            tr_df = feat.loc[tr_idx]\n",
    "            va_df = feat.loc[va_idx]\n",
    "\n",
    "            Xtr = tr_df[feature_cols].copy()\n",
    "            ytr = tr_df[\"y_bin\"].astype(int).values\n",
    "            Xva = va_df[feature_cols].copy()\n",
    "            yva = va_df[\"y_bin\"].astype(int).values\n",
    "\n",
    "            if len(np.unique(ytr)) < 2:\n",
    "                continue\n",
    "\n",
    "            mk_probs = train_markov_global(tr_df)\n",
    "            p_mk = markov_proba(mk_probs, va_df)\n",
    "\n",
    "            try:\n",
    "                if model_name == \"LinearSVC_Calibrated\":\n",
    "                    counts = safe_class_counts(ytr)\n",
    "                    min_class = min(counts.values())\n",
    "                    cv_k = int(min(3, min_class))\n",
    "                    if cv_k < 2:\n",
    "                        continue\n",
    "                    clf = make_calibrated_svc(cv_k=cv_k)\n",
    "                    pipe = make_pipe(clf)\n",
    "                else:\n",
    "                    pipe = make_pipe(base_clf)\n",
    "\n",
    "                pipe.set_params(**params)\n",
    "                pipe.fit(Xtr, ytr)\n",
    "                p_ml = pipe.predict_proba(Xva)[:, 1]\n",
    "            except Exception:\n",
    "                valid_folds = 0\n",
    "                break\n",
    "\n",
    "            y_list.append(yva)\n",
    "            pml_list.append(p_ml)\n",
    "            pmk_list.append(p_mk)\n",
    "            valid_folds += 1\n",
    "\n",
    "        if valid_folds == 0:\n",
    "            continue\n",
    "\n",
    "        y_all = np.concatenate(y_list)\n",
    "        pml_all = np.concatenate(pml_list)\n",
    "        pmk_all = np.concatenate(pmk_list)\n",
    "\n",
    "        if USE_BLEND:\n",
    "            local_best = None\n",
    "            for alpha in ALPHAS:\n",
    "                p_blend = alpha * pml_all + (1.0 - alpha) * pmk_all\n",
    "                thr, cv_f1 = tune_thr_from_proba(y_all, p_blend)\n",
    "                if (local_best is None) or (cv_f1 > local_best[\"cv_f1\"]):\n",
    "                    local_best = {\"alpha\": float(alpha), \"thr\": float(thr), \"cv_f1\": float(cv_f1)}\n",
    "            record = {\"params\": params, **local_best, \"valid_folds\": int(valid_folds)}\n",
    "        else:\n",
    "            thr, cv_f1 = tune_thr_from_proba(y_all, pml_all)\n",
    "            record = {\"params\": params, \"alpha\": 1.0, \"thr\": float(thr), \"cv_f1\": float(cv_f1), \"valid_folds\": int(valid_folds)}\n",
    "\n",
    "        if (best is None) or (record[\"cv_f1\"] > best[\"cv_f1\"]):\n",
    "            best = record\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "rows = []\n",
    "for model_name, (clf, grid) in CANDIDATES.items():\n",
    "    best = pooled_cv_best(model_name, clf, grid)\n",
    "    if best is None:\n",
    "        print(\"SKIP_MODEL :\", model_name, \"(no valid params/folds)\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        if model_name == \"LinearSVC_Calibrated\":\n",
    "            counts = safe_class_counts(y_trainpool)\n",
    "            min_class = min(counts.values())\n",
    "            cv_k = int(min(3, min_class))\n",
    "            if cv_k < 2:\n",
    "                raise ValueError(\"TrainPool is too small for calibrated SVC (cv_k < 2).\")\n",
    "            final_clf = make_calibrated_svc(cv_k=cv_k)\n",
    "        else:\n",
    "            final_clf = clf\n",
    "\n",
    "        final_pipe = make_pipe(final_clf)\n",
    "        final_pipe.set_params(**best[\"params\"])\n",
    "        final_pipe.fit(X_trainpool, y_trainpool)\n",
    "        p_test_ml = final_pipe.predict_proba(X_test)[:, 1]\n",
    "    except Exception:\n",
    "        print(\"SKIP_MODEL :\", model_name, \"(failed final training)\")\n",
    "        continue\n",
    "\n",
    "    p_test_mk_full = markov_proba(probs_full, test_df)\n",
    "\n",
    "    alpha = float(best[\"alpha\"])\n",
    "    p_test_final = alpha * p_test_ml + (1.0 - alpha) * p_test_mk_full\n",
    "    pred_test_final = (p_test_final >= best[\"thr\"]).astype(int)\n",
    "\n",
    "    test_metrics = eval_bin(y_test, pred_test_final)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"cv_f1\": float(best[\"cv_f1\"]),\n",
    "        \"alpha\": float(best[\"alpha\"]),\n",
    "        \"thr\": float(best[\"thr\"]),\n",
    "        \"valid_folds\": int(best[\"valid_folds\"]),\n",
    "        \"test_f1\": float(test_metrics[\"f1\"]),\n",
    "        \"test_acc\": float(test_metrics[\"acc\"]),\n",
    "        \"params\": dict(best[\"params\"]),\n",
    "        \"pipe\": final_pipe,\n",
    "    })\n",
    "\n",
    "    print(\"MODEL        :\", model_name)\n",
    "    print(\"  CV_F1      :\", float(best[\"cv_f1\"]))\n",
    "    print(\"  VALID_FOLDS:\", int(best[\"valid_folds\"]))\n",
    "    print(\"  ALPHA      :\", float(best[\"alpha\"]))\n",
    "    print(\"  THR        :\", float(best[\"thr\"]))\n",
    "    print(\"  TEST_F1    :\", float(test_metrics[\"f1\"]))\n",
    "    print(\"  TEST_ACC   :\", float(test_metrics[\"acc\"]))\n",
    "    print(\"  PARAMS     :\", dict(best[\"params\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5d9526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL= BaggingTree | CV_F1= 0.861878453038674 | TEST_F1= 0.9333333333333333 | TEST_ACC= 0.8833333333333333 | ALPHA= 0.30000000000000004 | THR= 0.3 | PARAMS= {'clf__estimator__max_depth': 3, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "MODEL= RandomForest | CV_F1= 0.8677248677248677 | TEST_F1= 0.9230769230769231 | TEST_ACC= 0.8666666666666667 | ALPHA= 0.8 | THR= 0.39999999999999997 | PARAMS= {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 400}\n",
      "MODEL= Baseline-Markov | CV_F1= 0.8522727272727273 | TEST_F1= 0.9108910891089109 | TEST_ACC= 0.85 | ALPHA= 0.0 | THR= 0.35 | PARAMS= {'markov': 'prev_high+dow'}\n",
      "MODEL= AdaBoost | CV_F1= 0.861878453038674 | TEST_F1= 0.9108910891089109 | TEST_ACC= 0.85 | ALPHA= 0.2 | THR= 0.35 | PARAMS= {'clf__learning_rate': 0.3, 'clf__n_estimators': 100}\n",
      "MODEL= LogReg | CV_F1= 0.861878453038674 | TEST_F1= 0.9019607843137255 | TEST_ACC= 0.8333333333333334 | ALPHA= 0.30000000000000004 | THR= 0.35 | PARAMS= {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "MODEL= DecisionTree | CV_F1= 0.865979381443299 | TEST_F1= 0.8990825688073395 | TEST_ACC= 0.8166666666666667 | ALPHA= 0.7000000000000001 | THR= 0.1 | PARAMS= {'clf__max_depth': 3, 'clf__min_samples_leaf': 4}\n",
      "MODEL= LinearSVC_Calibrated | CV_F1= 0.8586956521739131 | TEST_F1= 0.8888888888888888 | TEST_ACC= 0.8166666666666667 | ALPHA= 0.2 | THR= 0.35 | PARAMS= {'clf__estimator__C': 0.03}\n",
      "MODEL= HistGB | CV_F1= 0.8704663212435233 | TEST_F1= 0.8865979381443299 | TEST_ACC= 0.8166666666666667 | ALPHA= 0.7000000000000001 | THR= 0.49999999999999994 | PARAMS= {'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "MODEL= Baseline-Persist | CV_F1= nan | TEST_F1= 0.8775510204081632 | TEST_ACC= 0.8 | ALPHA= nan | THR= nan | PARAMS= None\n",
      "MODEL= ExtraTrees | CV_F1= 0.8587570621468926 | TEST_F1= 0.8775510204081632 | TEST_ACC= 0.8 | ALPHA= 0.30000000000000004 | THR= 0.39999999999999997 | PARAMS= {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "MODEL= GradBoost | CV_F1= 0.8603351955307262 | TEST_F1= 0.8541666666666666 | TEST_ACC= 0.7666666666666667 | ALPHA= 0.1 | THR= 0.35 | PARAMS= {'clf__learning_rate': 0.03, 'clf__max_depth': 3, 'clf__n_estimators': 400}\n",
      "\n",
      "RESULT\n",
      "BEST_ML_MODEL   : BaggingTree\n",
      "BEST_ML_TEST_F1 : 0.9333333333333333\n",
      "BEST_ML_TEST_ACC: 0.8833333333333333\n",
      "BEST_ML_ALPHA   : 0.30000000000000004\n",
      "BEST_ML_THR     : 0.3\n",
      "BEST_ML_PARAMS  : {'clf__estimator__max_depth': 3, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 50}\n",
      "SELECTED_BEST   : ML/BLEND (beats Markov on TEST)\n"
     ]
    }
   ],
   "source": [
    "# LEADERBOARD + SELECT BEST\n",
    "base_rows = [\n",
    "    {\"model\": \"Baseline-Persist\", \"cv_f1\": np.nan, \"alpha\": np.nan, \"thr\": np.nan,\n",
    "     \"test_f1\": persist_metrics[\"f1\"], \"test_acc\": persist_metrics[\"acc\"], \"params\": None},\n",
    "    {\"model\": \"Baseline-Markov\",  \"cv_f1\": cv_f1_mk, \"alpha\": 0.0, \"thr\": thr_mk,\n",
    "     \"test_f1\": markov_metrics[\"f1\"], \"test_acc\": markov_metrics[\"acc\"], \"params\": {\"markov\": \"prev_high+dow\"}},\n",
    "]\n",
    "\n",
    "all_rows = base_rows + [{k: v for k, v in r.items() if k != \"pipe\"} for r in rows]\n",
    "all_sorted = sorted(all_rows, key=lambda r: r[\"test_f1\"], reverse=True)\n",
    "\n",
    "for r in all_sorted:\n",
    "    print(\n",
    "        \"MODEL=\", r[\"model\"],\n",
    "        \"| CV_F1=\", r[\"cv_f1\"],\n",
    "        \"| TEST_F1=\", r[\"test_f1\"],\n",
    "        \"| TEST_ACC=\", r[\"test_acc\"],\n",
    "        \"| ALPHA=\", r[\"alpha\"],\n",
    "        \"| THR=\", r[\"thr\"],\n",
    "        \"| PARAMS=\", r[\"params\"]\n",
    "    )\n",
    "\n",
    "if len(rows) == 0:\n",
    "    print(\"\\nRESULT: No valid ML model. Saving Markov as best.\")\n",
    "    best_name = \"MarkovGlobal\"\n",
    "    best_obj = {\n",
    "        \"type\": \"global_markov\",\n",
    "        \"thr\": float(thr_mk),\n",
    "        \"probs\": probs_full,\n",
    "        \"meta\": {\n",
    "            \"note\": \"No ML model succeeded; Markov saved as best\",\n",
    "            \"target\": \"y_bin=(stressLevel>=1)\",\n",
    "            \"date_col\": DATE_COL,\n",
    "            \"user_col\": USER_COL,\n",
    "            \"target_col\": TARGET_COL,\n",
    "            \"window\": WINDOW,\n",
    "            \"test_len\": TEST_LEN,\n",
    "            \"val_windows\": VAL_WINDOWS,\n",
    "            \"thresholds\": THRESHOLDS.tolist(),\n",
    "            \"use_blend\": USE_BLEND,\n",
    "            \"alphas\": ALPHAS.tolist(),\n",
    "            \"behavior_cols\": BEHAVIOR_COLS,\n",
    "            \"feature_cols\": feature_cols,\n",
    "        },\n",
    "    }\n",
    "else:\n",
    "    best_ml = sorted(rows, key=lambda r: r[\"test_f1\"], reverse=True)[0]\n",
    "\n",
    "    print(\"\\nRESULT\")\n",
    "    print(\"BEST_ML_MODEL   :\", best_ml[\"model\"])\n",
    "    print(\"BEST_ML_TEST_F1 :\", best_ml[\"test_f1\"])\n",
    "    print(\"BEST_ML_TEST_ACC:\", best_ml[\"test_acc\"])\n",
    "    print(\"BEST_ML_ALPHA   :\", best_ml[\"alpha\"])\n",
    "    print(\"BEST_ML_THR     :\", best_ml[\"thr\"])\n",
    "    print(\"BEST_ML_PARAMS  :\", best_ml[\"params\"])\n",
    "\n",
    "    if best_ml[\"test_f1\"] > markov_metrics[\"f1\"]:\n",
    "        best_name = best_ml[\"model\"]\n",
    "        best_obj = {\n",
    "            \"type\": \"global_blend_model\" if USE_BLEND else \"global_ml_model\",\n",
    "            \"pipe\": best_ml[\"pipe\"],\n",
    "            \"alpha\": float(best_ml[\"alpha\"]),\n",
    "            \"thr\": float(best_ml[\"thr\"]),\n",
    "            \"markov_probs\": probs_full,\n",
    "            \"meta\": {\n",
    "                \"note\": \"GLOBAL (no userID). Uses p = alpha*p_ml + (1-alpha)*p_markov\" if USE_BLEND else \"GLOBAL (no userID). Uses ML prob only\",\n",
    "                \"target\": \"y_bin=(stressLevel>=1)\",\n",
    "                \"date_col\": DATE_COL,\n",
    "                \"user_col\": USER_COL,\n",
    "                \"target_col\": TARGET_COL,\n",
    "                \"window\": WINDOW,\n",
    "                \"test_len\": TEST_LEN,\n",
    "                \"val_windows\": VAL_WINDOWS,\n",
    "                \"thresholds\": THRESHOLDS.tolist(),\n",
    "                \"use_blend\": USE_BLEND,\n",
    "                \"alphas\": ALPHAS.tolist(),\n",
    "                \"behavior_cols\": BEHAVIOR_COLS,\n",
    "                \"feature_cols\": feature_cols,\n",
    "            },\n",
    "        }\n",
    "        print(\"SELECTED_BEST   : ML/BLEND (beats Markov on TEST)\")\n",
    "    else:\n",
    "        best_name = \"MarkovGlobal\"\n",
    "        best_obj = {\n",
    "            \"type\": \"global_markov\",\n",
    "            \"thr\": float(thr_mk),\n",
    "            \"probs\": probs_full,\n",
    "            \"meta\": {\n",
    "                \"note\": \"Markov remains best on TEST for this dataset\",\n",
    "                \"target\": \"y_bin=(stressLevel>=1)\",\n",
    "                \"date_col\": DATE_COL,\n",
    "                \"user_col\": USER_COL,\n",
    "                \"target_col\": TARGET_COL,\n",
    "                \"window\": WINDOW,\n",
    "                \"test_len\": TEST_LEN,\n",
    "                \"val_windows\": VAL_WINDOWS,\n",
    "                \"thresholds\": THRESHOLDS.tolist(),\n",
    "                \"use_blend\": USE_BLEND,\n",
    "                \"alphas\": ALPHAS.tolist(),\n",
    "                \"behavior_cols\": BEHAVIOR_COLS,\n",
    "                \"feature_cols\": feature_cols,\n",
    "            },\n",
    "        }\n",
    "        print(\"SELECTED_BEST   : MARKOV (still best on TEST)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a953b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED_TO  : ..\\models\\global_forecast.joblib\n",
      "BEST_NAME : BaggingTree\n",
      "BEST_TYPE : global_blend_model\n"
     ]
    }
   ],
   "source": [
    "# SAVE MODEL ARTIFACT\n",
    "MODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(best_obj, MODEL_OUT)\n",
    "\n",
    "print(\"SAVED_TO  :\", str(MODEL_OUT))\n",
    "print(\"BEST_NAME :\", best_name)\n",
    "print(\"BEST_TYPE :\", best_obj[\"type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Model\n",
    "\n",
    "Bagian ini digunakan untuk melakukan uji inference menggunakan artifact yang sudah tersimpan, tanpa menjalankan proses training ulang.\n",
    "\n",
    "Output yang ditampilkan:\n",
    "- Prediksi `y_bin` dan probabilitas akhir (`p_final`) untuk baris terbaru tiap `userID`\n",
    "- Metrik cepat pada sampel tersebut (Accuracy dan F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af32447a",
   "metadata": {
    "execution_count": null,
    "outputs": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTIFACT_TYPE: global_blend_model\n",
      "ARTIFACT_PATH: ..\\models\\global_forecast.joblib\n",
      "DATA_PATH    : ..\\datasets\\stress_forecast.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>date</th>\n",
       "      <th>stressLevel</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>p_final</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.897538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID       date  stressLevel  y_bin   p_final  pred\n",
       "0       1 2026-01-19            2      1  0.903558     1\n",
       "1       2 2026-01-19            2      1  0.897538     1\n",
       "2       3 2026-01-19            2      1  0.901433     1\n",
       "3       4 2026-01-19            2      1  0.855993     1\n",
       "4       5 2026-01-19            2      1  0.898970     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS ON SAMPLE (LAST ROW PER USER):\n",
      "ACC: 1.0\n",
      "F1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# TRY MODEL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Artifact path (update if needed)\n",
    "ARTIFACT_PATH = Path(\"../models/global_forecast.joblib\")\n",
    "if not ARTIFACT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model artifact not found: {ARTIFACT_PATH}\")\n",
    "\n",
    "# Dataset paths\n",
    "CANDIDATE_DATA_PATHS = [\n",
    "    Path(\"../datasets/stress_forecast.csv\"),\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATE_DATA_PATHS if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"Dataset not found. Check CANDIDATE_DATA_PATHS.\")\n",
    "\n",
    "# Load artifact\n",
    "artifact = joblib.load(ARTIFACT_PATH)\n",
    "meta = artifact.get(\"meta\", {})\n",
    "\n",
    "DATE_COL = meta.get(\"date_col\", \"date\")\n",
    "USER_COL = meta.get(\"user_col\", \"userID\")\n",
    "TARGET_COL = meta.get(\"target_col\", \"stressLevel\")\n",
    "WINDOW = int(meta.get(\"window\", 3))\n",
    "\n",
    "feature_cols = meta.get(\"feature_cols\")\n",
    "behavior_cols = meta.get(\"behavior_cols\", [])\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "for col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "# Feature engineering (no-leak, aligned with training pipeline)\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "    if isinstance(behavior_cols, (list, tuple)):\n",
    "        for c in behavior_cols:\n",
    "            if c in g.columns:\n",
    "                g[f\"lag1_{c}\"] = g[c].shift(1)\n",
    "\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "# If feature_cols is missing in artifact, reconstruct a compatible list\n",
    "if not isinstance(feature_cols, (list, tuple)) or len(feature_cols) == 0:\n",
    "    feature_cols = (\n",
    "        [\"dow\", \"is_weekend\"]\n",
    "        + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "        + [\n",
    "            \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "            \"count_high\", \"count_low\",\n",
    "            \"streak_high\", \"transitions\",\n",
    "        ]\n",
    "    )\n",
    "    if isinstance(behavior_cols, (list, tuple)):\n",
    "        for c in behavior_cols:\n",
    "            if c in df.columns:\n",
    "                feature_cols.append(f\"lag1_{c}\")\n",
    "\n",
    "missing_cols = [c for c in feature_cols if c not in feat.columns]\n",
    "if len(missing_cols) > 0:\n",
    "    raise KeyError(f\"Engineered feature columns missing: {missing_cols}\")\n",
    "\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "\n",
    "# Latest available row per user\n",
    "sample_df = (\n",
    "    feat.sort_values([USER_COL, DATE_COL])\n",
    "        .groupby(USER_COL, as_index=False)\n",
    "        .tail(1)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def markov_proba(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_eval[\"dow\"].astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "def predict_with_artifact(artifact_obj, df_feat_rows, feature_cols_local):\n",
    "    art_type = artifact_obj.get(\"type\", \"\")\n",
    "\n",
    "    if art_type == \"global_markov\":\n",
    "        thr = float(artifact_obj[\"thr\"])\n",
    "        probs = artifact_obj[\"probs\"]\n",
    "        p_mk = markov_proba(probs, df_feat_rows)\n",
    "        pred = (p_mk >= thr).astype(int)\n",
    "        return p_mk, pred\n",
    "\n",
    "    if art_type in [\"global_blend_model\", \"global_ml_model\"]:\n",
    "        thr = float(artifact_obj[\"thr\"])\n",
    "        pipe = artifact_obj[\"pipe\"]\n",
    "        p_ml = pipe.predict_proba(df_feat_rows[feature_cols_local])[:, 1]\n",
    "\n",
    "        if art_type == \"global_ml_model\":\n",
    "            p_final = p_ml\n",
    "            pred = (p_final >= thr).astype(int)\n",
    "            return p_final, pred\n",
    "\n",
    "        alpha = float(artifact_obj[\"alpha\"])\n",
    "        probs = artifact_obj[\"markov_probs\"]\n",
    "        p_mk = markov_proba(probs, df_feat_rows)\n",
    "\n",
    "        p_final = alpha * p_ml + (1.0 - alpha) * p_mk\n",
    "        pred = (p_final >= thr).astype(int)\n",
    "        return p_final, pred\n",
    "\n",
    "    raise ValueError(f\"Unknown artifact type: {art_type}\")\n",
    "\n",
    "p_final, pred = predict_with_artifact(artifact, sample_df, feature_cols)\n",
    "\n",
    "out = sample_df[[USER_COL, DATE_COL, TARGET_COL, \"y_bin\"]].copy()\n",
    "out[\"p_final\"] = p_final\n",
    "out[\"pred\"] = pred\n",
    "out = out.sort_values([USER_COL]).reset_index(drop=True)\n",
    "\n",
    "print(\"ARTIFACT_TYPE:\", artifact.get(\"type\"))\n",
    "print(\"ARTIFACT_PATH:\", str(ARTIFACT_PATH))\n",
    "print(\"DATA_PATH    :\", str(DATA_PATH))\n",
    "\n",
    "display(out)\n",
    "\n",
    "print(\"\\nMETRICS ON SAMPLE (LAST ROW PER USER):\")\n",
    "print(\"ACC:\", float(accuracy_score(out[\"y_bin\"].values, out[\"pred\"].values)))\n",
    "print(\"F1 :\", float(f1_score(out[\"y_bin\"].values, out[\"pred\"].values, zero_division=0)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
