{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c768a0e",
   "metadata": {},
   "source": [
    "# Imports and Setup\n",
    "\n",
    "Bagian ini memuat:\n",
    "- Import library utama\n",
    "- Konfigurasi untuk **PERSONALIZED forecasting** (1 model per user)\n",
    "- Utility untuk evaluasi, tuning threshold, dan ringkasan per-user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c34505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# =============================================================================\n",
    "# 0) CONFIG\n",
    "# =============================================================================\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"../datasets/stress_forecast.csv\"),\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"stress_forecast.csv not found. Check CANDIDATE_PATHS / DATA_PATH.\")\n",
    "\n",
    "MODEL_OUT = Path(\"../models/personalized_forecast.joblib\")\n",
    "\n",
    "DATE_COL   = \"date\"\n",
    "USER_COL   = \"userID\"\n",
    "TARGET_COL = \"stressLevel\"  # 0..2\n",
    "\n",
    "WINDOW   = 3\n",
    "TEST_LEN = 12\n",
    "\n",
    "VAL_WINDOWS = [(10, 20), (15, 25)]\n",
    "THRESHOLDS  = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "RANDOM_STATE = 26\n",
    "\n",
    "# Personalized: default = False (no semi-global/global)\n",
    "USE_USER_ID_FEATURE = False\n",
    "\n",
    "# Threshold tuning:\n",
    "# - True  => tune threshold per user (fair: uses only that user's CV folds)\n",
    "# - False => tune one global threshold pooled across users\n",
    "TUNE_THRESHOLD_PER_USER = True\n",
    "\n",
    "# Print per-user details for baselines and selected best model\n",
    "PRINT_PER_USER_DETAILS = True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Print helpers\n",
    "# =============================================================================\n",
    "def kv(k, v):\n",
    "    print(f\"{k:<20}: {v}\")\n",
    "\n",
    "def safe_class_counts(y):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    return {0: int((y == 0).sum()), 1: int((y == 1).sum())}\n",
    "\n",
    "def print_per_user_breakdown(title, per_user_records, thr_info=None):\n",
    "    print(f\"\\n{title}\")\n",
    "    for r in per_user_records:\n",
    "        uid = r[\"uid\"]\n",
    "        y = np.asarray(r[\"y\"]).astype(int)\n",
    "        pred = np.asarray(r[\"pred\"]).astype(int)\n",
    "        acc = float(accuracy_score(y, pred))\n",
    "        f1  = float(f1_score(y, pred, zero_division=0))\n",
    "        dist = safe_class_counts(y)\n",
    "\n",
    "        extra = \"\"\n",
    "        if thr_info is not None:\n",
    "            if isinstance(thr_info, dict) and uid in thr_info:\n",
    "                extra = f\" | thr={float(thr_info[uid]):.2f}\"\n",
    "            elif isinstance(thr_info, (float, int)):\n",
    "                extra = f\" | thr={float(thr_info):.2f}\"\n",
    "\n",
    "        print(f\"uid={uid} | n={len(y):<3} | dist={dist} | acc={acc:.4f} | f1={f1:.4f}{extra}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Core helpers\n",
    "# =============================================================================\n",
    "def eval_bin(y_true, y_pred):\n",
    "    return {\n",
    "        \"acc\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "    }\n",
    "\n",
    "def tune_thr_from_proba(y_true, p_high, thresholds=THRESHOLDS):\n",
    "    best_thr, best_f1 = None, -1.0\n",
    "    for thr in thresholds:\n",
    "        pred = (p_high >= thr).astype(int)\n",
    "        f1 = float(f1_score(y_true, pred, zero_division=0))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = f1, thr\n",
    "    return float(best_thr), float(best_f1)\n",
    "\n",
    "def per_user_macro_metrics(per_user_records):\n",
    "    accs, f1s = [], []\n",
    "    for r in per_user_records:\n",
    "        accs.append(accuracy_score(r[\"y\"], r[\"pred\"]))\n",
    "        f1s.append(f1_score(r[\"y\"], r[\"pred\"], zero_division=0))\n",
    "    return float(np.mean(accs)), float(np.mean(f1s))\n",
    "\n",
    "def cv_folds_user(tp_df):\n",
    "    folds = []\n",
    "    for (v0, v1) in VAL_WINDOWS:\n",
    "        if len(tp_df) < v1:\n",
    "            continue\n",
    "        tr = tp_df.iloc[:v0].copy()\n",
    "        va = tp_df.iloc[v0:v1].copy()\n",
    "        folds.append((tr, va))\n",
    "    return folds\n",
    "\n",
    "def min_class_count(y):\n",
    "    vc = pd.Series(np.asarray(y)).value_counts()\n",
    "    if len(vc) < 2:\n",
    "        return 0\n",
    "    return int(vc.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598dc2a3",
   "metadata": {},
   "source": [
    "# Load and Explore Dataset\n",
    "\n",
    "Bagian ini mencakup:\n",
    "- Load dataset\n",
    "- Validasi kolom wajib\n",
    "- Parsing `date` dan sorting time-series per user\n",
    "- Validasi range target `stressLevel` (0–2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bc3f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH           : ..\\datasets\\stress_forecast.csv\n",
      "ROWS_RAW            : 300\n",
      "USERS_RAW           : 5\n",
      "DATE_RANGE_RAW      : 2025-11-21 -> 2026-01-19\n",
      "\n",
      "HEAD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stressLevelID</th>\n",
       "      <th>userID</th>\n",
       "      <th>date</th>\n",
       "      <th>stressLevel</th>\n",
       "      <th>GPA</th>\n",
       "      <th>extracurricularHourPerDay</th>\n",
       "      <th>physicalActivityHourPerDay</th>\n",
       "      <th>sleepHourPerDay</th>\n",
       "      <th>studyHourPerDay</th>\n",
       "      <th>socialHourPerDay</th>\n",
       "      <th>emoji</th>\n",
       "      <th>createdAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-21 21:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-22 20:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-23 22:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-11-24 19:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-11-25 21:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stressLevelID  userID       date  stressLevel   GPA  \\\n",
       "0              2       1 2025-11-21            1  3.82   \n",
       "1              7       1 2025-11-22            0  3.82   \n",
       "2             12       1 2025-11-23            0  3.82   \n",
       "3             17       1 2025-11-24            1  3.82   \n",
       "4             22       1 2025-11-25            1  3.82   \n",
       "\n",
       "   extracurricularHourPerDay  physicalActivityHourPerDay  sleepHourPerDay  \\\n",
       "0                        0.0                         0.5              7.0   \n",
       "1                        0.0                         1.0              9.0   \n",
       "2                        0.0                         3.0              9.0   \n",
       "3                        0.0                         0.5              8.0   \n",
       "4                        0.0                         1.0              7.0   \n",
       "\n",
       "   studyHourPerDay  socialHourPerDay  emoji            createdAt  \n",
       "0              7.0               2.0      1  2025-11-21 21:12:00  \n",
       "1              2.0               5.0      2  2025-11-22 20:07:00  \n",
       "2              1.0               6.0      1  2025-11-23 22:18:00  \n",
       "3              7.0               5.0      3  2025-11-24 19:55:00  \n",
       "4              7.0               4.0      3  2025-11-25 21:40:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "for required_col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if required_col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{required_col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "if not df[TARGET_COL].dropna().between(0, 2).all():\n",
    "    raise ValueError(f\"'{TARGET_COL}' must be within range 0..2\")\n",
    "\n",
    "kv(\"DATA_PATH\", str(DATA_PATH))\n",
    "kv(\"ROWS_RAW\", len(df))\n",
    "kv(\"USERS_RAW\", df[USER_COL].nunique())\n",
    "kv(\"DATE_RANGE_RAW\", f\"{df[DATE_COL].min().date()} -> {df[DATE_COL].max().date()}\")\n",
    "\n",
    "print(\"\\nHEAD:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99836397",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Ringkasan cepat:\n",
    "- Distribusi `stressLevel` (0–2)\n",
    "- Jumlah baris per user (indikasi kecukupan data untuk split & CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10509d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_DIST_0_2     : {0: 124, 1: 91, 2: 85}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_PER_USER       : {1: 60, 2: 60, 3: 60, 4: 60, 5: 60}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# EDA: target distribution (0..2)\n",
    "target_counts = df[TARGET_COL].value_counts().sort_index()\n",
    "kv(\"TARGET_DIST_0_2\", target_counts.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "target_counts.plot(kind=\"bar\")\n",
    "plt.title(f\"Distribution of {TARGET_COL} (0..2)\")\n",
    "plt.xlabel(TARGET_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "# EDA: rows per user\n",
    "rows_per_user = df[USER_COL].value_counts().sort_index()\n",
    "kv(\"ROWS_PER_USER\", rows_per_user.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "rows_per_user.plot(kind=\"bar\")\n",
    "plt.title(\"Rows per user\")\n",
    "plt.xlabel(USER_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21e8fa",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Bagian ini melakukan **feature engineering tanpa leakage**:\n",
    "- Fitur kalender: `dow`, `is_weekend`\n",
    "- Fitur lag target: `lag_sp_1..lag_sp_WINDOW`\n",
    "- Rolling stats dari history yang berakhir di `t-1`\n",
    "\n",
    "Transformasi label:\n",
    "- `y_bin = 1` jika `stressLevel >= 1`\n",
    "- `y_bin = 0` jika `stressLevel == 0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6b8eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_FEAT           : 285\n",
      "USERS               : [1, 2, 3, 4, 5]\n",
      "DATE_RANGE_FEAT     : 2025-11-24 -> 2026-01-19\n",
      "WINDOW              : 3\n",
      "TEST_LEN            : 12\n",
      "FEATURES_COUNT      : 13\n",
      "USE_USER_ID_FEATURE : False\n",
      "BINARY_DIST         : {1: 171, 0: 114}\n",
      "VAL_WINDOWS         : [(10, 20), (15, 25)]\n",
      "TUNE_THRESHOLD_PER_USER: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>date</th>\n",
       "      <th>stressLevel</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_sp_1</th>\n",
       "      <th>lag_sp_2</th>\n",
       "      <th>lag_sp_3</th>\n",
       "      <th>sp_mean</th>\n",
       "      <th>sp_std</th>\n",
       "      <th>sp_min</th>\n",
       "      <th>sp_max</th>\n",
       "      <th>count_high</th>\n",
       "      <th>count_low</th>\n",
       "      <th>streak_high</th>\n",
       "      <th>transitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID       date  stressLevel  y_bin  dow  is_weekend  lag_sp_1  lag_sp_2  \\\n",
       "0       1 2025-11-24            1      1    0           0       0.0       0.0   \n",
       "1       1 2025-11-25            1      1    1           0       1.0       0.0   \n",
       "2       1 2025-11-26            1      1    2           0       1.0       1.0   \n",
       "3       1 2025-11-27            1      1    3           0       1.0       1.0   \n",
       "4       1 2025-11-28            1      1    4           0       1.0       1.0   \n",
       "\n",
       "   lag_sp_3   sp_mean   sp_std  sp_min  sp_max  count_high  count_low  \\\n",
       "0       1.0  0.333333  0.57735     0.0     1.0         1.0        2.0   \n",
       "1       0.0  0.333333  0.57735     0.0     1.0         1.0        2.0   \n",
       "2       0.0  0.666667  0.57735     0.0     1.0         2.0        1.0   \n",
       "3       1.0  1.000000  0.00000     1.0     1.0         3.0        0.0   \n",
       "4       1.0  1.000000  0.00000     1.0     1.0         3.0        0.0   \n",
       "\n",
       "   streak_high  transitions  \n",
       "0            0          2.0  \n",
       "1            1          2.0  \n",
       "2            2          1.0  \n",
       "3            3          1.0  \n",
       "4            4          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FEATURE ENGINEERING (NO-LEAK)\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# Binary labeling: y_bin = 1 if pred>=1 else 0\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "feature_cols = (\n",
    "    [\"dow\", \"is_weekend\"]\n",
    "    + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "    + [\n",
    "        \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "        \"count_high\", \"count_low\",\n",
    "        \"streak_high\", \"transitions\",\n",
    "    ]\n",
    ")\n",
    "if USE_USER_ID_FEATURE:\n",
    "    feature_cols = [USER_COL] + feature_cols\n",
    "\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "users = sorted(feat[USER_COL].unique().tolist())\n",
    "\n",
    "kv(\"ROWS_FEAT\", len(feat))\n",
    "kv(\"USERS\", users)\n",
    "kv(\"DATE_RANGE_FEAT\", f\"{feat[DATE_COL].min().date()} -> {feat[DATE_COL].max().date()}\")\n",
    "kv(\"WINDOW\", WINDOW)\n",
    "kv(\"TEST_LEN\", TEST_LEN)\n",
    "kv(\"FEATURES_COUNT\", len(feature_cols))\n",
    "kv(\"USE_USER_ID_FEATURE\", USE_USER_ID_FEATURE)\n",
    "kv(\"BINARY_DIST\", feat[\"y_bin\"].value_counts().to_dict())\n",
    "kv(\"VAL_WINDOWS\", VAL_WINDOWS)\n",
    "kv(\"TUNE_THRESHOLD_PER_USER\", TUNE_THRESHOLD_PER_USER)\n",
    "\n",
    "display(feat[[USER_COL, DATE_COL, TARGET_COL, \"y_bin\"] + feature_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bd733",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "Cakupan bagian ini:\n",
    "- Split time-based per user (TEST = last `TEST_LEN`)\n",
    "- Baseline L1: Persistence\n",
    "- Baseline L2: Markov per-user + threshold tuning (pooled CV)\n",
    "- Kandidat model ML per user (tanpa userID sebagai fitur)\n",
    "- SVM calibrated dengan cv adaptif (SAFE)\n",
    "- Leaderboard + seleksi model terbaik vs baseline\n",
    "- Simpan artifact ke file `.joblib`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0777bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_TRAINPOOL     : 225\n",
      "TOTAL_TEST          : 60\n",
      "\n",
      "PER_USER_SPLIT:\n",
      "uid=1 | total=57 | train_pool=45 dist={0: 20, 1: 25} | test=12 dist={0: 1, 1: 11}\n",
      "uid=2 | total=57 | train_pool=45 dist={0: 19, 1: 26} | test=12 dist={0: 3, 1: 9}\n",
      "uid=3 | total=57 | train_pool=45 dist={0: 27, 1: 18} | test=12 dist={0: 5, 1: 7}\n",
      "uid=4 | total=57 | train_pool=45 dist={0: 17, 1: 28} | test=12 dist={0: 0, 1: 12}\n",
      "uid=5 | total=57 | train_pool=45 dist={0: 20, 1: 25} | test=12 dist={0: 2, 1: 10}\n"
     ]
    }
   ],
   "source": [
    "# SPLIT PER USER (TIME-BASED)\n",
    "per_user = {}\n",
    "split_rows = []\n",
    "\n",
    "for uid in users:\n",
    "    g = feat[feat[USER_COL] == uid].sort_values(DATE_COL).reset_index(drop=True)\n",
    "    n = len(g)\n",
    "    test_start = n - TEST_LEN\n",
    "    if test_start <= 10:\n",
    "        raise ValueError(f\"User {uid}: insufficient rows for split (n={n}, TEST_LEN={TEST_LEN}).\")\n",
    "\n",
    "    tp = g.iloc[:test_start].copy()\n",
    "    te = g.iloc[test_start:].copy()\n",
    "\n",
    "    per_user[uid] = {\"train_pool\": tp, \"test\": te}\n",
    "\n",
    "    split_rows.append({\n",
    "        \"uid\": uid,\n",
    "        \"n_total\": n,\n",
    "        \"n_train_pool\": len(tp),\n",
    "        \"n_test\": len(te),\n",
    "        \"train_pool_dist\": safe_class_counts(tp[\"y_bin\"].values),\n",
    "        \"test_dist\": safe_class_counts(te[\"y_bin\"].values),\n",
    "    })\n",
    "\n",
    "kv(\"TOTAL_TRAINPOOL\", sum(r[\"n_train_pool\"] for r in split_rows))\n",
    "kv(\"TOTAL_TEST\", sum(r[\"n_test\"] for r in split_rows))\n",
    "\n",
    "print(\"\\nPER_USER_SPLIT:\")\n",
    "for r in split_rows:\n",
    "    print(\n",
    "        f\"uid={r['uid']} | total={r['n_total']} | train_pool={r['n_train_pool']} dist={r['train_pool_dist']} \"\n",
    "        f\"| test={r['n_test']} dist={r['test_dist']}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc6a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_POOLED_ACC     : 0.8\n",
      "TEST_POOLED_F1      : 0.8775510204081632\n",
      "TEST_MACRO_ACC      : 0.8\n",
      "TEST_MACRO_F1       : 0.8602308802308803\n",
      "\n",
      "PER-USER (Persistence) on TEST:\n",
      "uid=1 | n=12  | dist={0: 1, 1: 11} | acc=0.8333 | f1=0.9091\n",
      "uid=2 | n=12  | dist={0: 3, 1: 9} | acc=0.6667 | f1=0.7778\n",
      "uid=3 | n=12  | dist={0: 5, 1: 7} | acc=0.6667 | f1=0.7143\n",
      "uid=4 | n=12  | dist={0: 0, 1: 12} | acc=1.0000 | f1=1.0000\n",
      "uid=5 | n=12  | dist={0: 2, 1: 10} | acc=0.8333 | f1=0.9000\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L1: PERSISTENCE (PER USER)\n",
    "persist_user_records = []\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "for uid in users:\n",
    "    te = per_user[uid][\"test\"]\n",
    "    y = te[\"y_bin\"].astype(int).values\n",
    "    pred = (te[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "\n",
    "    persist_user_records.append({\"uid\": uid, \"y\": y, \"pred\": pred})\n",
    "    all_true.append(y)\n",
    "    all_pred.append(pred)\n",
    "\n",
    "y_all = np.concatenate(all_true)\n",
    "pred_all = np.concatenate(all_pred)\n",
    "\n",
    "persist_pooled = eval_bin(y_all, pred_all)\n",
    "persist_macro_acc, persist_macro_f1 = per_user_macro_metrics(persist_user_records)\n",
    "\n",
    "kv(\"TEST_POOLED_ACC\", persist_pooled[\"acc\"])\n",
    "kv(\"TEST_POOLED_F1\", persist_pooled[\"f1\"])\n",
    "kv(\"TEST_MACRO_ACC\", persist_macro_acc)\n",
    "kv(\"TEST_MACRO_F1\", persist_macro_f1)\n",
    "\n",
    "if PRINT_PER_USER_DETAILS:\n",
    "    print_per_user_breakdown(\"PER-USER (Persistence) on TEST:\", persist_user_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cca866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_FOLDS_TOTAL      : 10\n",
      "CV_POOLED_DIST      : {0: 15, 1: 85}\n",
      "BEST_THR_MARKOV     : 0.05\n",
      "CV_POOLED_F1        : 0.918918918918919\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "\n",
      "PER-USER (Markov) on TEST:\n",
      "uid=1 | n=12  | dist={0: 1, 1: 11} | acc=0.9167 | f1=0.9565 | thr=0.05\n",
      "uid=2 | n=12  | dist={0: 3, 1: 9} | acc=0.7500 | f1=0.8571 | thr=0.05\n",
      "uid=3 | n=12  | dist={0: 5, 1: 7} | acc=0.5833 | f1=0.7368 | thr=0.05\n",
      "uid=4 | n=12  | dist={0: 0, 1: 12} | acc=1.0000 | f1=1.0000 | thr=0.05\n",
      "uid=5 | n=12  | dist={0: 2, 1: 10} | acc=0.8333 | f1=0.9091 | thr=0.05\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L2: MARKOV PER USER (prev_high, dow) + THRESHOLD TUNING\n",
    "def train_markov_one_user(df_train):\n",
    "    counts = np.zeros((2, 7, 2), dtype=int)  # prev(2) x dow(7) x y(2)\n",
    "    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = (df_train[\"dow\"]).astype(int).values\n",
    "    yb   = (df_train[\"y_bin\"]).astype(int).values\n",
    "    for p, d, y in zip(prev, dow, yb):\n",
    "        counts[p, d, y] += 1\n",
    "    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)  # Laplace smoothing\n",
    "    return probs\n",
    "\n",
    "def markov_proba_user(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = (df_eval[\"dow\"]).astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "# Pooled CV threshold tuning (fair: uses only train_pool folds)\n",
    "cv_true, cv_phigh = [], []\n",
    "cv_fold_stats = []\n",
    "\n",
    "for uid in users:\n",
    "    tp = per_user[uid][\"train_pool\"]\n",
    "    folds = cv_folds_user(tp)\n",
    "    for (tr_df, va_df) in folds:\n",
    "        probs = train_markov_one_user(tr_df)\n",
    "        p = markov_proba_user(probs, va_df)\n",
    "        cv_true.append(va_df[\"y_bin\"].astype(int).values)\n",
    "        cv_phigh.append(p)\n",
    "        cv_fold_stats.append({\"uid\": uid, \"tr_len\": len(tr_df), \"va_len\": len(va_df)})\n",
    "\n",
    "if len(cv_true) == 0:\n",
    "    raise ValueError(\"No valid CV folds. Reduce VAL_WINDOWS / TEST_LEN / WINDOW.\")\n",
    "\n",
    "cv_true = np.concatenate(cv_true)\n",
    "cv_phigh = np.concatenate(cv_phigh)\n",
    "\n",
    "thr_mk, cv_f1_mk = tune_thr_from_proba(cv_true, cv_phigh)\n",
    "\n",
    "mk_models = {}\n",
    "markov_user_records = []\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "for uid in users:\n",
    "    tp = per_user[uid][\"train_pool\"]\n",
    "    te = per_user[uid][\"test\"]\n",
    "\n",
    "    probs = train_markov_one_user(tp)\n",
    "    mk_models[uid] = probs\n",
    "\n",
    "    p = markov_proba_user(probs, te)\n",
    "    pred = (p >= thr_mk).astype(int)\n",
    "    y = te[\"y_bin\"].astype(int).values\n",
    "\n",
    "    markov_user_records.append({\"uid\": uid, \"y\": y, \"pred\": pred})\n",
    "    all_true.append(y)\n",
    "    all_pred.append(pred)\n",
    "\n",
    "y_all = np.concatenate(all_true)\n",
    "pred_all = np.concatenate(all_pred)\n",
    "\n",
    "markov_pooled = eval_bin(y_all, pred_all)\n",
    "markov_macro_acc, markov_macro_f1 = per_user_macro_metrics(markov_user_records)\n",
    "\n",
    "kv(\"CV_FOLDS_TOTAL\", len(cv_fold_stats))\n",
    "kv(\"CV_POOLED_DIST\", safe_class_counts(cv_true))\n",
    "kv(\"BEST_THR_MARKOV\", thr_mk)\n",
    "kv(\"CV_POOLED_F1\", cv_f1_mk)\n",
    "kv(\"TEST_POOLED_ACC\", markov_pooled[\"acc\"])\n",
    "kv(\"TEST_POOLED_F1\", markov_pooled[\"f1\"])\n",
    "kv(\"TEST_MACRO_ACC\", markov_macro_acc)\n",
    "kv(\"TEST_MACRO_F1\", markov_macro_f1)\n",
    "\n",
    "if PRINT_PER_USER_DETAILS:\n",
    "    print_per_user_breakdown(\"PER-USER (Markov) on TEST:\", markov_user_records, thr_info=thr_mk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b0257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_COLS            : ['dow', 'is_weekend']\n",
      "NUM_COLS_COUNT      : 11\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS (FOR ML)\n",
    "cat_cols = [\"dow\", \"is_weekend\"]\n",
    "if USE_USER_ID_FEATURE:\n",
    "    cat_cols = [USER_COL] + cat_cols\n",
    "\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "kv(\"CAT_COLS\", cat_cols)\n",
    "kv(\"NUM_COLS_COUNT\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02578c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS              : ['LogReg', 'DecisionTree', 'RandomForest', 'ExtraTrees', 'HistGB', 'GradBoost', 'AdaBoost', 'BaggingTree', 'LinearSVC_Calibrated_SAFE']\n",
      "THRESHOLDS_COUNT    : 19\n"
     ]
    }
   ],
   "source": [
    "# CANDIDATE MODELS (NON-SVM) + SVM SAFE CONFIG\n",
    "try:\n",
    "    bag_base = BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    BAG_ESTIMATOR_PARAM = \"clf__estimator__\"\n",
    "except TypeError:\n",
    "    bag_base = BaggingClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    BAG_ESTIMATOR_PARAM = \"clf__base_estimator__\"\n",
    "\n",
    "CANDIDATES = {\n",
    "    \"LogReg\": (\n",
    "        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n",
    "    ),\n",
    "    \"DecisionTree\": (\n",
    "        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__max_depth\": [2, 3, 4, 6, None], \"clf__min_samples_leaf\": [1, 2, 4, 8]}\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]}\n",
    "    ),\n",
    "    \"ExtraTrees\": (\n",
    "        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]}\n",
    "    ),\n",
    "    \"HistGB\": (\n",
    "        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3],\n",
    "         \"clf__max_leaf_nodes\": [15, 31, 63]}\n",
    "    ),\n",
    "    \"GradBoost\": (\n",
    "        GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__n_estimators\": [100, 200, 400],\n",
    "         \"clf__max_depth\": [2, 3]}\n",
    "    ),\n",
    "    \"AdaBoost\": (\n",
    "        AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1, 0.3], \"clf__n_estimators\": [50, 100, 200, 400]}\n",
    "    ),\n",
    "    \"BaggingTree\": (\n",
    "        bag_base,\n",
    "        {\"clf__n_estimators\": [50, 100, 200],\n",
    "         f\"{BAG_ESTIMATOR_PARAM}max_depth\": [2, 3, 4, None],\n",
    "         f\"{BAG_ESTIMATOR_PARAM}min_samples_leaf\": [1, 2, 4]}\n",
    "    ),\n",
    "}\n",
    "\n",
    "SVM_NAME = \"LinearSVC_Calibrated_SAFE\"\n",
    "SVM_GRID = {\"C\": [0.03, 0.1, 0.3, 1.0, 3.0]}\n",
    "\n",
    "kv(\"MODELS\", list(CANDIDATES.keys()) + [SVM_NAME])\n",
    "kv(\"THRESHOLDS_COUNT\", len(THRESHOLDS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d127fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNING UTILITIES (GLOBAL THRESHOLD OR PER-USER THRESHOLD)\n",
    "def tune_global_thr_pooled_over_all_users(pipe, params):\n",
    "    y_list, p_list = [], []\n",
    "    for uid in users:\n",
    "        tp = per_user[uid][\"train_pool\"]\n",
    "        folds = cv_folds_user(tp)\n",
    "        for tr_df, va_df in folds:\n",
    "            ytr = tr_df[\"y_bin\"].astype(int).values\n",
    "            if len(np.unique(ytr)) < 2:\n",
    "                continue\n",
    "            pipe.set_params(**params)\n",
    "            pipe.fit(tr_df[feature_cols], ytr)\n",
    "            p = pipe.predict_proba(va_df[feature_cols])[:, 1]\n",
    "            y_list.append(va_df[\"y_bin\"].astype(int).values)\n",
    "            p_list.append(p)\n",
    "\n",
    "    if len(y_list) == 0:\n",
    "        return None, None\n",
    "\n",
    "    y_all = np.concatenate(y_list)\n",
    "    p_all = np.concatenate(p_list)\n",
    "    thr, cv_f1 = tune_thr_from_proba(y_all, p_all)\n",
    "    return float(thr), float(cv_f1)\n",
    "\n",
    "def tune_per_user_thr(pipe, params):\n",
    "    thr_by_user = {}\n",
    "    f1s = []\n",
    "\n",
    "    for uid in users:\n",
    "        tp = per_user[uid][\"train_pool\"]\n",
    "        folds = cv_folds_user(tp)\n",
    "        if len(folds) == 0:\n",
    "            return None, None\n",
    "\n",
    "        y_list, p_list = [], []\n",
    "        for tr_df, va_df in folds:\n",
    "            ytr = tr_df[\"y_bin\"].astype(int).values\n",
    "            if len(np.unique(ytr)) < 2:\n",
    "                continue\n",
    "            pipe.set_params(**params)\n",
    "            pipe.fit(tr_df[feature_cols], ytr)\n",
    "            p = pipe.predict_proba(va_df[feature_cols])[:, 1]\n",
    "            y_list.append(va_df[\"y_bin\"].astype(int).values)\n",
    "            p_list.append(p)\n",
    "\n",
    "        if len(y_list) == 0:\n",
    "            return None, None\n",
    "\n",
    "        y_u = np.concatenate(y_list)\n",
    "        p_u = np.concatenate(p_list)\n",
    "        thr_u, f1_u = tune_thr_from_proba(y_u, p_u)\n",
    "        thr_by_user[uid] = float(thr_u)\n",
    "        f1s.append(float(f1_u))\n",
    "\n",
    "    return thr_by_user, float(np.mean(f1s))\n",
    "\n",
    "def eval_personalized_models(models_by_user, thr_by_user_or_scalar):\n",
    "    per_user_records = []\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for uid in users:\n",
    "        te = per_user[uid][\"test\"]\n",
    "        y = te[\"y_bin\"].astype(int).values\n",
    "\n",
    "        pipe = models_by_user[uid]\n",
    "        p = pipe.predict_proba(te[feature_cols])[:, 1]\n",
    "        thr = thr_by_user_or_scalar[uid] if isinstance(thr_by_user_or_scalar, dict) else float(thr_by_user_or_scalar)\n",
    "        pred = (p >= thr).astype(int)\n",
    "\n",
    "        per_user_records.append({\"uid\": uid, \"y\": y, \"pred\": pred})\n",
    "        all_true.append(y)\n",
    "        all_pred.append(pred)\n",
    "\n",
    "    y_all = np.concatenate(all_true)\n",
    "    pred_all = np.concatenate(all_pred)\n",
    "\n",
    "    pooled = eval_bin(y_all, pred_all)\n",
    "    macro_acc, macro_f1 = per_user_macro_metrics(per_user_records)\n",
    "    macro = {\"acc\": float(macro_acc), \"f1\": float(macro_f1)}\n",
    "    return pooled, macro, per_user_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67acd35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: LogReg\n",
      "CV_SCORE            : 0.9123454790823212\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.9056603773584906\n",
      "TEST_POOLED_ACC     : 0.8333333333333334\n",
      "TEST_MACRO_F1       : 0.8945511010728401\n",
      "TEST_MACRO_ACC      : 0.8333333333333333\n",
      "PARAMS              : {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "\n",
      "MODEL: DecisionTree\n",
      "CV_SCORE            : 0.8986311933680355\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__max_depth': 2, 'clf__min_samples_leaf': 8}\n",
      "\n",
      "MODEL: RandomForest\n",
      "CV_SCORE            : 0.9298000245368667\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8846153846153846\n",
      "TEST_POOLED_ACC     : 0.8\n",
      "TEST_MACRO_F1       : 0.8588368153585545\n",
      "TEST_MACRO_ACC      : 0.8\n",
      "PARAMS              : {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "\n",
      "MODEL: ExtraTrees\n",
      "CV_SCORE            : 0.9241101241101243\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8846153846153846\n",
      "TEST_POOLED_ACC     : 0.8\n",
      "TEST_MACRO_F1       : 0.8588368153585545\n",
      "TEST_MACRO_ACC      : 0.8\n",
      "PARAMS              : {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 200}\n",
      "\n",
      "MODEL: HistGB\n",
      "CV_SCORE            : 0.8986311933680355\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "\n",
      "MODEL: GradBoost\n",
      "CV_SCORE            : 0.8948171948171948\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__n_estimators': 100}\n",
      "\n",
      "MODEL: AdaBoost\n",
      "CV_SCORE            : 0.9298000245368667\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.9038461538461539\n",
      "TEST_POOLED_ACC     : 0.8333333333333334\n",
      "TEST_MACRO_F1       : 0.887408243929983\n",
      "TEST_MACRO_ACC      : 0.8333333333333333\n",
      "PARAMS              : {'clf__learning_rate': 0.03, 'clf__n_estimators': 50}\n",
      "\n",
      "MODEL: BaggingTree\n",
      "CV_SCORE            : 0.9298000245368667\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8932038834951457\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8676280241497633\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__estimator__max_depth': 2, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# PERSONALIZED ML: TRAIN + TUNE (NON-SVM)\n",
    "rows = []\n",
    "\n",
    "for name, (clf, grid) in CANDIDATES.items():\n",
    "    best = None\n",
    "\n",
    "    for params in ParameterGrid(grid):\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "\n",
    "        if TUNE_THRESHOLD_PER_USER:\n",
    "            thr_obj, cv_score = tune_per_user_thr(pipe, params)\n",
    "        else:\n",
    "            thr_obj, cv_score = tune_global_thr_pooled_over_all_users(pipe, params)\n",
    "\n",
    "        if thr_obj is None:\n",
    "            continue\n",
    "\n",
    "        if (best is None) or (cv_score > best[\"cv_score\"]):\n",
    "            best = {\"params\": dict(params), \"thr_obj\": thr_obj, \"cv_score\": float(cv_score)}\n",
    "\n",
    "    if best is None:\n",
    "        print(f\"SKIP_MODEL: {name} (no valid params/folds)\")\n",
    "        continue\n",
    "\n",
    "    # Final training per user (train_pool only)\n",
    "    models_by_user = {}\n",
    "    ok = True\n",
    "\n",
    "    for uid in users:\n",
    "        tp = per_user[uid][\"train_pool\"]\n",
    "        ytr = tp[\"y_bin\"].astype(int).values\n",
    "        if len(np.unique(ytr)) < 2:\n",
    "            ok = False\n",
    "            break\n",
    "\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "        pipe.set_params(**best[\"params\"])\n",
    "        pipe.fit(tp[feature_cols], ytr)\n",
    "        models_by_user[uid] = pipe\n",
    "\n",
    "    if not ok:\n",
    "        print(f\"SKIP_MODEL: {name} (some user train_pool has single class)\")\n",
    "        continue\n",
    "\n",
    "    pooled, macro, user_records = eval_personalized_models(models_by_user, best[\"thr_obj\"])\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"cv_score\": float(best[\"cv_score\"]),\n",
    "        \"thr_obj\": best[\"thr_obj\"],\n",
    "        \"test_pooled_f1\": float(pooled[\"f1\"]),\n",
    "        \"test_pooled_acc\": float(pooled[\"acc\"]),\n",
    "        \"test_macro_f1\": float(macro[\"f1\"]),\n",
    "        \"test_macro_acc\": float(macro[\"acc\"]),\n",
    "        \"params\": dict(best[\"params\"]),\n",
    "        \"models_by_user\": models_by_user,\n",
    "        \"test_user_records\": user_records,\n",
    "    })\n",
    "\n",
    "    thr_desc = \"per-user\" if isinstance(best[\"thr_obj\"], dict) else f\"{best['thr_obj']:.2f}\"\n",
    "    print(f\"\\nMODEL: {name}\")\n",
    "    kv(\"CV_SCORE\", best[\"cv_score\"])\n",
    "    kv(\"THRESHOLD\", thr_desc)\n",
    "    kv(\"TEST_POOLED_F1\", pooled[\"f1\"])\n",
    "    kv(\"TEST_POOLED_ACC\", pooled[\"acc\"])\n",
    "    kv(\"TEST_MACRO_F1\", macro[\"f1\"])\n",
    "    kv(\"TEST_MACRO_ACC\", macro[\"acc\"])\n",
    "    kv(\"PARAMS\", best[\"params\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f62c22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_FEASIBLE_ALL_USERS: True\n",
      "SVM_FEASIBLE_DETAIL:\n",
      "uid=1 | min_class_count_trainpool=20\n",
      "uid=2 | min_class_count_trainpool=19\n",
      "uid=3 | min_class_count_trainpool=18\n",
      "uid=4 | min_class_count_trainpool=17\n",
      "uid=5 | min_class_count_trainpool=20\n",
      "\n",
      "MODEL: LinearSVC_Calibrated_SAFE\n",
      "CV_SCORE            : 0.9234759138649299\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.865979381443299\n",
      "TEST_POOLED_ACC     : 0.7833333333333333\n",
      "TEST_MACRO_F1       : 0.7445511010728402\n",
      "TEST_MACRO_ACC      : 0.7833333333333333\n",
      "PARAMS              : {'C': 1.0, 'final_cv_by_user': {1: 3, 2: 3, 3: 3, 4: 3, 5: 3}}\n"
     ]
    }
   ],
   "source": [
    "# SVM CALIBRATED SAFE (ADAPTIVE CV PER FOLD)\n",
    "def make_calibrator(base, cv_k):\n",
    "    try:\n",
    "        return CalibratedClassifierCV(estimator=base, method=\"sigmoid\", cv=cv_k)\n",
    "    except TypeError:\n",
    "        return CalibratedClassifierCV(base_estimator=base, method=\"sigmoid\", cv=cv_k)\n",
    "\n",
    "def svm_fit_predict_proba(tr_X, tr_y, va_X, C, cv_max=3):\n",
    "    mcc = min_class_count(tr_y)\n",
    "    cv_k = int(min(cv_max, mcc))\n",
    "    if cv_k < 2:\n",
    "        return None, cv_k\n",
    "    base = LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE, C=float(C))\n",
    "    calib = make_calibrator(base, cv_k=cv_k)\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", calib)])\n",
    "    pipe.fit(tr_X, tr_y)\n",
    "    return pipe.predict_proba(va_X)[:, 1], cv_k\n",
    "\n",
    "# Feasibility check for final training across all users\n",
    "svm_feasible_all_users = True\n",
    "svm_feasible_detail = []\n",
    "\n",
    "for uid in users:\n",
    "    y_tp = per_user[uid][\"train_pool\"][\"y_bin\"].astype(int).values\n",
    "    mcc = min_class_count(y_tp)\n",
    "    svm_feasible_detail.append({\"uid\": uid, \"min_class_count_trainpool\": mcc})\n",
    "    if mcc < 2:\n",
    "        svm_feasible_all_users = False\n",
    "\n",
    "kv(\"SVM_FEASIBLE_ALL_USERS\", svm_feasible_all_users)\n",
    "print(\"SVM_FEASIBLE_DETAIL:\")\n",
    "for r in svm_feasible_detail:\n",
    "    print(f\"uid={r['uid']} | min_class_count_trainpool={r['min_class_count_trainpool']}\")\n",
    "\n",
    "if svm_feasible_all_users:\n",
    "    best = None\n",
    "\n",
    "    for C in SVM_GRID[\"C\"]:\n",
    "        if TUNE_THRESHOLD_PER_USER:\n",
    "            thr_by_user = {}\n",
    "            per_user_cv_scores = []\n",
    "            all_users_ok = True\n",
    "            users_valid = 0\n",
    "\n",
    "            for uid in users:\n",
    "                tp = per_user[uid][\"train_pool\"]\n",
    "                folds = cv_folds_user(tp)\n",
    "\n",
    "                y_list_u, p_list_u = [], []\n",
    "                for (tr_df, va_df) in folds:\n",
    "                    tr_y = tr_df[\"y_bin\"].astype(int).values\n",
    "                    p, cv_k = svm_fit_predict_proba(tr_df[feature_cols], tr_y, va_df[feature_cols], C=C, cv_max=3)\n",
    "                    if p is None:\n",
    "                        continue\n",
    "                    y_list_u.append(va_df[\"y_bin\"].astype(int).values)\n",
    "                    p_list_u.append(p)\n",
    "\n",
    "                if len(y_list_u) == 0:\n",
    "                    all_users_ok = False\n",
    "                    break\n",
    "\n",
    "                y_u = np.concatenate(y_list_u)\n",
    "                p_u = np.concatenate(p_list_u)\n",
    "                thr_u, f1_u = tune_thr_from_proba(y_u, p_u)\n",
    "                thr_by_user[uid] = float(thr_u)\n",
    "                per_user_cv_scores.append(float(f1_u))\n",
    "                users_valid += 1\n",
    "\n",
    "            if (not all_users_ok) or (users_valid < len(users)):\n",
    "                continue\n",
    "\n",
    "            cv_score = float(np.mean(per_user_cv_scores))\n",
    "            thr_obj = thr_by_user\n",
    "\n",
    "        else:\n",
    "            y_list, p_list = [], []\n",
    "            for uid in users:\n",
    "                tp = per_user[uid][\"train_pool\"]\n",
    "                folds = cv_folds_user(tp)\n",
    "                for (tr_df, va_df) in folds:\n",
    "                    tr_y = tr_df[\"y_bin\"].astype(int).values\n",
    "                    p, cv_k = svm_fit_predict_proba(tr_df[feature_cols], tr_y, va_df[feature_cols], C=C, cv_max=3)\n",
    "                    if p is None:\n",
    "                        continue\n",
    "                    y_list.append(va_df[\"y_bin\"].astype(int).values)\n",
    "                    p_list.append(p)\n",
    "\n",
    "            if len(y_list) == 0:\n",
    "                continue\n",
    "\n",
    "            y_all = np.concatenate(y_list)\n",
    "            p_all = np.concatenate(p_list)\n",
    "            thr_obj, cv_score = tune_thr_from_proba(y_all, p_all)\n",
    "\n",
    "        if (best is None) or (cv_score > best[\"cv_score\"]):\n",
    "            best = {\"C\": float(C), \"thr_obj\": thr_obj, \"cv_score\": float(cv_score)}\n",
    "\n",
    "    if best is None:\n",
    "        print(f\"SKIP_MODEL: {SVM_NAME} (no valid C across all users/folds)\")\n",
    "    else:\n",
    "        # Final training per user (adaptive cv from train_pool)\n",
    "        models_by_user = {}\n",
    "        ok = True\n",
    "        final_cv_by_user = {}\n",
    "\n",
    "        for uid in users:\n",
    "            tp = per_user[uid][\"train_pool\"]\n",
    "            tr_y = tp[\"y_bin\"].astype(int).values\n",
    "            mcc = min_class_count(tr_y)\n",
    "            cv_k = int(min(3, mcc))\n",
    "            if cv_k < 2:\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            base = LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE, C=float(best[\"C\"]))\n",
    "            calib = make_calibrator(base, cv_k=cv_k)\n",
    "            pipe = Pipeline([(\"prep\", preprocess), (\"clf\", calib)])\n",
    "            pipe.fit(tp[feature_cols], tr_y)\n",
    "\n",
    "            models_by_user[uid] = pipe\n",
    "            final_cv_by_user[uid] = cv_k\n",
    "\n",
    "        if not ok:\n",
    "            print(f\"SKIP_MODEL: {SVM_NAME} (final training not feasible for all users)\")\n",
    "        else:\n",
    "            pooled, macro, user_records = eval_personalized_models(models_by_user, best[\"thr_obj\"])\n",
    "            rows.append({\n",
    "                \"model\": SVM_NAME,\n",
    "                \"cv_score\": float(best[\"cv_score\"]),\n",
    "                \"thr_obj\": best[\"thr_obj\"],\n",
    "                \"test_pooled_f1\": float(pooled[\"f1\"]),\n",
    "                \"test_pooled_acc\": float(pooled[\"acc\"]),\n",
    "                \"test_macro_f1\": float(macro[\"f1\"]),\n",
    "                \"test_macro_acc\": float(macro[\"acc\"]),\n",
    "                \"params\": {\"C\": float(best[\"C\"]), \"calibration_cv\": f\"adaptive<=3 (per user), {final_cv_by_user}\"},\n",
    "                \"models_by_user\": models_by_user,\n",
    "                \"test_user_records\": user_records,\n",
    "            })\n",
    "\n",
    "            thr_desc = \"per-user\" if isinstance(best[\"thr_obj\"], dict) else f\"{best['thr_obj']:.2f}\"\n",
    "            print(f\"\\nMODEL: {SVM_NAME}\")\n",
    "            kv(\"CV_SCORE\", best[\"cv_score\"])\n",
    "            kv(\"THRESHOLD\", thr_desc)\n",
    "            kv(\"TEST_POOLED_F1\", pooled[\"f1\"])\n",
    "            kv(\"TEST_POOLED_ACC\", pooled[\"acc\"])\n",
    "            kv(\"TEST_MACRO_F1\", macro[\"f1\"])\n",
    "            kv(\"TEST_MACRO_ACC\", macro[\"acc\"])\n",
    "            kv(\"PARAMS\", {\"C\": best[\"C\"], \"final_cv_by_user\": final_cv_by_user})\n",
    "else:\n",
    "    print(f\"SKIP_MODEL: {SVM_NAME} (some user train_pool has single class)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef59bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINES:\n",
      "  Baseline-Persist | TEST pooled: acc=0.8000, f1=0.8776 | macro(user): acc=0.8000, f1=0.8602\n",
      "  Baseline-Markov  | CV pooled: f1=0.9189, thr=0.05 | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919\n",
      "\n",
      "CANDIDATES:\n",
      "  LogReg                     | CV=0.9123 | thr=per-user | TEST pooled: acc=0.8333, f1=0.9057 | macro(user): acc=0.8333, f1=0.8946 | params={'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "  AdaBoost                   | CV=0.9298 | thr=per-user | TEST pooled: acc=0.8333, f1=0.9038 | macro(user): acc=0.8333, f1=0.8874 | params={'clf__learning_rate': 0.03, 'clf__n_estimators': 50}\n",
      "  DecisionTree               | CV=0.8986 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919 | params={'clf__max_depth': 2, 'clf__min_samples_leaf': 8}\n",
      "  HistGB                     | CV=0.8986 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "  GradBoost                  | CV=0.8948 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__n_estimators': 100}\n",
      "  BaggingTree                | CV=0.9298 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8932 | macro(user): acc=0.8167, f1=0.8676 | params={'clf__estimator__max_depth': 2, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 100}\n",
      "  RandomForest               | CV=0.9298 | thr=per-user | TEST pooled: acc=0.8000, f1=0.8846 | macro(user): acc=0.8000, f1=0.8588 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "  ExtraTrees                 | CV=0.9241 | thr=per-user | TEST pooled: acc=0.8000, f1=0.8846 | macro(user): acc=0.8000, f1=0.8588 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 200}\n",
      "  LinearSVC_Calibrated_SAFE  | CV=0.9235 | thr=per-user | TEST pooled: acc=0.7833, f1=0.8660 | macro(user): acc=0.7833, f1=0.7446 | params={'C': 1.0, 'calibration_cv': 'adaptive<=3 (per user), {1: 3, 2: 3, 3: 3, 4: 3, 5: 3}'}\n",
      "\n",
      "SELECTED_BEST: LogReg\n",
      "\n",
      "PER-USER (SELECTED_BEST=LogReg) on TEST:\n",
      "uid=1 | n=12  | dist={0: 1, 1: 11} | acc=0.9167 | f1=0.9565 | thr=0.05\n",
      "uid=2 | n=12  | dist={0: 3, 1: 9} | acc=0.7500 | f1=0.8571 | thr=0.05\n",
      "uid=3 | n=12  | dist={0: 5, 1: 7} | acc=0.6667 | f1=0.7500 | thr=0.50\n",
      "uid=4 | n=12  | dist={0: 0, 1: 12} | acc=1.0000 | f1=1.0000 | thr=0.05\n",
      "uid=5 | n=12  | dist={0: 2, 1: 10} | acc=0.8333 | f1=0.9091 | thr=0.05\n"
     ]
    }
   ],
   "source": [
    "# LEADERBOARD + SELECT BEST (VS MARKOV)\n",
    "print(\"BASELINES:\")\n",
    "print(\n",
    "    f\"  Baseline-Persist | TEST pooled: acc={persist_pooled['acc']:.4f}, f1={persist_pooled['f1']:.4f} | \"\n",
    "    f\"macro(user): acc={persist_macro_acc:.4f}, f1={persist_macro_f1:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Baseline-Markov  | CV pooled: f1={cv_f1_mk:.4f}, thr={thr_mk:.2f} | \"\n",
    "    f\"TEST pooled: acc={markov_pooled['acc']:.4f}, f1={markov_pooled['f1']:.4f} | \"\n",
    "    f\"macro(user): acc={markov_macro_acc:.4f}, f1={markov_macro_f1:.4f}\"\n",
    ")\n",
    "\n",
    "rows_sorted = sorted(rows, key=lambda r: r[\"test_pooled_f1\"], reverse=True)\n",
    "\n",
    "print(\"\\nCANDIDATES:\")\n",
    "if len(rows_sorted) == 0:\n",
    "    print(\"  (no ML candidates succeeded)\")\n",
    "else:\n",
    "    for r in rows_sorted:\n",
    "        thr_desc = \"per-user\" if isinstance(r[\"thr_obj\"], dict) else f\"{r['thr_obj']:.2f}\"\n",
    "        print(\n",
    "            f\"  {r['model']:<26} | CV={r['cv_score']:.4f} | thr={thr_desc:<8} | \"\n",
    "            f\"TEST pooled: acc={r['test_pooled_acc']:.4f}, f1={r['test_pooled_f1']:.4f} | \"\n",
    "            f\"macro(user): acc={r['test_macro_acc']:.4f}, f1={r['test_macro_f1']:.4f} | params={r['params']}\"\n",
    "        )\n",
    "\n",
    "best_name = \"MarkovUser\"\n",
    "best_obj = {\"type\": \"markov_user\", \"thr\": float(thr_mk), \"probs_by_user\": mk_models}\n",
    "best_test_pooled_f1 = float(markov_pooled[\"f1\"])\n",
    "best_user_records = markov_user_records\n",
    "best_thr_info = thr_mk\n",
    "\n",
    "if len(rows_sorted) > 0 and float(rows_sorted[0][\"test_pooled_f1\"]) > best_test_pooled_f1:\n",
    "    top = rows_sorted[0]\n",
    "    best_name = top[\"model\"]\n",
    "    best_obj = {\n",
    "        \"type\": \"personalized_sklearn\",\n",
    "        \"models_by_user\": top[\"models_by_user\"],\n",
    "        \"thr\": top[\"thr_obj\"],\n",
    "        \"meta\": {\"tune_threshold_per_user\": bool(TUNE_THRESHOLD_PER_USER)},\n",
    "    }\n",
    "    best_user_records = top[\"test_user_records\"]\n",
    "    best_thr_info = top[\"thr_obj\"]\n",
    "\n",
    "print(\"\\nSELECTED_BEST:\", best_name)\n",
    "if best_name == \"MarkovUser\":\n",
    "    print(\"SELECT_REASON: Markov baseline remains best on TEST pooled F1 for this dataset.\")\n",
    "\n",
    "if PRINT_PER_USER_DETAILS:\n",
    "    print_per_user_breakdown(f\"PER-USER (SELECTED_BEST={best_name}) on TEST:\", best_user_records, thr_info=best_thr_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab36d6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED_TO            : ..\\models\\personalized_forecast.joblib\n",
      "BEST_NAME           : LogReg\n"
     ]
    }
   ],
   "source": [
    "# SAVE ARTIFACT\n",
    "MODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"best_name\": best_name,\n",
    "        \"artifact\": best_obj,\n",
    "        \"meta\": {\n",
    "            \"target\": \"y_bin = (stressLevel>=1)\",\n",
    "            \"date_col\": DATE_COL,\n",
    "            \"user_col\": USER_COL,\n",
    "            \"target_col\": TARGET_COL,\n",
    "            \"window\": WINDOW,\n",
    "            \"test_len\": TEST_LEN,\n",
    "            \"val_windows\": VAL_WINDOWS,\n",
    "            \"thresholds\": THRESHOLDS.tolist(),\n",
    "            \"users\": users,\n",
    "            \"baseline_l1\": \"persistence(per-user)\",\n",
    "            \"baseline_l2\": \"markov_user(prev_high, dow)\",\n",
    "            \"use_user_id_feature\": USE_USER_ID_FEATURE,\n",
    "            \"tune_threshold_per_user\": TUNE_THRESHOLD_PER_USER,\n",
    "            \"random_state\": RANDOM_STATE,\n",
    "            \"feature_cols\": feature_cols,\n",
    "        }\n",
    "    },\n",
    "    MODEL_OUT\n",
    ")\n",
    "\n",
    "kv(\"SAVED_TO\", str(MODEL_OUT))\n",
    "kv(\"BEST_NAME\", best_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Model\n",
    "\n",
    "Bagian ini menjalankan inference menggunakan artifact yang sudah tersimpan, tanpa menjalankan proses training ulang.\n",
    "\n",
    "Output menampilkan prediksi untuk baris terbaru per user (setelah fitur history tersedia).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be0fa18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTIFACT_PATH: ..\\models\\personalized_forecast.joblib\n",
      "ARTIFACT_TYPE: personalized_sklearn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>date</th>\n",
       "      <th>y_true</th>\n",
       "      <th>p</th>\n",
       "      <th>pred</th>\n",
       "      <th>thr</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745165</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID       date  y_true         p  pred   thr            model_type\n",
       "0       1 2026-01-19       1  0.700946     1  0.05  personalized_sklearn\n",
       "1       2 2026-01-19       1  0.716169     1  0.05  personalized_sklearn\n",
       "2       3 2026-01-19       1  0.700946     1  0.50  personalized_sklearn\n",
       "3       4 2026-01-19       1  0.830487     1  0.05  personalized_sklearn\n",
       "4       5 2026-01-19       1  0.745165     1  0.05  personalized_sklearn"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS (SAMPLE: last row per user)\n",
      "ACC: 1.0\n",
      "F1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# TRY MODEL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Config\n",
    "# -----------------------------------------------------------------------------\n",
    "ARTIFACT_PATH = Path(\"../models/personalized_forecast.joblib\")\n",
    "DATA_PATH = Path(\"../datasets/stress_forecast.csv\")\n",
    "\n",
    "DATE_COL = \"date\"\n",
    "USER_COL = \"userID\"\n",
    "TARGET_COL = \"stressLevel\"  # 0..2\n",
    "\n",
    "WINDOW = 3\n",
    "\n",
    "if not ARTIFACT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Artifact not found: {ARTIFACT_PATH}\")\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATA_PATH}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load artifact\n",
    "# -----------------------------------------------------------------------------\n",
    "bundle = joblib.load(ARTIFACT_PATH)\n",
    "artifact = bundle.get(\"artifact\", bundle)\n",
    "meta = bundle.get(\"meta\", {})\n",
    "\n",
    "use_user_id_feature = bool(meta.get(\"use_user_id_feature\", False))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load data\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "for required_col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if required_col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{required_col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "if not df[TARGET_COL].dropna().between(0, 2).all():\n",
    "    raise ValueError(f\"'{TARGET_COL}' must be within range 0..2\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Feature engineering (no leakage)\n",
    "# -----------------------------------------------------------------------------\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "feature_cols = (\n",
    "    [\"dow\", \"is_weekend\"]\n",
    "    + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "    + [\n",
    "        \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "        \"count_high\", \"count_low\",\n",
    "        \"streak_high\", \"transitions\",\n",
    "    ]\n",
    ")\n",
    "if use_user_id_feature:\n",
    "    feature_cols = [USER_COL] + feature_cols\n",
    "\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "\n",
    "# Latest engineered row per user\n",
    "sample_df = (\n",
    "    feat.sort_values([USER_COL, DATE_COL])\n",
    "        .groupby(USER_COL, as_index=False)\n",
    "        .tail(1)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Inference helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "def markov_proba_user(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_eval[\"dow\"].astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run inference (supports markov_user and personalized_sklearn)\n",
    "# -----------------------------------------------------------------------------\n",
    "art_type = artifact.get(\"type\", \"\")\n",
    "\n",
    "out_rows = []\n",
    "if art_type == \"markov_user\":\n",
    "    thr = artifact[\"thr\"]\n",
    "    probs_by_user = artifact[\"probs_by_user\"]\n",
    "\n",
    "    for _, r in sample_df.iterrows():\n",
    "        uid = r[USER_COL]\n",
    "        probs = probs_by_user.get(uid)\n",
    "        if probs is None:\n",
    "            continue\n",
    "\n",
    "        p = markov_proba_user(probs, pd.DataFrame([r]))[0]\n",
    "        pred = int(p >= float(thr))\n",
    "\n",
    "        out_rows.append({\n",
    "            \"userID\": uid,\n",
    "            \"date\": r[DATE_COL],\n",
    "            \"y_true\": int(r[\"y_bin\"]),\n",
    "            \"p\": float(p),\n",
    "            \"pred\": int(pred),\n",
    "            \"model_type\": art_type,\n",
    "        })\n",
    "\n",
    "elif art_type == \"personalized_sklearn\":\n",
    "    models_by_user = artifact[\"models_by_user\"]\n",
    "    thr_obj = artifact.get(\"thr\")\n",
    "\n",
    "    for _, r in sample_df.iterrows():\n",
    "        uid = r[USER_COL]\n",
    "        pipe = models_by_user.get(uid)\n",
    "        if pipe is None:\n",
    "            continue\n",
    "\n",
    "        X = pd.DataFrame([r])[feature_cols]\n",
    "        p = float(pipe.predict_proba(X)[:, 1][0])\n",
    "\n",
    "        thr = thr_obj.get(uid) if isinstance(thr_obj, dict) else float(thr_obj)\n",
    "        pred = int(p >= float(thr))\n",
    "\n",
    "        out_rows.append({\n",
    "            \"userID\": uid,\n",
    "            \"date\": r[DATE_COL],\n",
    "            \"y_true\": int(r[\"y_bin\"]),\n",
    "            \"p\": float(p),\n",
    "            \"pred\": int(pred),\n",
    "            \"thr\": float(thr),\n",
    "            \"model_type\": art_type,\n",
    "        })\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported artifact type: {art_type}\")\n",
    "\n",
    "out = pd.DataFrame(out_rows).sort_values([\"userID\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"ARTIFACT_PATH:\", str(ARTIFACT_PATH))\n",
    "print(\"ARTIFACT_TYPE:\", art_type)\n",
    "\n",
    "display(out)\n",
    "\n",
    "if len(out) > 0:\n",
    "    acc = float((out[\"pred\"].values == out[\"y_true\"].values).mean())\n",
    "    f1  = float(f1_score(out[\"y_true\"].values, out[\"pred\"].values, zero_division=0))\n",
    "    print(\"\\nMETRICS (SAMPLE: last row per user)\")\n",
    "    print(\"ACC:\", acc)\n",
    "    print(\"F1 :\", f1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
