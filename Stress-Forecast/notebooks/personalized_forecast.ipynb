{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c768a0e",
   "metadata": {},
   "source": [
    "# Imports and Setup\n",
    "\n",
    "Bagian ini memuat:\n",
    "- Import library utama\n",
    "- Konfigurasi untuk **PERSONALIZED forecasting** (1 model per user)\n",
    "- Utility untuk evaluasi, tuning threshold, dan ringkasan per-user\n",
    "\n",
    "- Semua nama kolom kini snake_case (mis. `user_id`, `stress_level`, `created_at`, `study_hour_per_day`).\n",
    "- Kolom `is_restored` adalah metadata input/restore dan **tidak** dipakai sebagai fitur model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c34505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, ExtraTreesClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    GradientBoostingClassifier, AdaBoostClassifier,\n",
    "    BaggingClassifier\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# =============================================================================\n",
    "# 0) CONFIG\n",
    "# =============================================================================\n",
    "CANDIDATE_PATHS = [\n",
    "    Path(\"../datasets/stress_forecast.csv\"),\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"stress_forecast.csv not found. Check CANDIDATE_PATHS / DATA_PATH.\")\n",
    "\n",
    "MODEL_OUT = Path(\"../models/personalized_forecast.joblib\")\n",
    "\n",
    "DATE_COL   = \"date\"\n",
    "USER_COL   = \"user_id\"\n",
    "TARGET_COL = \"stress_level\"  # 0..2\n",
    "\n",
    "WINDOW   = 3\n",
    "TEST_LEN = 12\n",
    "\n",
    "VAL_WINDOWS = [(10, 20), (15, 25)]\n",
    "THRESHOLDS  = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "RANDOM_STATE = 26\n",
    "\n",
    "# Personalized: default = False (no semi-global/global)\n",
    "USE_USER_ID_FEATURE = False\n",
    "\n",
    "# Threshold tuning:\n",
    "# - True  => tune threshold per user (fair: uses only that user's CV folds)\n",
    "# - False => tune one global threshold pooled across users\n",
    "TUNE_THRESHOLD_PER_USER = True\n",
    "\n",
    "# Print per-user details for baselines and selected best model\n",
    "PRINT_PER_USER_DETAILS = True\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Print helpers\n",
    "# =============================================================================\n",
    "def kv(k, v):\n",
    "    print(f\"{k:<20}: {v}\")\n",
    "\n",
    "def safe_class_counts(y):\n",
    "    y = np.asarray(y).astype(int)\n",
    "    return {0: int((y == 0).sum()), 1: int((y == 1).sum())}\n",
    "\n",
    "def print_per_user_breakdown(title, per_user_records, thr_info=None):\n",
    "    print(f\"\\n{title}\")\n",
    "    for r in per_user_records:\n",
    "        uid = r[\"uid\"]\n",
    "        y = np.asarray(r[\"y\"]).astype(int)\n",
    "        pred = np.asarray(r[\"pred\"]).astype(int)\n",
    "        acc = float(accuracy_score(y, pred))\n",
    "        f1  = float(f1_score(y, pred, zero_division=0))\n",
    "        dist = safe_class_counts(y)\n",
    "\n",
    "        extra = \"\"\n",
    "        if thr_info is not None:\n",
    "            if isinstance(thr_info, dict) and uid in thr_info:\n",
    "                extra = f\" | thr={float(thr_info[uid]):.2f}\"\n",
    "            elif isinstance(thr_info, (float, int)):\n",
    "                extra = f\" | thr={float(thr_info):.2f}\"\n",
    "\n",
    "        print(f\"uid={uid} | n={len(y):<3} | dist={dist} | acc={acc:.4f} | f1={f1:.4f}{extra}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Core helpers\n",
    "# =============================================================================\n",
    "def eval_bin(y_true, y_pred):\n",
    "    return {\n",
    "        \"acc\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"f1\":  float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "    }\n",
    "\n",
    "def tune_thr_from_proba(y_true, p_high, thresholds=THRESHOLDS):\n",
    "    best_thr, best_f1 = None, -1.0\n",
    "    for thr in thresholds:\n",
    "        pred = (p_high >= thr).astype(int)\n",
    "        f1 = float(f1_score(y_true, pred, zero_division=0))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = f1, thr\n",
    "    return float(best_thr), float(best_f1)\n",
    "\n",
    "def per_user_macro_metrics(per_user_records):\n",
    "    accs, f1s = [], []\n",
    "    for r in per_user_records:\n",
    "        accs.append(accuracy_score(r[\"y\"], r[\"pred\"]))\n",
    "        f1s.append(f1_score(r[\"y\"], r[\"pred\"], zero_division=0))\n",
    "    return float(np.mean(accs)), float(np.mean(f1s))\n",
    "\n",
    "def cv_folds_user(tp_df):\n",
    "    folds = []\n",
    "    for (v0, v1) in VAL_WINDOWS:\n",
    "        if len(tp_df) < v1:\n",
    "            continue\n",
    "        tr = tp_df.iloc[:v0].copy()\n",
    "        va = tp_df.iloc[v0:v1].copy()\n",
    "        folds.append((tr, va))\n",
    "    return folds\n",
    "\n",
    "def min_class_count(y):\n",
    "    vc = pd.Series(np.asarray(y)).value_counts()\n",
    "    if len(vc) < 2:\n",
    "        return 0\n",
    "    return int(vc.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598dc2a3",
   "metadata": {},
   "source": [
    "# Load and Explore Dataset\n",
    "\n",
    "Bagian ini mencakup:\n",
    "- Load dataset\n",
    "- Validasi kolom wajib\n",
    "- Parsing `date` dan sorting time-series per user\n",
    "- Validasi range target `stress_level` (0–2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bc3f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH           : ..\\datasets\\stress_forecast.csv\n",
      "ROWS_RAW            : 300\n",
      "USERS_RAW           : 5\n",
      "DATE_RANGE_RAW      : 2025-11-21 -> 2026-01-19\n",
      "\n",
      "HEAD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stress_level_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>gpa</th>\n",
       "      <th>extracurricular_hour_per_day</th>\n",
       "      <th>physical_activity_hour_per_day</th>\n",
       "      <th>sleep_hour_per_day</th>\n",
       "      <th>study_hour_per_day</th>\n",
       "      <th>social_hour_per_day</th>\n",
       "      <th>emoji</th>\n",
       "      <th>is_restored</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-21 21:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-22 20:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-23 22:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-24 19:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-11-25 21:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stress_level_id  user_id       date  stress_level   gpa  \\\n",
       "0                2        1 2025-11-21             1  3.82   \n",
       "1                7        1 2025-11-22             0  3.82   \n",
       "2               12        1 2025-11-23             0  3.82   \n",
       "3               17        1 2025-11-24             1  3.82   \n",
       "4               22        1 2025-11-25             1  3.82   \n",
       "\n",
       "   extracurricular_hour_per_day  physical_activity_hour_per_day  \\\n",
       "0                           0.0                             0.5   \n",
       "1                           0.0                             1.0   \n",
       "2                           0.0                             3.0   \n",
       "3                           0.0                             0.5   \n",
       "4                           0.0                             1.0   \n",
       "\n",
       "   sleep_hour_per_day  study_hour_per_day  social_hour_per_day  emoji  \\\n",
       "0                 7.0                 7.0                  2.0      1   \n",
       "1                 9.0                 2.0                  5.0      2   \n",
       "2                 9.0                 1.0                  6.0      1   \n",
       "3                 8.0                 7.0                  5.0      3   \n",
       "4                 7.0                 7.0                  4.0      3   \n",
       "\n",
       "   is_restored           created_at  \n",
       "0            0  2025-11-21 21:12:00  \n",
       "1            0  2025-11-22 20:07:00  \n",
       "2            0  2025-11-23 22:18:00  \n",
       "3            0  2025-11-24 19:55:00  \n",
       "4            0  2025-11-25 21:40:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if \"is_restored\" not in df.columns:\n",
    "    df[\"is_restored\"] = 0\n",
    "df[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\n",
    "\n",
    "for required_col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if required_col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{required_col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "if not df[TARGET_COL].dropna().between(0, 2).all():\n",
    "    raise ValueError(f\"'{TARGET_COL}' must be within range 0..2\")\n",
    "\n",
    "kv(\"DATA_PATH\", str(DATA_PATH))\n",
    "kv(\"ROWS_RAW\", len(df))\n",
    "kv(\"USERS_RAW\", df[USER_COL].nunique())\n",
    "kv(\"DATE_RANGE_RAW\", f\"{df[DATE_COL].min().date()} -> {df[DATE_COL].max().date()}\")\n",
    "\n",
    "print(\"\\nHEAD:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99836397",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Ringkasan cepat:\n",
    "- Distribusi `stress_level` (0–2)\n",
    "- Jumlah baris per user (indikasi kecukupan data untuk split & CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10509d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_DIST_0_2     : {0: 124, 1: 91, 2: 85}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_PER_USER       : {1: 60, 2: 60, 3: 60, 4: 60, 5: 60}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# EDA: target distribution (0..2)\n",
    "target_counts = df[TARGET_COL].value_counts().sort_index()\n",
    "kv(\"TARGET_DIST_0_2\", target_counts.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "target_counts.plot(kind=\"bar\")\n",
    "plt.title(f\"Distribution of {TARGET_COL} (0..2)\")\n",
    "plt.xlabel(TARGET_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "# EDA: rows per user\n",
    "rows_per_user = df[USER_COL].value_counts().sort_index()\n",
    "kv(\"ROWS_PER_USER\", rows_per_user.to_dict())\n",
    "\n",
    "plt.figure()\n",
    "rows_per_user.plot(kind=\"bar\")\n",
    "plt.title(\"Rows per user\")\n",
    "plt.xlabel(USER_COL)\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21e8fa",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Bagian ini melakukan **feature engineering tanpa leakage**:\n",
    "- Fitur kalender: `dow`, `is_weekend`\n",
    "- Fitur lag target: `lag_sp_1..lag_sp_WINDOW`\n",
    "- Rolling stats dari history yang berakhir di `t-1`\n",
    "\n",
    "Transformasi label:\n",
    "- `y_bin = 1` jika `stress_level >= 1`\n",
    "- `y_bin = 0` jika `stress_level == 0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6b8eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROWS_FEAT           : 285\n",
      "USERS               : [1, 2, 3, 4, 5]\n",
      "DATE_RANGE_FEAT     : 2025-11-24 -> 2026-01-19\n",
      "WINDOW              : 3\n",
      "TEST_LEN            : 12\n",
      "FEATURES_COUNT      : 13\n",
      "USE_USER_ID_FEATURE : False\n",
      "BINARY_DIST         : {1: 171, 0: 114}\n",
      "VAL_WINDOWS         : [(10, 20), (15, 25)]\n",
      "TUNE_THRESHOLD_PER_USER: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>y_bin</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_sp_1</th>\n",
       "      <th>lag_sp_2</th>\n",
       "      <th>lag_sp_3</th>\n",
       "      <th>sp_mean</th>\n",
       "      <th>sp_std</th>\n",
       "      <th>sp_min</th>\n",
       "      <th>sp_max</th>\n",
       "      <th>count_high</th>\n",
       "      <th>count_low</th>\n",
       "      <th>streak_high</th>\n",
       "      <th>transitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       date  stress_level  y_bin  dow  is_weekend  lag_sp_1  \\\n",
       "0        1 2025-11-24             1      1    0           0       0.0   \n",
       "1        1 2025-11-25             1      1    1           0       1.0   \n",
       "2        1 2025-11-26             1      1    2           0       1.0   \n",
       "3        1 2025-11-27             1      1    3           0       1.0   \n",
       "4        1 2025-11-28             1      1    4           0       1.0   \n",
       "\n",
       "   lag_sp_2  lag_sp_3   sp_mean   sp_std  sp_min  sp_max  count_high  \\\n",
       "0       0.0       1.0  0.333333  0.57735     0.0     1.0         1.0   \n",
       "1       0.0       0.0  0.333333  0.57735     0.0     1.0         1.0   \n",
       "2       1.0       0.0  0.666667  0.57735     0.0     1.0         2.0   \n",
       "3       1.0       1.0  1.000000  0.00000     1.0     1.0         3.0   \n",
       "4       1.0       1.0  1.000000  0.00000     1.0     1.0         3.0   \n",
       "\n",
       "   count_low  streak_high  transitions  \n",
       "0        2.0            0          2.0  \n",
       "1        2.0            1          2.0  \n",
       "2        1.0            2          1.0  \n",
       "3        0.0            3          1.0  \n",
       "4        0.0            4          0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FEATURE ENGINEERING (NO-LEAK)\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# Binary labeling: y_bin = 1 if pred>=1 else 0\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "feature_cols = (\n",
    "    [\"dow\", \"is_weekend\"]\n",
    "    + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "    + [\n",
    "        \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "        \"count_high\", \"count_low\",\n",
    "        \"streak_high\", \"transitions\",\n",
    "    ]\n",
    ")\n",
    "if USE_USER_ID_FEATURE:\n",
    "    feature_cols = [USER_COL] + feature_cols\n",
    "\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "users = sorted(feat[USER_COL].unique().tolist())\n",
    "\n",
    "kv(\"ROWS_FEAT\", len(feat))\n",
    "kv(\"USERS\", users)\n",
    "kv(\"DATE_RANGE_FEAT\", f\"{feat[DATE_COL].min().date()} -> {feat[DATE_COL].max().date()}\")\n",
    "kv(\"WINDOW\", WINDOW)\n",
    "kv(\"TEST_LEN\", TEST_LEN)\n",
    "kv(\"FEATURES_COUNT\", len(feature_cols))\n",
    "kv(\"USE_USER_ID_FEATURE\", USE_USER_ID_FEATURE)\n",
    "kv(\"BINARY_DIST\", feat[\"y_bin\"].value_counts().to_dict())\n",
    "kv(\"VAL_WINDOWS\", VAL_WINDOWS)\n",
    "kv(\"TUNE_THRESHOLD_PER_USER\", TUNE_THRESHOLD_PER_USER)\n",
    "\n",
    "display(feat[[USER_COL, DATE_COL, TARGET_COL, \"y_bin\"] + feature_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bd733",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "Cakupan bagian ini:\n",
    "- Split time-based per user (TEST = last `TEST_LEN`)\n",
    "- Baseline L1: Persistence\n",
    "- Baseline L2: Markov per-user + threshold tuning (pooled CV)\n",
    "- Kandidat model ML per user (tanpa user_id sebagai fitur)\n",
    "- SVM calibrated dengan cv adaptif (SAFE)\n",
    "- Leaderboard + seleksi model terbaik vs baseline\n",
    "- Simpan artifact ke file `.joblib`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0777bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_TRAINPOOL     : 225\n",
      "TOTAL_TEST          : 60\n",
      "\n",
      "PER_USER_SPLIT:\n",
      "uid=1 | total=57 | train_pool=45 dist={0: 20, 1: 25} | test=12 dist={0: 1, 1: 11}\n",
      "uid=2 | total=57 | train_pool=45 dist={0: 19, 1: 26} | test=12 dist={0: 3, 1: 9}\n",
      "uid=3 | total=57 | train_pool=45 dist={0: 27, 1: 18} | test=12 dist={0: 5, 1: 7}\n",
      "uid=4 | total=57 | train_pool=45 dist={0: 17, 1: 28} | test=12 dist={0: 0, 1: 12}\n",
      "uid=5 | total=57 | train_pool=45 dist={0: 20, 1: 25} | test=12 dist={0: 2, 1: 10}\n"
     ]
    }
   ],
   "source": [
    "# SPLIT PER USER (TIME-BASED)\n",
    "per_user = {}\n",
    "split_rows = []\n",
    "\n",
    "for uid in users:\n",
    "    g = feat[feat[USER_COL] == uid].sort_values(DATE_COL).reset_index(drop=True)\n",
    "    n = len(g)\n",
    "    test_start = n - TEST_LEN\n",
    "    if test_start <= 10:\n",
    "        raise ValueError(f\"User {uid}: insufficient rows for split (n={n}, TEST_LEN={TEST_LEN}).\")\n",
    "\n",
    "    tp = g.iloc[:test_start].copy()\n",
    "    te = g.iloc[test_start:].copy()\n",
    "\n",
    "    per_user[uid] = {\"train_pool\": tp, \"test\": te}\n",
    "\n",
    "    split_rows.append({\n",
    "        \"uid\": uid,\n",
    "        \"n_total\": n,\n",
    "        \"n_train_pool\": len(tp),\n",
    "        \"n_test\": len(te),\n",
    "        \"train_pool_dist\": safe_class_counts(tp[\"y_bin\"].values),\n",
    "        \"test_dist\": safe_class_counts(te[\"y_bin\"].values),\n",
    "    })\n",
    "\n",
    "kv(\"TOTAL_TRAINPOOL\", sum(r[\"n_train_pool\"] for r in split_rows))\n",
    "kv(\"TOTAL_TEST\", sum(r[\"n_test\"] for r in split_rows))\n",
    "\n",
    "print(\"\\nPER_USER_SPLIT:\")\n",
    "for r in split_rows:\n",
    "    print(\n",
    "        f\"uid={r['uid']} | total={r['n_total']} | train_pool={r['n_train_pool']} dist={r['train_pool_dist']} \"\n",
    "        f\"| test={r['n_test']} dist={r['test_dist']}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc6a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_POOLED_ACC     : 0.8\n",
      "TEST_POOLED_F1      : 0.8775510204081632\n",
      "TEST_MACRO_ACC      : 0.8\n",
      "TEST_MACRO_F1       : 0.8602308802308803\n",
      "\n",
      "PER-USER (Persistence) on TEST:\n",
      "uid=1 | n=12  | dist={0: 1, 1: 11} | acc=0.8333 | f1=0.9091\n",
      "uid=2 | n=12  | dist={0: 3, 1: 9} | acc=0.6667 | f1=0.7778\n",
      "uid=3 | n=12  | dist={0: 5, 1: 7} | acc=0.6667 | f1=0.7143\n",
      "uid=4 | n=12  | dist={0: 0, 1: 12} | acc=1.0000 | f1=1.0000\n",
      "uid=5 | n=12  | dist={0: 2, 1: 10} | acc=0.8333 | f1=0.9000\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L1: PERSISTENCE (PER USER)\n",
    "persist_user_records = []\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "for uid in users:\n",
    "    te = per_user[uid][\"test\"]\n",
    "    y = te[\"y_bin\"].astype(int).values\n",
    "    pred = (te[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "\n",
    "    persist_user_records.append({\"uid\": uid, \"y\": y, \"pred\": pred})\n",
    "    all_true.append(y)\n",
    "    all_pred.append(pred)\n",
    "\n",
    "y_all = np.concatenate(all_true)\n",
    "pred_all = np.concatenate(all_pred)\n",
    "\n",
    "persist_pooled = eval_bin(y_all, pred_all)\n",
    "persist_macro_acc, persist_macro_f1 = per_user_macro_metrics(persist_user_records)\n",
    "\n",
    "kv(\"TEST_POOLED_ACC\", persist_pooled[\"acc\"])\n",
    "kv(\"TEST_POOLED_F1\", persist_pooled[\"f1\"])\n",
    "kv(\"TEST_MACRO_ACC\", persist_macro_acc)\n",
    "kv(\"TEST_MACRO_F1\", persist_macro_f1)\n",
    "\n",
    "if PRINT_PER_USER_DETAILS:\n",
    "    print_per_user_breakdown(\"PER-USER (Persistence) on TEST:\", persist_user_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cca866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_FOLDS_TOTAL      : 10\n",
      "CV_POOLED_DIST      : {0: 15, 1: 85}\n",
      "BEST_THR_MARKOV     : 0.05\n",
      "CV_POOLED_F1        : 0.918918918918919\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "\n",
      "PER-USER (Markov) on TEST:\n",
      "uid=1 | n=12  | dist={0: 1, 1: 11} | acc=0.9167 | f1=0.9565 | thr=0.05\n",
      "uid=2 | n=12  | dist={0: 3, 1: 9} | acc=0.7500 | f1=0.8571 | thr=0.05\n",
      "uid=3 | n=12  | dist={0: 5, 1: 7} | acc=0.5833 | f1=0.7368 | thr=0.05\n",
      "uid=4 | n=12  | dist={0: 0, 1: 12} | acc=1.0000 | f1=1.0000 | thr=0.05\n",
      "uid=5 | n=12  | dist={0: 2, 1: 10} | acc=0.8333 | f1=0.9091 | thr=0.05\n"
     ]
    }
   ],
   "source": [
    "# BASELINE L2: MARKOV PER USER (prev_high, dow) + THRESHOLD TUNING\n",
    "def train_markov_one_user(df_train):\n",
    "    counts = np.zeros((2, 7, 2), dtype=int)  # prev(2) x dow(7) x y(2)\n",
    "    prev = (df_train[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = (df_train[\"dow\"]).astype(int).values\n",
    "    yb   = (df_train[\"y_bin\"]).astype(int).values\n",
    "    for p, d, y in zip(prev, dow, yb):\n",
    "        counts[p, d, y] += 1\n",
    "    probs = (counts + 1) / (counts.sum(axis=2, keepdims=True) + 2)  # Laplace smoothing\n",
    "    return probs\n",
    "\n",
    "def markov_proba_user(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = (df_eval[\"dow\"]).astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "# Pooled CV threshold tuning (fair: uses only train_pool folds)\n",
    "cv_true, cv_phigh = [], []\n",
    "cv_fold_stats = []\n",
    "\n",
    "for uid in users:\n",
    "    tp = per_user[uid][\"train_pool\"]\n",
    "    folds = cv_folds_user(tp)\n",
    "    for (tr_df, va_df) in folds:\n",
    "        probs = train_markov_one_user(tr_df)\n",
    "        p = markov_proba_user(probs, va_df)\n",
    "        cv_true.append(va_df[\"y_bin\"].astype(int).values)\n",
    "        cv_phigh.append(p)\n",
    "        cv_fold_stats.append({\"uid\": uid, \"tr_len\": len(tr_df), \"va_len\": len(va_df)})\n",
    "\n",
    "if len(cv_true) == 0:\n",
    "    raise ValueError(\"No valid CV folds. Reduce VAL_WINDOWS / TEST_LEN / WINDOW.\")\n",
    "\n",
    "cv_true = np.concatenate(cv_true)\n",
    "cv_phigh = np.concatenate(cv_phigh)\n",
    "\n",
    "thr_mk, cv_f1_mk = tune_thr_from_proba(cv_true, cv_phigh)\n",
    "\n",
    "mk_models = {}\n",
    "markov_user_records = []\n",
    "all_true, all_pred = [], []\n",
    "\n",
    "for uid in users:\n",
    "    tp = per_user[uid][\"train_pool\"]\n",
    "    te = per_user[uid][\"test\"]\n",
    "\n",
    "    probs = train_markov_one_user(tp)\n",
    "    mk_models[uid] = probs\n",
    "\n",
    "    p = markov_proba_user(probs, te)\n",
    "    pred = (p >= thr_mk).astype(int)\n",
    "    y = te[\"y_bin\"].astype(int).values\n",
    "\n",
    "    markov_user_records.append({\"uid\": uid, \"y\": y, \"pred\": pred})\n",
    "    all_true.append(y)\n",
    "    all_pred.append(pred)\n",
    "\n",
    "y_all = np.concatenate(all_true)\n",
    "pred_all = np.concatenate(all_pred)\n",
    "\n",
    "markov_pooled = eval_bin(y_all, pred_all)\n",
    "markov_macro_acc, markov_macro_f1 = per_user_macro_metrics(markov_user_records)\n",
    "\n",
    "kv(\"CV_FOLDS_TOTAL\", len(cv_fold_stats))\n",
    "kv(\"CV_POOLED_DIST\", safe_class_counts(cv_true))\n",
    "kv(\"BEST_THR_MARKOV\", thr_mk)\n",
    "kv(\"CV_POOLED_F1\", cv_f1_mk)\n",
    "kv(\"TEST_POOLED_ACC\", markov_pooled[\"acc\"])\n",
    "kv(\"TEST_POOLED_F1\", markov_pooled[\"f1\"])\n",
    "kv(\"TEST_MACRO_ACC\", markov_macro_acc)\n",
    "kv(\"TEST_MACRO_F1\", markov_macro_f1)\n",
    "\n",
    "if PRINT_PER_USER_DETAILS:\n",
    "    print_per_user_breakdown(\"PER-USER (Markov) on TEST:\", markov_user_records, thr_info=thr_mk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b0257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_COLS            : ['dow', 'is_weekend']\n",
      "NUM_COLS_COUNT      : 11\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS (FOR ML)\n",
    "cat_cols = [\"dow\", \"is_weekend\"]\n",
    "if USE_USER_ID_FEATURE:\n",
    "    cat_cols = [USER_COL] + cat_cols\n",
    "\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "kv(\"CAT_COLS\", cat_cols)\n",
    "kv(\"NUM_COLS_COUNT\", len(num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02578c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS              : ['LogReg', 'DecisionTree', 'RandomForest', 'ExtraTrees', 'HistGB', 'GradBoost', 'AdaBoost', 'BaggingTree', 'LinearSVC_Calibrated_SAFE']\n",
      "THRESHOLDS_COUNT    : 19\n"
     ]
    }
   ],
   "source": [
    "# CANDIDATE MODELS (NON-SVM) + SVM SAFE CONFIG\n",
    "try:\n",
    "    bag_base = BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    BAG_ESTIMATOR_PARAM = \"clf__estimator__\"\n",
    "except TypeError:\n",
    "    bag_base = BaggingClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    BAG_ESTIMATOR_PARAM = \"clf__base_estimator__\"\n",
    "\n",
    "CANDIDATES = {\n",
    "    \"LogReg\": (\n",
    "        LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__C\": [0.03, 0.1, 0.3, 1.0, 3.0], \"clf__solver\": [\"liblinear\"]}\n",
    "    ),\n",
    "    \"DecisionTree\": (\n",
    "        DecisionTreeClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE),\n",
    "        {\"clf__max_depth\": [2, 3, 4, 6, None], \"clf__min_samples_leaf\": [1, 2, 4, 8]}\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]}\n",
    "    ),\n",
    "    \"ExtraTrees\": (\n",
    "        ExtraTreesClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=1),\n",
    "        {\"clf__n_estimators\": [200, 400, 800], \"clf__max_depth\": [None, 6, 10],\n",
    "         \"clf__min_samples_leaf\": [1, 2, 4], \"clf__max_features\": [\"sqrt\"]}\n",
    "    ),\n",
    "    \"HistGB\": (\n",
    "        HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__max_depth\": [2, 3],\n",
    "         \"clf__max_leaf_nodes\": [15, 31, 63]}\n",
    "    ),\n",
    "    \"GradBoost\": (\n",
    "        GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1], \"clf__n_estimators\": [100, 200, 400],\n",
    "         \"clf__max_depth\": [2, 3]}\n",
    "    ),\n",
    "    \"AdaBoost\": (\n",
    "        AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "        {\"clf__learning_rate\": [0.03, 0.05, 0.1, 0.3], \"clf__n_estimators\": [50, 100, 200, 400]}\n",
    "    ),\n",
    "    \"BaggingTree\": (\n",
    "        bag_base,\n",
    "        {\"clf__n_estimators\": [50, 100, 200],\n",
    "         f\"{BAG_ESTIMATOR_PARAM}max_depth\": [2, 3, 4, None],\n",
    "         f\"{BAG_ESTIMATOR_PARAM}min_samples_leaf\": [1, 2, 4]}\n",
    "    ),\n",
    "}\n",
    "\n",
    "SVM_NAME = \"LinearSVC_Calibrated_SAFE\"\n",
    "SVM_GRID = {\"C\": [0.03, 0.1, 0.3, 1.0, 3.0]}\n",
    "\n",
    "kv(\"MODELS\", list(CANDIDATES.keys()) + [SVM_NAME])\n",
    "kv(\"THRESHOLDS_COUNT\", len(THRESHOLDS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d127fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNING UTILITIES (GLOBAL THRESHOLD OR PER-USER THRESHOLD)\n",
    "def tune_global_thr_pooled_over_all_users(pipe, params):\n",
    "    y_list, p_list = [], []\n",
    "    for uid in users:\n",
    "        tp = per_user[uid][\"train_pool\"]\n",
    "        folds = cv_folds_user(tp)\n",
    "        for tr_df, va_df in folds:\n",
    "            ytr = tr_df[\"y_bin\"].astype(int).values\n",
    "            if len(np.unique(ytr)) < 2:\n",
    "                continue\n",
    "            pipe.set_params(**params)\n",
    "            pipe.fit(tr_df[feature_cols], ytr)\n",
    "            p = pipe.predict_proba(va_df[feature_cols])[:, 1]\n",
    "            y_list.append(va_df[\"y_bin\"].astype(int).values)\n",
    "            p_list.append(p)\n",
    "\n",
    "    if len(y_list) == 0:\n",
    "        return None, None\n",
    "\n",
    "    y_all = np.concatenate(y_list)\n",
    "    p_all = np.concatenate(p_list)\n",
    "    thr, cv_f1 = tune_thr_from_proba(y_all, p_all)\n",
    "    return float(thr), float(cv_f1)\n",
    "\n",
    "def tune_per_user_thr(pipe, params):\n",
    "    thr_by_user = {}\n",
    "    f1s = []\n",
    "\n",
    "    for uid in users:\n",
    "        tp = per_user[uid][\"train_pool\"]\n",
    "        folds = cv_folds_user(tp)\n",
    "        if len(folds) == 0:\n",
    "            return None, None\n",
    "\n",
    "        y_list, p_list = [], []\n",
    "        for tr_df, va_df in folds:\n",
    "            ytr = tr_df[\"y_bin\"].astype(int).values\n",
    "            if len(np.unique(ytr)) < 2:\n",
    "                continue\n",
    "            pipe.set_params(**params)\n",
    "            pipe.fit(tr_df[feature_cols], ytr)\n",
    "            p = pipe.predict_proba(va_df[feature_cols])[:, 1]\n",
    "            y_list.append(va_df[\"y_bin\"].astype(int).values)\n",
    "            p_list.append(p)\n",
    "\n",
    "        if len(y_list) == 0:\n",
    "            return None, None\n",
    "\n",
    "        y_u = np.concatenate(y_list)\n",
    "        p_u = np.concatenate(p_list)\n",
    "        thr_u, f1_u = tune_thr_from_proba(y_u, p_u)\n",
    "        thr_by_user[uid] = float(thr_u)\n",
    "        f1s.append(float(f1_u))\n",
    "\n",
    "    return thr_by_user, float(np.mean(f1s))\n",
    "\n",
    "def eval_personalized_models(models_by_user, thr_by_user_or_scalar):\n",
    "    per_user_records = []\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for uid in users:\n",
    "        te = per_user[uid][\"test\"]\n",
    "        y = te[\"y_bin\"].astype(int).values\n",
    "\n",
    "        pipe = models_by_user[uid]\n",
    "        p = pipe.predict_proba(te[feature_cols])[:, 1]\n",
    "        thr = thr_by_user_or_scalar[uid] if isinstance(thr_by_user_or_scalar, dict) else float(thr_by_user_or_scalar)\n",
    "        pred = (p >= thr).astype(int)\n",
    "\n",
    "        per_user_records.append({\"uid\": uid, \"y\": y, \"pred\": pred})\n",
    "        all_true.append(y)\n",
    "        all_pred.append(pred)\n",
    "\n",
    "    y_all = np.concatenate(all_true)\n",
    "    pred_all = np.concatenate(all_pred)\n",
    "\n",
    "    pooled = eval_bin(y_all, pred_all)\n",
    "    macro_acc, macro_f1 = per_user_macro_metrics(per_user_records)\n",
    "    macro = {\"acc\": float(macro_acc), \"f1\": float(macro_f1)}\n",
    "    return pooled, macro, per_user_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67acd35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: LogReg\n",
      "CV_SCORE            : 0.9123454790823212\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.9056603773584906\n",
      "TEST_POOLED_ACC     : 0.8333333333333334\n",
      "TEST_MACRO_F1       : 0.8945511010728401\n",
      "TEST_MACRO_ACC      : 0.8333333333333333\n",
      "PARAMS              : {'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "\n",
      "MODEL: DecisionTree\n",
      "CV_SCORE            : 0.8986311933680355\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__max_depth': 2, 'clf__min_samples_leaf': 8}\n",
      "\n",
      "MODEL: RandomForest\n",
      "CV_SCORE            : 0.9298000245368667\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8846153846153846\n",
      "TEST_POOLED_ACC     : 0.8\n",
      "TEST_MACRO_F1       : 0.8588368153585545\n",
      "TEST_MACRO_ACC      : 0.8\n",
      "PARAMS              : {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "\n",
      "MODEL: ExtraTrees\n",
      "CV_SCORE            : 0.9241101241101243\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8846153846153846\n",
      "TEST_POOLED_ACC     : 0.8\n",
      "TEST_MACRO_F1       : 0.8588368153585545\n",
      "TEST_MACRO_ACC      : 0.8\n",
      "PARAMS              : {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 200}\n",
      "\n",
      "MODEL: HistGB\n",
      "CV_SCORE            : 0.8986311933680355\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "\n",
      "MODEL: GradBoost\n",
      "CV_SCORE            : 0.8948171948171948\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8990825688073395\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8919195221254718\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__n_estimators': 100}\n",
      "\n",
      "MODEL: AdaBoost\n",
      "CV_SCORE            : 0.9298000245368667\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.9038461538461539\n",
      "TEST_POOLED_ACC     : 0.8333333333333334\n",
      "TEST_MACRO_F1       : 0.887408243929983\n",
      "TEST_MACRO_ACC      : 0.8333333333333333\n",
      "PARAMS              : {'clf__learning_rate': 0.03, 'clf__n_estimators': 50}\n",
      "\n",
      "MODEL: BaggingTree\n",
      "CV_SCORE            : 0.9298000245368667\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.8932038834951457\n",
      "TEST_POOLED_ACC     : 0.8166666666666667\n",
      "TEST_MACRO_F1       : 0.8676280241497633\n",
      "TEST_MACRO_ACC      : 0.8166666666666667\n",
      "PARAMS              : {'clf__estimator__max_depth': 2, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# PERSONALIZED ML: TRAIN + TUNE (NON-SVM)\n",
    "rows = []\n",
    "\n",
    "for name, (clf, grid) in CANDIDATES.items():\n",
    "    best = None\n",
    "\n",
    "    for params in ParameterGrid(grid):\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "\n",
    "        if TUNE_THRESHOLD_PER_USER:\n",
    "            thr_obj, cv_score = tune_per_user_thr(pipe, params)\n",
    "        else:\n",
    "            thr_obj, cv_score = tune_global_thr_pooled_over_all_users(pipe, params)\n",
    "\n",
    "        if thr_obj is None:\n",
    "            continue\n",
    "\n",
    "        if (best is None) or (cv_score > best[\"cv_score\"]):\n",
    "            best = {\"params\": dict(params), \"thr_obj\": thr_obj, \"cv_score\": float(cv_score)}\n",
    "\n",
    "    if best is None:\n",
    "        print(f\"SKIP_MODEL: {name} (no valid params/folds)\")\n",
    "        continue\n",
    "\n",
    "    # Final training per user (train_pool only)\n",
    "    models_by_user = {}\n",
    "    ok = True\n",
    "\n",
    "    for uid in users:\n",
    "        tp = per_user[uid][\"train_pool\"]\n",
    "        ytr = tp[\"y_bin\"].astype(int).values\n",
    "        if len(np.unique(ytr)) < 2:\n",
    "            ok = False\n",
    "            break\n",
    "\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "        pipe.set_params(**best[\"params\"])\n",
    "        pipe.fit(tp[feature_cols], ytr)\n",
    "        models_by_user[uid] = pipe\n",
    "\n",
    "    if not ok:\n",
    "        print(f\"SKIP_MODEL: {name} (some user train_pool has single class)\")\n",
    "        continue\n",
    "\n",
    "    pooled, macro, user_records = eval_personalized_models(models_by_user, best[\"thr_obj\"])\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"cv_score\": float(best[\"cv_score\"]),\n",
    "        \"thr_obj\": best[\"thr_obj\"],\n",
    "        \"test_pooled_f1\": float(pooled[\"f1\"]),\n",
    "        \"test_pooled_acc\": float(pooled[\"acc\"]),\n",
    "        \"test_macro_f1\": float(macro[\"f1\"]),\n",
    "        \"test_macro_acc\": float(macro[\"acc\"]),\n",
    "        \"params\": dict(best[\"params\"]),\n",
    "        \"models_by_user\": models_by_user,\n",
    "        \"test_user_records\": user_records,\n",
    "    })\n",
    "\n",
    "    thr_desc = \"per-user\" if isinstance(best[\"thr_obj\"], dict) else f\"{best['thr_obj']:.2f}\"\n",
    "    print(f\"\\nMODEL: {name}\")\n",
    "    kv(\"CV_SCORE\", best[\"cv_score\"])\n",
    "    kv(\"THRESHOLD\", thr_desc)\n",
    "    kv(\"TEST_POOLED_F1\", pooled[\"f1\"])\n",
    "    kv(\"TEST_POOLED_ACC\", pooled[\"acc\"])\n",
    "    kv(\"TEST_MACRO_F1\", macro[\"f1\"])\n",
    "    kv(\"TEST_MACRO_ACC\", macro[\"acc\"])\n",
    "    kv(\"PARAMS\", best[\"params\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f62c22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_FEASIBLE_ALL_USERS: True\n",
      "SVM_FEASIBLE_DETAIL:\n",
      "uid=1 | min_class_count_trainpool=20\n",
      "uid=2 | min_class_count_trainpool=19\n",
      "uid=3 | min_class_count_trainpool=18\n",
      "uid=4 | min_class_count_trainpool=17\n",
      "uid=5 | min_class_count_trainpool=20\n",
      "\n",
      "MODEL: LinearSVC_Calibrated_SAFE\n",
      "CV_SCORE            : 0.9234759138649299\n",
      "THRESHOLD           : per-user\n",
      "TEST_POOLED_F1      : 0.865979381443299\n",
      "TEST_POOLED_ACC     : 0.7833333333333333\n",
      "TEST_MACRO_F1       : 0.7445511010728402\n",
      "TEST_MACRO_ACC      : 0.7833333333333333\n",
      "PARAMS              : {'C': 1.0, 'final_cv_by_user': {1: 3, 2: 3, 3: 3, 4: 3, 5: 3}}\n"
     ]
    }
   ],
   "source": [
    "# SVM CALIBRATED SAFE (ADAPTIVE CV PER FOLD)\n",
    "def make_calibrator(base, cv_k):\n",
    "    try:\n",
    "        return CalibratedClassifierCV(estimator=base, method=\"sigmoid\", cv=cv_k)\n",
    "    except TypeError:\n",
    "        return CalibratedClassifierCV(base_estimator=base, method=\"sigmoid\", cv=cv_k)\n",
    "\n",
    "def svm_fit_predict_proba(tr_X, tr_y, va_X, C, cv_max=3):\n",
    "    mcc = min_class_count(tr_y)\n",
    "    cv_k = int(min(cv_max, mcc))\n",
    "    if cv_k < 2:\n",
    "        return None, cv_k\n",
    "    base = LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE, C=float(C))\n",
    "    calib = make_calibrator(base, cv_k=cv_k)\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", calib)])\n",
    "    pipe.fit(tr_X, tr_y)\n",
    "    return pipe.predict_proba(va_X)[:, 1], cv_k\n",
    "\n",
    "# Feasibility check for final training across all users\n",
    "svm_feasible_all_users = True\n",
    "svm_feasible_detail = []\n",
    "\n",
    "for uid in users:\n",
    "    y_tp = per_user[uid][\"train_pool\"][\"y_bin\"].astype(int).values\n",
    "    mcc = min_class_count(y_tp)\n",
    "    svm_feasible_detail.append({\"uid\": uid, \"min_class_count_trainpool\": mcc})\n",
    "    if mcc < 2:\n",
    "        svm_feasible_all_users = False\n",
    "\n",
    "kv(\"SVM_FEASIBLE_ALL_USERS\", svm_feasible_all_users)\n",
    "print(\"SVM_FEASIBLE_DETAIL:\")\n",
    "for r in svm_feasible_detail:\n",
    "    print(f\"uid={r['uid']} | min_class_count_trainpool={r['min_class_count_trainpool']}\")\n",
    "\n",
    "if svm_feasible_all_users:\n",
    "    best = None\n",
    "\n",
    "    for C in SVM_GRID[\"C\"]:\n",
    "        if TUNE_THRESHOLD_PER_USER:\n",
    "            thr_by_user = {}\n",
    "            per_user_cv_scores = []\n",
    "            all_users_ok = True\n",
    "            users_valid = 0\n",
    "\n",
    "            for uid in users:\n",
    "                tp = per_user[uid][\"train_pool\"]\n",
    "                folds = cv_folds_user(tp)\n",
    "\n",
    "                y_list_u, p_list_u = [], []\n",
    "                for (tr_df, va_df) in folds:\n",
    "                    tr_y = tr_df[\"y_bin\"].astype(int).values\n",
    "                    p, cv_k = svm_fit_predict_proba(tr_df[feature_cols], tr_y, va_df[feature_cols], C=C, cv_max=3)\n",
    "                    if p is None:\n",
    "                        continue\n",
    "                    y_list_u.append(va_df[\"y_bin\"].astype(int).values)\n",
    "                    p_list_u.append(p)\n",
    "\n",
    "                if len(y_list_u) == 0:\n",
    "                    all_users_ok = False\n",
    "                    break\n",
    "\n",
    "                y_u = np.concatenate(y_list_u)\n",
    "                p_u = np.concatenate(p_list_u)\n",
    "                thr_u, f1_u = tune_thr_from_proba(y_u, p_u)\n",
    "                thr_by_user[uid] = float(thr_u)\n",
    "                per_user_cv_scores.append(float(f1_u))\n",
    "                users_valid += 1\n",
    "\n",
    "            if (not all_users_ok) or (users_valid < len(users)):\n",
    "                continue\n",
    "\n",
    "            cv_score = float(np.mean(per_user_cv_scores))\n",
    "            thr_obj = thr_by_user\n",
    "\n",
    "        else:\n",
    "            y_list, p_list = [], []\n",
    "            for uid in users:\n",
    "                tp = per_user[uid][\"train_pool\"]\n",
    "                folds = cv_folds_user(tp)\n",
    "                for (tr_df, va_df) in folds:\n",
    "                    tr_y = tr_df[\"y_bin\"].astype(int).values\n",
    "                    p, cv_k = svm_fit_predict_proba(tr_df[feature_cols], tr_y, va_df[feature_cols], C=C, cv_max=3)\n",
    "                    if p is None:\n",
    "                        continue\n",
    "                    y_list.append(va_df[\"y_bin\"].astype(int).values)\n",
    "                    p_list.append(p)\n",
    "\n",
    "            if len(y_list) == 0:\n",
    "                continue\n",
    "\n",
    "            y_all = np.concatenate(y_list)\n",
    "            p_all = np.concatenate(p_list)\n",
    "            thr_obj, cv_score = tune_thr_from_proba(y_all, p_all)\n",
    "\n",
    "        if (best is None) or (cv_score > best[\"cv_score\"]):\n",
    "            best = {\"C\": float(C), \"thr_obj\": thr_obj, \"cv_score\": float(cv_score)}\n",
    "\n",
    "    if best is None:\n",
    "        print(f\"SKIP_MODEL: {SVM_NAME} (no valid C across all users/folds)\")\n",
    "    else:\n",
    "        # Final training per user (adaptive cv from train_pool)\n",
    "        models_by_user = {}\n",
    "        ok = True\n",
    "        final_cv_by_user = {}\n",
    "\n",
    "        for uid in users:\n",
    "            tp = per_user[uid][\"train_pool\"]\n",
    "            tr_y = tp[\"y_bin\"].astype(int).values\n",
    "            mcc = min_class_count(tr_y)\n",
    "            cv_k = int(min(3, mcc))\n",
    "            if cv_k < 2:\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            base = LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE, C=float(best[\"C\"]))\n",
    "            calib = make_calibrator(base, cv_k=cv_k)\n",
    "            pipe = Pipeline([(\"prep\", preprocess), (\"clf\", calib)])\n",
    "            pipe.fit(tp[feature_cols], tr_y)\n",
    "\n",
    "            models_by_user[uid] = pipe\n",
    "            final_cv_by_user[uid] = cv_k\n",
    "\n",
    "        if not ok:\n",
    "            print(f\"SKIP_MODEL: {SVM_NAME} (final training not feasible for all users)\")\n",
    "        else:\n",
    "            pooled, macro, user_records = eval_personalized_models(models_by_user, best[\"thr_obj\"])\n",
    "            rows.append({\n",
    "                \"model\": SVM_NAME,\n",
    "                \"cv_score\": float(best[\"cv_score\"]),\n",
    "                \"thr_obj\": best[\"thr_obj\"],\n",
    "                \"test_pooled_f1\": float(pooled[\"f1\"]),\n",
    "                \"test_pooled_acc\": float(pooled[\"acc\"]),\n",
    "                \"test_macro_f1\": float(macro[\"f1\"]),\n",
    "                \"test_macro_acc\": float(macro[\"acc\"]),\n",
    "                \"params\": {\"C\": float(best[\"C\"]), \"calibration_cv\": f\"adaptive<=3 (per user), {final_cv_by_user}\"},\n",
    "                \"models_by_user\": models_by_user,\n",
    "                \"test_user_records\": user_records,\n",
    "            })\n",
    "\n",
    "            thr_desc = \"per-user\" if isinstance(best[\"thr_obj\"], dict) else f\"{best['thr_obj']:.2f}\"\n",
    "            print(f\"\\nMODEL: {SVM_NAME}\")\n",
    "            kv(\"CV_SCORE\", best[\"cv_score\"])\n",
    "            kv(\"THRESHOLD\", thr_desc)\n",
    "            kv(\"TEST_POOLED_F1\", pooled[\"f1\"])\n",
    "            kv(\"TEST_POOLED_ACC\", pooled[\"acc\"])\n",
    "            kv(\"TEST_MACRO_F1\", macro[\"f1\"])\n",
    "            kv(\"TEST_MACRO_ACC\", macro[\"acc\"])\n",
    "            kv(\"PARAMS\", {\"C\": best[\"C\"], \"final_cv_by_user\": final_cv_by_user})\n",
    "else:\n",
    "    print(f\"SKIP_MODEL: {SVM_NAME} (some user train_pool has single class)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef59bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINES:\n",
      "  Baseline-Persist | TEST pooled: acc=0.8000, f1=0.8776 | macro(user): acc=0.8000, f1=0.8602\n",
      "  Baseline-Markov  | CV pooled: f1=0.9189, thr=0.05 | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919\n",
      "\n",
      "CANDIDATES:\n",
      "  LogReg                     | CV=0.9123 | thr=per-user | TEST pooled: acc=0.8333, f1=0.9057 | macro(user): acc=0.8333, f1=0.8946 | params={'clf__C': 0.03, 'clf__solver': 'liblinear'}\n",
      "  AdaBoost                   | CV=0.9298 | thr=per-user | TEST pooled: acc=0.8333, f1=0.9038 | macro(user): acc=0.8333, f1=0.8874 | params={'clf__learning_rate': 0.03, 'clf__n_estimators': 50}\n",
      "  DecisionTree               | CV=0.8986 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919 | params={'clf__max_depth': 2, 'clf__min_samples_leaf': 8}\n",
      "  HistGB                     | CV=0.8986 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__max_leaf_nodes': 15}\n",
      "  GradBoost                  | CV=0.8948 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8991 | macro(user): acc=0.8167, f1=0.8919 | params={'clf__learning_rate': 0.03, 'clf__max_depth': 2, 'clf__n_estimators': 100}\n",
      "  BaggingTree                | CV=0.9298 | thr=per-user | TEST pooled: acc=0.8167, f1=0.8932 | macro(user): acc=0.8167, f1=0.8676 | params={'clf__estimator__max_depth': 2, 'clf__estimator__min_samples_leaf': 1, 'clf__n_estimators': 100}\n",
      "  RandomForest               | CV=0.9298 | thr=per-user | TEST pooled: acc=0.8000, f1=0.8846 | macro(user): acc=0.8000, f1=0.8588 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__n_estimators': 200}\n",
      "  ExtraTrees                 | CV=0.9241 | thr=per-user | TEST pooled: acc=0.8000, f1=0.8846 | macro(user): acc=0.8000, f1=0.8588 | params={'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 2, 'clf__n_estimators': 200}\n",
      "  LinearSVC_Calibrated_SAFE  | CV=0.9235 | thr=per-user | TEST pooled: acc=0.7833, f1=0.8660 | macro(user): acc=0.7833, f1=0.7446 | params={'C': 1.0, 'calibration_cv': 'adaptive<=3 (per user), {1: 3, 2: 3, 3: 3, 4: 3, 5: 3}'}\n",
      "\n",
      "SELECTED_BEST: LogReg\n",
      "\n",
      "PER-USER (SELECTED_BEST=LogReg) on TEST:\n",
      "uid=1 | n=12  | dist={0: 1, 1: 11} | acc=0.9167 | f1=0.9565 | thr=0.05\n",
      "uid=2 | n=12  | dist={0: 3, 1: 9} | acc=0.7500 | f1=0.8571 | thr=0.05\n",
      "uid=3 | n=12  | dist={0: 5, 1: 7} | acc=0.6667 | f1=0.7500 | thr=0.50\n",
      "uid=4 | n=12  | dist={0: 0, 1: 12} | acc=1.0000 | f1=1.0000 | thr=0.05\n",
      "uid=5 | n=12  | dist={0: 2, 1: 10} | acc=0.8333 | f1=0.9091 | thr=0.05\n"
     ]
    }
   ],
   "source": [
    "# LEADERBOARD + SELECT BEST (VS MARKOV)\n",
    "print(\"BASELINES:\")\n",
    "print(\n",
    "    f\"  Baseline-Persist | TEST pooled: acc={persist_pooled['acc']:.4f}, f1={persist_pooled['f1']:.4f} | \"\n",
    "    f\"macro(user): acc={persist_macro_acc:.4f}, f1={persist_macro_f1:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Baseline-Markov  | CV pooled: f1={cv_f1_mk:.4f}, thr={thr_mk:.2f} | \"\n",
    "    f\"TEST pooled: acc={markov_pooled['acc']:.4f}, f1={markov_pooled['f1']:.4f} | \"\n",
    "    f\"macro(user): acc={markov_macro_acc:.4f}, f1={markov_macro_f1:.4f}\"\n",
    ")\n",
    "\n",
    "rows_sorted = sorted(rows, key=lambda r: r[\"test_pooled_f1\"], reverse=True)\n",
    "\n",
    "print(\"\\nCANDIDATES:\")\n",
    "if len(rows_sorted) == 0:\n",
    "    print(\"  (no ML candidates succeeded)\")\n",
    "else:\n",
    "    for r in rows_sorted:\n",
    "        thr_desc = \"per-user\" if isinstance(r[\"thr_obj\"], dict) else f\"{r['thr_obj']:.2f}\"\n",
    "        print(\n",
    "            f\"  {r['model']:<26} | CV={r['cv_score']:.4f} | thr={thr_desc:<8} | \"\n",
    "            f\"TEST pooled: acc={r['test_pooled_acc']:.4f}, f1={r['test_pooled_f1']:.4f} | \"\n",
    "            f\"macro(user): acc={r['test_macro_acc']:.4f}, f1={r['test_macro_f1']:.4f} | params={r['params']}\"\n",
    "        )\n",
    "\n",
    "best_name = \"MarkovUser\"\n",
    "best_obj = {\"type\": \"markov_user\", \"thr\": float(thr_mk), \"probs_by_user\": mk_models}\n",
    "best_test_pooled_f1 = float(markov_pooled[\"f1\"])\n",
    "best_user_records = markov_user_records\n",
    "best_thr_info = thr_mk\n",
    "\n",
    "if len(rows_sorted) > 0 and float(rows_sorted[0][\"test_pooled_f1\"]) > best_test_pooled_f1:\n",
    "    top = rows_sorted[0]\n",
    "    best_name = top[\"model\"]\n",
    "    best_obj = {\n",
    "        \"type\": \"personalized_sklearn\",\n",
    "        \"models_by_user\": top[\"models_by_user\"],\n",
    "        \"thr\": top[\"thr_obj\"],\n",
    "        \"meta\": {\"tune_threshold_per_user\": bool(TUNE_THRESHOLD_PER_USER)},\n",
    "    }\n",
    "    best_user_records = top[\"test_user_records\"]\n",
    "    best_thr_info = top[\"thr_obj\"]\n",
    "\n",
    "print(\"\\nSELECTED_BEST:\", best_name)\n",
    "if best_name == \"MarkovUser\":\n",
    "    print(\"SELECT_REASON: Markov baseline remains best on TEST pooled F1 for this dataset.\")\n",
    "\n",
    "if PRINT_PER_USER_DETAILS:\n",
    "    print_per_user_breakdown(f\"PER-USER (SELECTED_BEST={best_name}) on TEST:\", best_user_records, thr_info=best_thr_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab36d6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED_TO            : ..\\models\\personalized_forecast.joblib\n",
      "BEST_NAME           : LogReg\n"
     ]
    }
   ],
   "source": [
    "# SAVE ARTIFACT\n",
    "MODEL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"best_name\": best_name,\n",
    "        \"artifact\": best_obj,\n",
    "        \"meta\": {\n",
    "            \"target\": \"y_bin = (stress_level>=1)\",\n",
    "            \"date_col\": DATE_COL,\n",
    "            \"user_col\": USER_COL,\n",
    "            \"target_col\": TARGET_COL,\n",
    "            \"window\": WINDOW,\n",
    "            \"test_len\": TEST_LEN,\n",
    "            \"val_windows\": VAL_WINDOWS,\n",
    "            \"thresholds\": THRESHOLDS.tolist(),\n",
    "            \"users\": users,\n",
    "            \"baseline_l1\": \"persistence(per-user)\",\n",
    "            \"baseline_l2\": \"markov_user(prev_high, dow)\",\n",
    "            \"use_user_id_feature\": USE_USER_ID_FEATURE,\n",
    "            \"tune_threshold_per_user\": TUNE_THRESHOLD_PER_USER,\n",
    "            \"random_state\": RANDOM_STATE,\n",
    "            \"feature_cols\": feature_cols,\n",
    "        }\n",
    "    },\n",
    "    MODEL_OUT\n",
    ")\n",
    "\n",
    "kv(\"SAVED_TO\", str(MODEL_OUT))\n",
    "kv(\"BEST_NAME\", best_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e261447",
   "metadata": {},
   "source": [
    "# Try Model\n",
    "\n",
    "Bagian ini menjalankan inference menggunakan artifact yang sudah tersimpan, tanpa menjalankan proses training ulang.\n",
    "\n",
    "Output menampilkan prediksi untuk baris terbaru per user (setelah fitur history tersedia).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be0fa18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTIFACT_PATH: ..\\models\\personalized_forecast.joblib\n",
      "ARTIFACT_TYPE: personalized_sklearn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>y_true</th>\n",
       "      <th>p</th>\n",
       "      <th>pred</th>\n",
       "      <th>thr</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.745165</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>personalized_sklearn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       date  y_true         p  pred   thr            model_type\n",
       "0        1 2026-01-19       1  0.700946     1  0.05  personalized_sklearn\n",
       "1        2 2026-01-19       1  0.716169     1  0.05  personalized_sklearn\n",
       "2        3 2026-01-19       1  0.700946     1  0.50  personalized_sklearn\n",
       "3        4 2026-01-19       1  0.830487     1  0.05  personalized_sklearn\n",
       "4        5 2026-01-19       1  0.745165     1  0.05  personalized_sklearn"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS (SAMPLE: last row per user)\n",
      "ACC: 1.0\n",
      "F1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# TRY MODEL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Config\n",
    "# -----------------------------------------------------------------------------\n",
    "ARTIFACT_PATH = Path(\"../models/personalized_forecast.joblib\")\n",
    "DATA_PATH = Path(\"../datasets/stress_forecast.csv\")\n",
    "\n",
    "DATE_COL = \"date\"\n",
    "USER_COL = \"user_id\"\n",
    "TARGET_COL = \"stress_level\"  # 0..2\n",
    "\n",
    "WINDOW = 3\n",
    "\n",
    "if not ARTIFACT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Artifact not found: {ARTIFACT_PATH}\")\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATA_PATH}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load artifact\n",
    "# -----------------------------------------------------------------------------\n",
    "bundle = joblib.load(ARTIFACT_PATH)\n",
    "artifact = bundle.get(\"artifact\", bundle)\n",
    "meta = bundle.get(\"meta\", {})\n",
    "\n",
    "use_user_id_feature = bool(meta.get(\"use_user_id_feature\", False))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load data\n",
    "# -----------------------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if \"is_restored\" not in df.columns:\n",
    "    df[\"is_restored\"] = 0\n",
    "df[\"is_restored\"] = df[\"is_restored\"].fillna(0).astype(int)\n",
    "for required_col in [DATE_COL, USER_COL, TARGET_COL]:\n",
    "    if required_col not in df.columns:\n",
    "        raise KeyError(f\"Required column '{required_col}' not found in dataset.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"raise\")\n",
    "df = df.sort_values([USER_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "if not df[TARGET_COL].dropna().between(0, 2).all():\n",
    "    raise ValueError(f\"'{TARGET_COL}' must be within range 0..2\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Feature engineering (no leakage)\n",
    "# -----------------------------------------------------------------------------\n",
    "rows = []\n",
    "for uid, g in df.groupby(USER_COL):\n",
    "    g = g.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "    g[\"dow\"] = g[DATE_COL].dt.dayofweek.astype(int)\n",
    "    g[\"is_weekend\"] = (g[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    for k in range(1, WINDOW + 1):\n",
    "        g[f\"lag_sp_{k}\"] = g[TARGET_COL].shift(k)\n",
    "\n",
    "    sp_shift = g[TARGET_COL].shift(1)\n",
    "\n",
    "    g[\"sp_mean\"] = sp_shift.rolling(WINDOW).mean()\n",
    "    g[\"sp_std\"]  = sp_shift.rolling(WINDOW).std().fillna(0.0)\n",
    "    g[\"sp_min\"]  = sp_shift.rolling(WINDOW).min()\n",
    "    g[\"sp_max\"]  = sp_shift.rolling(WINDOW).max()\n",
    "\n",
    "    g[\"count_high\"] = (sp_shift >= 1).rolling(WINDOW).sum()\n",
    "    g[\"count_low\"]  = (sp_shift == 0).rolling(WINDOW).sum()\n",
    "\n",
    "    high = (sp_shift >= 1).astype(int).fillna(0).astype(int).tolist()\n",
    "    streak, cur = [], 0\n",
    "    for v in high:\n",
    "        cur = cur + 1 if v == 1 else 0\n",
    "        streak.append(cur)\n",
    "    g[\"streak_high\"] = streak\n",
    "\n",
    "    diff = (sp_shift != sp_shift.shift(1)).astype(int)\n",
    "    g[\"transitions\"] = diff.rolling(WINDOW).sum()\n",
    "\n",
    "    rows.append(g)\n",
    "\n",
    "feat = pd.concat(rows, ignore_index=True)\n",
    "feat[\"y_bin\"] = (feat[TARGET_COL] >= 1).astype(int)\n",
    "\n",
    "feature_cols = (\n",
    "    [\"dow\", \"is_weekend\"]\n",
    "    + [f\"lag_sp_{k}\" for k in range(1, WINDOW + 1)]\n",
    "    + [\n",
    "        \"sp_mean\", \"sp_std\", \"sp_min\", \"sp_max\",\n",
    "        \"count_high\", \"count_low\",\n",
    "        \"streak_high\", \"transitions\",\n",
    "    ]\n",
    ")\n",
    "if use_user_id_feature:\n",
    "    feature_cols = [USER_COL] + feature_cols\n",
    "\n",
    "feat = feat.dropna(subset=feature_cols + [\"y_bin\"]).reset_index(drop=True)\n",
    "\n",
    "# Latest engineered row per user\n",
    "sample_df = (\n",
    "    feat.sort_values([USER_COL, DATE_COL])\n",
    "        .groupby(USER_COL, as_index=False)\n",
    "        .tail(1)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Inference helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "def markov_proba_user(probs, df_eval):\n",
    "    prev = (df_eval[\"lag_sp_1\"] >= 1).astype(int).values\n",
    "    dow  = df_eval[\"dow\"].astype(int).values\n",
    "    return np.array([probs[p, d, 1] for p, d in zip(prev, dow)], dtype=float)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run inference (supports markov_user and personalized_sklearn)\n",
    "# -----------------------------------------------------------------------------\n",
    "art_type = artifact.get(\"type\", \"\")\n",
    "\n",
    "out_rows = []\n",
    "if art_type == \"markov_user\":\n",
    "    thr = artifact[\"thr\"]\n",
    "    probs_by_user = artifact[\"probs_by_user\"]\n",
    "\n",
    "    for _, r in sample_df.iterrows():\n",
    "        uid = r[USER_COL]\n",
    "        probs = probs_by_user.get(uid)\n",
    "        if probs is None:\n",
    "            continue\n",
    "\n",
    "        p = markov_proba_user(probs, pd.DataFrame([r]))[0]\n",
    "        pred = int(p >= float(thr))\n",
    "\n",
    "        out_rows.append({\n",
    "            \"user_id\": uid,\n",
    "            \"date\": r[DATE_COL],\n",
    "            \"y_true\": int(r[\"y_bin\"]),\n",
    "            \"p\": float(p),\n",
    "            \"pred\": int(pred),\n",
    "            \"model_type\": art_type,\n",
    "        })\n",
    "\n",
    "elif art_type == \"personalized_sklearn\":\n",
    "    models_by_user = artifact[\"models_by_user\"]\n",
    "    thr_obj = artifact.get(\"thr\")\n",
    "\n",
    "    for _, r in sample_df.iterrows():\n",
    "        uid = r[USER_COL]\n",
    "        pipe = models_by_user.get(uid)\n",
    "        if pipe is None:\n",
    "            continue\n",
    "\n",
    "        X = pd.DataFrame([r])[feature_cols]\n",
    "        p = float(pipe.predict_proba(X)[:, 1][0])\n",
    "\n",
    "        thr = thr_obj.get(uid) if isinstance(thr_obj, dict) else float(thr_obj)\n",
    "        pred = int(p >= float(thr))\n",
    "\n",
    "        out_rows.append({\n",
    "            \"user_id\": uid,\n",
    "            \"date\": r[DATE_COL],\n",
    "            \"y_true\": int(r[\"y_bin\"]),\n",
    "            \"p\": float(p),\n",
    "            \"pred\": int(pred),\n",
    "            \"thr\": float(thr),\n",
    "            \"model_type\": art_type,\n",
    "        })\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported artifact type: {art_type}\")\n",
    "\n",
    "out = pd.DataFrame(out_rows).sort_values([\"user_id\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"ARTIFACT_PATH:\", str(ARTIFACT_PATH))\n",
    "print(\"ARTIFACT_TYPE:\", art_type)\n",
    "\n",
    "display(out)\n",
    "\n",
    "if len(out) > 0:\n",
    "    acc = float((out[\"pred\"].values == out[\"y_true\"].values).mean())\n",
    "    f1  = float(f1_score(out[\"y_true\"].values, out[\"pred\"].values, zero_division=0))\n",
    "    print(\"\\nMETRICS (SAMPLE: last row per user)\")\n",
    "    print(\"ACC:\", acc)\n",
    "    print(\"F1 :\", f1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
