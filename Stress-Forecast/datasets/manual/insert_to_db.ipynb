{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CSV (5 file) -> predict stress_level -> emoji -> insert ke MySQL\n",
    "#\n",
    "# Output table columns:\n",
    "# stress_level_id (AUTO INC), user_id, date, stress_level, gpa,\n",
    "# extracurricular_hour_per_day, physical_activity_hour_per_day,\n",
    "# sleep_hour_per_day, study_hour_per_day, social_hour_per_day,\n",
    "# emoji, is_restored, created_at\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# =========================\n",
    "# 0) INPUT FILES\n",
    "# =========================\n",
    "CSV_FILES = [\n",
    "    (\"Akbar\", Path(\"./Our Data - Akbar.csv\"), 1),\n",
    "    (\"Kaleb\", Path(\"./Our Data - Kaleb.csv\"), 2),\n",
    "    (\"Epin\",  Path(\"./Our Data - Epin.csv\"),  3),\n",
    "    (\"Adel\",  Path(\"./Our Data - Adel.csv\"),  4),\n",
    "    (\"Sye\",   Path(\"./Our Data - Sye.csv\"),   5),\n",
    "]\n",
    "\n",
    "# Range yang dipakai\n",
    "START_DATE = pd.Timestamp(\"2025-11-21\")\n",
    "END_DATE   = pd.Timestamp(\"2026-01-22\")\n",
    "\n",
    "# Model\n",
    "ARTIFACT_PATH = Path(\"current_stress_pipeline.joblib\")\n",
    "\n",
    "# =========================\n",
    "# 1) DB CONFIG (ENV recommended)\n",
    "# =========================\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = int(os.getenv(\"DB_PORT\", \"3306\"))\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\",\n",
    "    pool_pre_ping=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) Helpers\n",
    "# =========================\n",
    "month_map = {\n",
    "    \"January\":1,\"February\":2,\"March\":3,\"April\":4,\"May\":5,\"June\":6,\"July\":7,\"August\":8,\"September\":9,\"October\":10,\"November\":11,\"December\":12,\n",
    "    \"Januari\":1,\"Februari\":2,\"Maret\":3,\"April\":4,\"Mei\":5,\"Juni\":6,\"Juli\":7,\"Agustus\":8,\"September\":9,\"Oktober\":10,\"November\":11,\"Desember\":12\n",
    "}\n",
    "\n",
    "def to_num(x):\n",
    "    \"\"\"Handle string angka dengan koma (3,82 / 8,5) -> float\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip().replace(\",\", \".\")\n",
    "        x = x.replace(\" \", \"\")\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def detect_ymd_cols(df: pd.DataFrame):\n",
    "    \"\"\"Detect kolom tahun/bulan/tanggal (kadang jadi Unnamed:0/1/2)\"\"\"\n",
    "    if {\"Tahun\",\"Bulan\",\"Tanggal\"}.issubset(df.columns):\n",
    "        return \"Tahun\", \"Bulan\", \"Tanggal\"\n",
    "    # fallback: 3 kolom pertama (Kaleb/Epin/Adel/Sye csv kamu)\n",
    "    return df.columns[0], df.columns[1], df.columns[2]\n",
    "\n",
    "def normalize_one_csv(csv_path: Path, user_id: int) -> pd.DataFrame:\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"CSV not found: {csv_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    ycol, mcol, dcol = detect_ymd_cols(df)\n",
    "\n",
    "    year = pd.to_numeric(df[ycol], errors=\"coerce\").astype(\"Int64\")\n",
    "    month = df[mcol].astype(str).str.strip()\n",
    "    day = pd.to_numeric(df[dcol], errors=\"coerce\").astype(\"Int64\")\n",
    "    month_num = month.map(month_map)\n",
    "\n",
    "    date = pd.to_datetime(dict(year=year, month=month_num, day=day), errors=\"coerce\")\n",
    "\n",
    "    # Kolom data sesuai CSV kamu\n",
    "    col_study = \"Study Hours Per Day (Normalnya Weekday 6)\"\n",
    "    col_extra = \"Extracurricular Hours Per Day\"\n",
    "    col_sleep = \"Sleep Hours Per Day\"\n",
    "    col_social = \"Social Hours Per Day (Normalnya 2, kerkom/belajar bareng dihitung juga)\"\n",
    "    col_phys = \"Physical Activity Hours Per Day (Normalnya 0.5)\"\n",
    "    col_gpa = \"GPA\"\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"user_id\": user_id,\n",
    "        \"date\": date,\n",
    "        \"study_hour_per_day\": df.get(col_study),\n",
    "        \"extracurricular_hour_per_day\": df.get(col_extra),\n",
    "        \"sleep_hour_per_day\": df.get(col_sleep),\n",
    "        \"social_hour_per_day\": df.get(col_social),\n",
    "        \"physical_activity_hour_per_day\": df.get(col_phys),\n",
    "        \"gpa\": df.get(col_gpa),\n",
    "    })\n",
    "\n",
    "    # convert numbers properly (koma -> titik)\n",
    "    for c in [\n",
    "        \"study_hour_per_day\",\n",
    "        \"extracurricular_hour_per_day\",\n",
    "        \"sleep_hour_per_day\",\n",
    "        \"social_hour_per_day\",\n",
    "        \"physical_activity_hour_per_day\",\n",
    "        \"gpa\"\n",
    "    ]:\n",
    "        out[c] = out[c].apply(to_num)\n",
    "\n",
    "    # filter range\n",
    "    out = out[out[\"date\"].between(START_DATE, END_DATE)].copy()\n",
    "    out = out.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# 3) Load all CSVs\n",
    "# =========================\n",
    "all_df = []\n",
    "for name, path, uid in CSV_FILES:\n",
    "    tmp = normalize_one_csv(path, uid)\n",
    "    print(f\"{name}: rows_in_range={len(tmp)}\")\n",
    "    all_df.append(tmp)\n",
    "\n",
    "df = pd.concat(all_df, ignore_index=True)\n",
    "df = df.sort_values([\"user_id\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTotal rows:\", len(df))\n",
    "print(\"Rows per user:\", df.groupby(\"user_id\").size().to_dict())\n",
    "\n",
    "# =========================\n",
    "# 4) Validation (harus tidak ada NA di kolom wajib)\n",
    "# =========================\n",
    "required = [\n",
    "    \"gpa\",\"extracurricular_hour_per_day\",\"physical_activity_hour_per_day\",\n",
    "    \"sleep_hour_per_day\",\"study_hour_per_day\",\"social_hour_per_day\"\n",
    "]\n",
    "bad = df[df[required].isna().any(axis=1)]\n",
    "if not bad.empty:\n",
    "    print(\"\\n❌ Masih ada nilai kosong/invalid di kolom wajib. Fix CSV dulu:\")\n",
    "    print(bad[[\"user_id\",\"date\"] + required].to_string(index=False))\n",
    "    raise SystemExit(\"Stop: Fix CSV lalu rerun.\")\n",
    "\n",
    "# =========================\n",
    "# 5) created_at random 19:00–23:00, is_restored=0\n",
    "# =========================\n",
    "rng_time = np.random.default_rng(26)\n",
    "\n",
    "def random_created_at(d: pd.Timestamp) -> str:\n",
    "    h = int(rng_time.integers(19, 24))\n",
    "    m = int(rng_time.integers(0, 60))\n",
    "    s = int(rng_time.integers(0, 60))\n",
    "    return f\"{d.date()} {h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "df[\"created_at\"] = df[\"date\"].apply(random_created_at)\n",
    "df[\"is_restored\"] = 0\n",
    "\n",
    "# =========================\n",
    "# 6) Load model & predict stress_level\n",
    "# =========================\n",
    "if not ARTIFACT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model artifact not found: {ARTIFACT_PATH}\")\n",
    "\n",
    "artifact = joblib.load(ARTIFACT_PATH)\n",
    "pipeline = artifact.get(\"pipeline\")\n",
    "feature_names = list(artifact.get(\"feature_names\", []))\n",
    "if pipeline is None or not feature_names:\n",
    "    raise ValueError(\"Artifact invalid. Need keys: pipeline, feature_names\")\n",
    "\n",
    "rename_map = {\n",
    "    \"gpa\": \"GPA\",\n",
    "    \"study_hour_per_day\": \"Study_Hours_Per_Day\",\n",
    "    \"sleep_hour_per_day\": \"Sleep_Hours_Per_Day\",\n",
    "    \"social_hour_per_day\": \"Social_Hours_Per_Day\",\n",
    "    \"physical_activity_hour_per_day\": \"Physical_Activity_Hours_Per_Day\",\n",
    "    \"extracurricular_hour_per_day\": \"Extracurricular_Hours_Per_Day\",\n",
    "}\n",
    "feat_df = df.rename(columns=rename_map).copy()\n",
    "\n",
    "# optional: Academic performance columns (kalau model butuh)\n",
    "def categorize_academic_performance(gpa: float) -> str:\n",
    "    if gpa >= 3.5: return \"Excellent\"\n",
    "    if 3.0 <= gpa < 3.5: return \"Good\"\n",
    "    if 2.0 <= gpa < 3.0: return \"Fair\"\n",
    "    return \"Poor\"\n",
    "\n",
    "mapping_perf = {\"Poor\": 0, \"Fair\": 1, \"Good\": 2, \"Excellent\": 3}\n",
    "\n",
    "if \"Academic_Performance\" in feature_names and \"Academic_Performance\" not in feat_df.columns:\n",
    "    feat_df[\"Academic_Performance\"] = feat_df[\"GPA\"].astype(float).apply(categorize_academic_performance)\n",
    "\n",
    "if \"Academic_Performance_Encoded\" in feature_names and \"Academic_Performance_Encoded\" not in feat_df.columns:\n",
    "    perf = feat_df[\"GPA\"].astype(float).apply(categorize_academic_performance)\n",
    "    feat_df[\"Academic_Performance_Encoded\"] = perf.map(mapping_perf).astype(int)\n",
    "\n",
    "missing_feats = [c for c in feature_names if c not in feat_df.columns]\n",
    "if missing_feats:\n",
    "    raise KeyError(f\"Missing model features: {missing_feats}\\nAvailable: {list(feat_df.columns)}\")\n",
    "\n",
    "X = feat_df[feature_names].copy()\n",
    "pred = pipeline.predict(X).astype(int)\n",
    "df[\"stress_level\"] = pred\n",
    "\n",
    "# =========================\n",
    "# 7) Emoji rule\n",
    "# stress=0 -> emoji 0-1\n",
    "# stress=1 -> emoji 2\n",
    "# stress=2 -> emoji 3-4\n",
    "# =========================\n",
    "rng_emoji = np.random.default_rng(26)\n",
    "emoji = np.empty_like(pred)\n",
    "for i, s in enumerate(pred):\n",
    "    if s == 0:\n",
    "        emoji[i] = int(rng_emoji.integers(0, 2))\n",
    "    elif s == 1:\n",
    "        emoji[i] = 2\n",
    "    else:\n",
    "        emoji[i] = int(rng_emoji.integers(3, 5))\n",
    "df[\"emoji\"] = emoji\n",
    "\n",
    "# =========================\n",
    "# 8) TRUNCATE + INSERT to DB\n",
    "# =========================\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"SET FOREIGN_KEY_CHECKS=0;\"))\n",
    "    conn.execute(text(\"TRUNCATE TABLE stress_levels;\"))\n",
    "    conn.execute(text(\"SET FOREIGN_KEY_CHECKS=1;\"))\n",
    "\n",
    "insert_sql = text(\"\"\"\n",
    "INSERT INTO stress_levels (\n",
    "  user_id, date, stress_level, gpa,\n",
    "  extracurricular_hour_per_day,\n",
    "  physical_activity_hour_per_day,\n",
    "  sleep_hour_per_day,\n",
    "  study_hour_per_day,\n",
    "  social_hour_per_day,\n",
    "  emoji, is_restored, created_at\n",
    ") VALUES (\n",
    "  :user_id, :date, :stress_level, :gpa,\n",
    "  :extracurricular_hour_per_day,\n",
    "  :physical_activity_hour_per_day,\n",
    "  :sleep_hour_per_day,\n",
    "  :study_hour_per_day,\n",
    "  :social_hour_per_day,\n",
    "  :emoji, :is_restored, :created_at\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "payload = df.assign(date=df[\"date\"].dt.date.astype(str)).to_dict(orient=\"records\")\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(insert_sql, payload)\n",
    "\n",
    "print(\"\\n✅ DONE. Inserted rows:\", len(payload))\n",
    "print(\"Stress dist:\", pd.Series(pred).value_counts().sort_index().to_dict())\n",
    "print(\"Emoji dist :\", pd.Series(emoji).value_counts().sort_index().to_dict())\n",
    "print(df[[\"user_id\",\"date\",\"stress_level\",\"emoji\",\"created_at\"]].head(15).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
